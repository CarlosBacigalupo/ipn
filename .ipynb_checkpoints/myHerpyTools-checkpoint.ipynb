{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyfits as pf\n",
    "import pylab as plt\n",
    "from scipy import optimize\n",
    "from scipy.signal import medfilt, find_peaks_cwt\n",
    "from scipy.ndimage.filters import minimum_filter, maximum_filter, median_filter, convolve\n",
    "from scipy.ndimage.measurements import label\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cd /Users/Carlos/Documents/HERMES/reductions/myherpy/HD1581/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Opens a file and subtracts bias from overscann\n",
    "#In: filename\n",
    "#out: thisData (data array)\n",
    "def openFile(fileName):\n",
    "    thisFile = pf.open(fileName)\n",
    "\n",
    "    print thisFile[0].header['OBJECT']\n",
    "    \n",
    "    gain0_2000  = thisFile[0].header['RO_GAIN']\n",
    "    gain2000_4000  = thisFile[0].header['RO_GAIN1']\n",
    "\n",
    "    thisData = thisFile[0].data\n",
    "\n",
    "    bias0_2000 = np.median(thisData[3:2052,4099:-3])\n",
    "    bias2000_4000 = np.median(thisData[2059:-3,4099:-3])\n",
    "\n",
    "    thisData = thisData[:,:4096]\n",
    "\n",
    "    thisData[:2055] -= bias0_2000\n",
    "    thisData[2055:] -= bias2000_4000\n",
    "    \n",
    "    return thisData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cleans and flattens the flat\n",
    "#in: raw flat\n",
    "#out: flattened flat\n",
    "def make_flat_flat(flat):\n",
    "    #Flat fielding\n",
    "    flat_mf = medfilt(flat, [3,9])\n",
    "    flat_1d = np.sum(flat_mf,axis =0)\n",
    "    flat_per = np.percentile(flat_1d, 90)\n",
    "    flat_1d_norm = flat_1d/flat_per\n",
    "    flat_flat = flat_mf / flat_1d_norm[None,:]\n",
    "    return flat_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert flat_flat to binary for tracing\n",
    "def make_flat_flat_bin(flat_flat):\n",
    "    flat_flat_bin = flat_flat.copy()\n",
    "\n",
    "    for i in range(flat_flat.shape[1]):\n",
    "        singleCol = flat_flat[:,i].copy()\n",
    "\n",
    "        singleMinEnv = convolve(minimum_filter(singleCol,15),[.2,.2,.2,.2,.2])\n",
    "        singleMin = singleCol - singleMinEnv\n",
    "\n",
    "        singleMax = convolve(maximum_filter(singleMin,15),[.2,.2,.2,.2,.2])\n",
    "\n",
    "        fixer = convolve(singleMax, np.ones(200)/200)\n",
    "        singleMax[singleMax<fixer*.5] = fixer[singleMax<fixer*.5]*.5\n",
    "        singleColFlat = singleMin/singleMax\n",
    "\n",
    "        singleColFlat[singleColFlat>.3] = 1\n",
    "        singleColFlat[singleColFlat<.3] = 0\n",
    "\n",
    "        flat_flat_bin[:,i] = singleColFlat\n",
    "    return flat_flat_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fibre_centroids(flat_flat_bin):\n",
    "    out_array, fibres = label(flat_flat_bin, np.ones((3,3)))\n",
    "    print 'Found', fibres,'fibres for centroiding'\n",
    "    # n-=2 # fibres 252 and 253 are not good for HD1581 epoch 0 \n",
    "\n",
    "    #create centroid array\n",
    "    cols = out_array.shape[1]\n",
    "    fibre_centroids = np.ones((fibres,cols))*np.nan\n",
    "    for fibre in range(fibres):\n",
    "        wRows, wCols = np.where(out_array==fibre+1)\n",
    "        print fibre,\n",
    "        for col in range(max(wCols)+1):\n",
    "            fibre_centroids[fibre, col] = np.average(wRows[wCols==col])\n",
    "    return fibre_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_single_fibre_centroids(flat_flat_bin, group):\n",
    "    out_array, fibres = label(flat_flat_bin, np.ones((3,3)))\n",
    "    print 'Found', fibres,'fibres for centroiding'\n",
    "    # n-=2 # fibres 252 and 253 are not good for HD1581 epoch 0 \n",
    "\n",
    "    #create centroid array\n",
    "    cols = out_array.shape[1]\n",
    "    fibre_centroids = np.ones(cols)*np.nan\n",
    "#     for fibre in range(fibres):\n",
    "    wRows, wCols = np.where(out_array==group)\n",
    "#     print fibre,\n",
    "    for col in range(max(wCols)+1):\n",
    "        fibre_centroids[fibre, col] = np.average(wRows[wCols==col])\n",
    "    return fibre_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create polynomials from centroids\n",
    "def make_fibrePolys(fibre_centroids):\n",
    "    fibrePolys = np.ones((fibre_centroids.shape[0],6))*np.nan\n",
    "    for y,fibre in enumerate(fibre_centroids):\n",
    "        fibrePolys[y-1,:] = np.polyfit(range(fibre.shape[0]),fibre,5)\n",
    "        if np.sum(np.isnan(fibrePolys[y-1,:]))>0:\n",
    "            print 'Found nan in fibre number',y\n",
    "            print 'Fibre values',fibre[np.isnan(fibre)]\n",
    "            print\n",
    "    return fibrePolys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create tramlines from polynomials\n",
    "def make_tramlines(fibre_centroids, fibrePolys):\n",
    "    tramlines = (np.ones(fibre_centroids.shape)*np.nan)[:-1]\n",
    "    thisRange = np.arange(fibre_centroids.shape[1])\n",
    "    for i,thisPoly in enumerate(fibrePolys[1:]):\n",
    "        tramlines[i] = fithOrder(thisPoly,thisRange)\n",
    "    return tramlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fithOrder(thisPoly, thisRange):\n",
    "    result = thisPoly[0]*thisRange**5\n",
    "    result += thisPoly[1]*thisRange**4\n",
    "    result += thisPoly[2]*thisRange**3\n",
    "    result += thisPoly[3]*thisRange**2\n",
    "    result += thisPoly[4]*thisRange**1\n",
    "    result += thisPoly[5]*thisRange**0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_vertical_shift(flat, arc):\n",
    "    CCTotal = 0\n",
    "    for column in range(flat.shape[1]):\n",
    "        thisFlatCol = flat[:,column]\n",
    "        thisArcCol = arc[:,column]\n",
    "        CCCurve = np.correlate(thisFlatCol, thisArcCol, mode='full')\n",
    "        CCTotal += CCCurve\n",
    "\n",
    "    y = CCTotal[int(CCTotal.shape[0]/2.)+1-5:int(CCTotal.shape[0]/2.)+1+4]\n",
    "    y /=np.max(y)\n",
    "    x = np.arange(-4,5)\n",
    "    x_dense = np.linspace(-4,4)\n",
    "    p,_ = fit_gaussian([1,3.],y,x )\n",
    "    shift = p[0]\n",
    "    return shift\n",
    "################\n",
    "##Need to SUBTRACT the result of the gaussian fit \n",
    "###to make the 1st curve be like the second (i.e the traces be like the arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sum_extract(fibre, tramlines, image, numPx):\n",
    "    \n",
    "    flux = np.ones(tramlines.shape[1])*np.nan\n",
    "#     flux1 = np.ones(tramlines.shape[1])*np.nan\n",
    "#     flux2 = np.ones(tramlines.shape[1])*np.nan\n",
    "    \n",
    "    for i,thisCentroid in enumerate(tramlines[fibre]):\n",
    "#         print thisCentroid\n",
    "        try:\n",
    "            fullPx = image[ int(thisCentroid)-numPx : int(thisCentroid)+numPx+1 , i]\n",
    "            flux[i] = np.sum(fullPx) - fullPx[0]*(thisCentroid%1) - fullPx[-1]*(1-thisCentroid%1)\n",
    "#         flux1[i] = fullPx[0]*(thisCentroid%1)\n",
    "#         flux2[i] = fullPx[-1]*(1-thisCentroid%1)\n",
    "        except:\n",
    "            print fibre, 'falied'\n",
    "            print thisCentroid, 'centroid found in index',i\n",
    "            break\n",
    "#             print fibre\n",
    "    return flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(tramlines_shifted, data):\n",
    "    extracted = np.ones(tramlines_shifted.shape)*np.nan\n",
    "    for fibre in range(tramlines_shifted.shape[0]):\n",
    "        extracted[fibre] = sum_extract(fibre,tramlines_shifted, data, 4)\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig, ):\n",
    "    x = np.array(x)\n",
    "    return np.exp(-np.power(x - mu, 2.) / 2 / np.power(sig, 2.))\n",
    "\n",
    "\n",
    "def flexi_gaussian(x, mu, sig, power, a, d ):\n",
    "    \"\"\"\n",
    "    a* np.exp(-np.power(np.abs((x - mu) * np.sqrt(2*np.log(2))/sig),power))+d\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    return a* np.exp(-np.power(np.abs((x - mu) * np.sqrt(2*np.log(2))/sig),power))+d\n",
    "\n",
    "def fit_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def fit_flexi_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_flexi_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def diff_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "\n",
    "    diff = gaussian(x_range, p[0],p[1]) - flux\n",
    "    return diff\n",
    "\n",
    "def diff_flexi_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "    weights = np.abs(np.gradient(flux)) * (flux+np.max(flux)*.1)\n",
    "    diff = (flexi_gaussian(x_range, p[0], p[1], p[2], p[3], p[4]) - flux)# *weights\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a filename and an array and writes the npy in folder\\\n",
    "def write_NPY(fileName, prefix, postfix, data, folder =\"\"):\n",
    "    if folder[:-1]!=\"/\": folder += \"/\"\n",
    "    outName = folder + prefix + \"_\" + fileName.split(\"/\")[-1][:-5] + \"_\" + postfix\n",
    "    np.save(outName, data)\n",
    "    print outName, \"saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes a filename and an array and writes the npy in folder\\\n",
    "def read_NPY(fileName, prefix, postfix, folder =\"\"):\n",
    "    if folder[:-1]!=\"/\": folder += \"/\"\n",
    "    outName = folder + prefix + \"_\" + fileName.split(\"/\")[-1][:-5] + \"_\" + postfix + \".npy\"\n",
    "    data = np.load(outName)\n",
    "    print outName, \"read\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a ploynomial, a model and errors given a objectArc and a lineTemplate\n",
    "def make_poly_model_err(objectArc, lineListFileName):\n",
    "\n",
    "    #the 1/2 range to fit the cross-correlation over\n",
    "    halfCCRange = 15 \n",
    "    \n",
    "    #1D array of 0s length of pixels\n",
    "    lineTemplate = np.zeros(objectArc.shape[0]) \n",
    "\n",
    "    #this is the ThXe emission line list. 2 cols: pixel, wl. Comes from an adjusted linelist.txt\n",
    "    lineList = np.loadtxt(lineListFileName)\n",
    "    \n",
    "    # make the wavelengths with emissions from lineList=1, the rest 0.\n",
    "    lineTemplate[lineList[:,0].astype(int)]=1\n",
    "    \n",
    "    #plots template and arc\n",
    "#     import pylab as plt\n",
    "#     plt.plot(lineTemplate * np.max(objectArc))\n",
    "#     plt.plot(objectArc)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    #Cross correlate to get offset in the px direction\n",
    "    CCCurve = np.correlate(objectArc, lineTemplate, mode='full')\n",
    "    \n",
    "    if np.sum(np.isnan(CCCurve))==0: #Check for NaNs\n",
    "        #prepare x and y of the cross correlation curve\n",
    "        ccX = np.arange(-halfCCRange,halfCCRange+1)\n",
    "        ccY = CCCurve[int(CCCurve.shape[0]/2.)+1-halfCCRange:int(CCCurve.shape[0]/2.)+1+halfCCRange+1]\n",
    "\n",
    "        #Find px value of the peak of the cross correlation\n",
    "        ccMaxIdx = np.where(ccY==np.max(ccY))[0][0]\n",
    "        thisShift = ccX[ccMaxIdx]\n",
    "        print 'Shift between template and this fibre arc', thisShift\n",
    "\n",
    "        #creates adjLineList with the px offset found in the CC step\n",
    "        adjLineList = lineList.copy()\n",
    "        adjLineList[:,0] += thisShift\n",
    "\n",
    "\n",
    "        #this loop fits a flexigaussian on each emission peak to fine tune the exact px value\n",
    "        for i, thisLineWl in enumerate(adjLineList): #retuns i=index, thisLineWl=[px value, wl] \n",
    "    #         print i,'- Searching for wl',thisLineWl[1],'in px',thisLineWl[0]\n",
    "\n",
    "            #slice 5px on each side of the initial px location guess\n",
    "            firstSliceX = np.arange(thisLineWl[0]-5,thisLineWl[0]+6).astype(int)\n",
    "            firstSliceY = objectArc[firstSliceX]\n",
    "\n",
    "            #find the px value of the found peak\n",
    "            maxIdx =  firstSliceX[np.where(firstSliceY==np.max(firstSliceY))[0][0]]\n",
    "\n",
    "            #slice again, now around the found peak\n",
    "            secondSliceX = np.arange(maxIdx-5,maxIdx+6).astype(int)\n",
    "            secondSliceY = objectArc[secondSliceX]      \n",
    "\n",
    "            p,_ = fit_flexi_gaussian([maxIdx,1., 2., np.max(secondSliceY), 0], secondSliceY, secondSliceX )\n",
    "\n",
    "    #         print 'Changing pixel value',adjLineList[i,0], 'into', p[0]\n",
    "\n",
    "            #put the found peak in the final array\n",
    "            goodPxValue = p[0]\n",
    "            adjLineList[i,0] = goodPxValue\n",
    "\n",
    "            x_dense = np.linspace(np.min(secondSliceX),np.max(secondSliceX))\n",
    "            plt.plot(secondSliceX,secondSliceY)\n",
    "            plt.plot(x_dense,flexi_gaussian(x_dense,p[0],p[1],p[2],p[3],p[4]))\n",
    "            plt.title(goodPxValue)\n",
    "            plt.show()\n",
    "\n",
    "    #     print adjLineList\n",
    "    #         print\n",
    "\n",
    "        #At this point we have an adjusted line list (adjLineList) with the best pixel values \n",
    "        #We turn that into a polynomial, a Wl solution, and an error array\n",
    "\n",
    "        #create the polynimial solution from adjLineList\n",
    "        thisPoly = np.polyfit(adjLineList[:,0], adjLineList[:,1], 5)\n",
    "\n",
    "        #Evaluate the polynomial accross all pixels\n",
    "        thisSolution = fithOrder(thisPoly, np.arange(4095))\n",
    "\n",
    "        thisErr = fithOrder(thisPoly, adjLineList[:,0]) - adjLineList[:,1]\n",
    "\n",
    "    else: #NaNs in CCCurve (from extracted_arc)\n",
    "        thisPoly = np.ones(6) * np.nan\n",
    "        thisSolution = np.ones(4095) * np.nan\n",
    "        thisErr = np.ones(adjLineList.shape[0]) * np.nan\n",
    "\n",
    "    return thisPoly, thisSolution, thisErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a ploynomial from a wls\n",
    "# wlsfilename can be npy or txt\n",
    "def make_poly_from_wls(wlsFileName):\n",
    "    \n",
    "    if wlsFileName[-3:]==\"npy\": #numpy array\n",
    "        wls = np.load(wlsFileName)\n",
    "    elif wlsFileName[-3:]==\"txt\": #txt file\n",
    "        wls = np.loadtxt(wlsFileName)\n",
    "            \n",
    "    #create the polynimial solution from adjLineList\n",
    "    thisPoly = np.polyfit(np.arange(wls.shape[0]), wls, 3)\n",
    "\n",
    "    return thisPoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extend line list to all peaks\n",
    "#creates the new linelist. Wrong, but equally wrong\n",
    "\n",
    "def extend_lineList(objectArc, thisWlPoly, noiseLevel = 200):\n",
    "    \n",
    "    thisObjectArc = objectArc.copy()\n",
    "    thisObjectArc[thisObjectArc<noiseLevel]=0\n",
    "    thisPeaks = find_peaks_cwt(thisObjectArc, np.arange(1,2))\n",
    "    print \"Found\", len(thisPeaks), \"peaks.\"\n",
    "\n",
    "\n",
    "    lineList_v2 = []\n",
    "    for i, thisPeak in enumerate(thisPeaks):\n",
    "    #         print 'Searching for wl',thisLineWl[1],'in px',thisLineWl[0],\n",
    "\n",
    "        firstSliceX = np.arange(thisPeak-5,thisPeak+6).astype(int)\n",
    "        if np.max(firstSliceX) < objectArc.shape[0]:\n",
    "            firstSliceY = thisObjectArc[firstSliceX]\n",
    "            maxIdx =  firstSliceX[np.where(firstSliceY==np.max(firstSliceY))[0][0]]\n",
    "\n",
    "            secondSliceX = np.arange(maxIdx-5,maxIdx+6).astype(int)\n",
    "            secondSliceY = thisObjectArc[secondSliceX]      \n",
    "\n",
    "            p,_ = fit_flexi_gaussian([maxIdx,1., 2., np.max(secondSliceY), 0], secondSliceY, secondSliceX )\n",
    "\n",
    "        #         print 'Changing pixel value',adjLineList[i,0], 'into', p[0]\n",
    "            goodPxValue = p[0]\n",
    "\n",
    "#             x_dense = np.linspace(np.min(secondSliceX),np.max(secondSliceX))\n",
    "#             plt.plot(secondSliceX,secondSliceY)\n",
    "#             plt.plot(x_dense,flexi_gaussian(x_dense,p[0],p[1],p[2],p[3],p[4]))\n",
    "#             plt.title(goodPxValue)\n",
    "#             plt.show()\n",
    "\n",
    "            x = np.polynomial.polynomial.polyval(goodPxValue, thisWlPoly[::-1])\n",
    "\n",
    "            lineList_v2.append((goodPxValue,x))\n",
    "\n",
    "    lineList_v2 = np.array(lineList_v2)\n",
    "    #         plt.plot(x_dense,gaussian(x_dense,p[0],p[1]))\n",
    "    #         plt.plot(firstSliceX,firstSliceY/np.max(firstSliceY))\n",
    "    #         plt.title(maxIdx)\n",
    "    #         plt.plot(objectArc[thisLineWl[0]-5:thisLineWl[0]+5])\n",
    "    #         plt.show()\n",
    "    return lineList_v2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reduces the extendedLinelist based on line stability across epochs\n",
    "def px_change_across_epochs(extendedLinelist, arcNpyList, goodFibres, folder):\n",
    "    #sanitise folder\n",
    "    if folder[:-1]!=\"/\": folder += \"/\"\n",
    "        \n",
    "    #initialise offset array with nans. rows = number of lines, cols= epochs\n",
    "    #each cell holds de diff in pixels between the first epoch and each subsequent for each line\n",
    "    pxValuesEpoch = np.ones((extendedLinelist.shape[0],len(arcNpyList) )) * np.nan\n",
    "    \n",
    "\n",
    "    ref_arc = np.load(folder+arcNpyList[0]) \n",
    "    halfCCRange = 15\n",
    "    refFibre = goodFibres[0]\n",
    "    \n",
    "    #loop over each arc of each epoch (columns)\n",
    "    for colIdx in range(len(arcNpyList)):\n",
    "        extractedFibre = goodFibres[colIdx]\n",
    "#         print \"Working with\", arcNpyList[colIdx] \n",
    "        thisArcNpy = arcNpyList[colIdx]\n",
    "        extracted_arc = np.load(folder+thisArcNpy)\n",
    "\n",
    "#         thisWlsNpy = wlsNpyList[0]\n",
    "#         print thisWlsNpy\n",
    "    # bigLineList = np.loadtxt('bigLineList.txt')\n",
    "#     bigLineList = reducedbigLineList\n",
    "    # lineLocations = np.ones((extracted_arc.shape[0],bigLineList.shape[0]))*np.nan\n",
    "#     lineLocations = np.ones(bigLineList.shape[0])*np.nan\n",
    "\n",
    "# for thisFibre in range(extracted_arc.shape[0])[170:171]:\n",
    "        print 'Fibre',refFibre,\"epoch\",colIdx\n",
    "    \n",
    "        #Cross correlate to get offset in the px direction\n",
    "        CCCurve = np.correlate(ref_arc[refFibre], extracted_arc[extractedFibre], mode='full')\n",
    "\n",
    "#         if np.sum(np.isnan(CCCurve))==0: #Check for NaNs\n",
    "        #prepare x and y of the cross correlation curve\n",
    "        ccX = np.arange(-halfCCRange,halfCCRange+1)\n",
    "        ccY = CCCurve[int(CCCurve.shape[0]/2.)-halfCCRange:int(CCCurve.shape[0]/2.)+1+halfCCRange]\n",
    "\n",
    "        #Find px value of the peak of the cross correlation\n",
    "        ccMaxIdx = np.where(ccY==np.max(ccY))[0][0]\n",
    "        thisShift = ccX[ccMaxIdx]\n",
    "        print 'Shift between template and this fibre arc', thisShift\n",
    "\n",
    "        #creates adjLineList with the px offset found in the CC step\n",
    "        adjLineList_v2 = extendedLinelist.copy()\n",
    "        adjLineList_v2[:,0] += thisShift\n",
    "\n",
    "#         plt.plot(ccX,ccY)\n",
    "#         plt.show()\n",
    "\n",
    "#         thisArc = extracted_arc[refFibre].copy()\n",
    "        \n",
    "        \n",
    "        #hack, should be refFibre for complete wlSolutions array (only doing 1 now)\n",
    "#         thisWlSolution = wlSolutions[0].copy() \n",
    "    \n",
    "        #for this epoch, loop over each wl found in the long list (v2)\n",
    "        for rowIdx, thisWlpx in enumerate(adjLineList_v2[:,0]):\n",
    "#             print 'Searching for wl',thisWl\n",
    "#             diffArray = np.abs(thisWlSolution-thisWl)\n",
    "#             print thisWl, thisWlSolution, diffArray \n",
    "#             wlPx = np.where(diffArray==np.min(diffArray))[0][0]\n",
    "#             print wlPx, thisWlSolution[wlPx-1:wlPx+2]\n",
    "\n",
    "            thisSlice = np.arange(thisWlpx-6,thisWlpx+7).astype(int)\n",
    "\n",
    "#             firstSliceX = thisWlSolution[thisSlice]\n",
    "            firstSliceX = thisSlice\n",
    "            firstSliceY = extracted_arc[extractedFibre][thisSlice]\n",
    "            maxIdx =  thisSlice[np.where(firstSliceY==np.max(firstSliceY))[0][0]]\n",
    "#             print maxIdx\n",
    "        \n",
    "#             if rowIdx==0:\n",
    "#                 if colIdx==0:\n",
    "#                     plt.plot(firstSliceX,firstSliceY)\n",
    "#                     plt.show()\n",
    "\n",
    "        \n",
    "            thisSecondSlice = np.arange(maxIdx-5,maxIdx+6).astype(int)\n",
    "#             secondSliceX = thisWlSolution[thisSecondSlice]\n",
    "            secondSliceX = thisSecondSlice\n",
    "            secondSliceY = extracted_arc[extractedFibre][thisSecondSlice]      \n",
    "\n",
    "#             if rowIdx>30:\n",
    "#                 if colIdx==1:                    \n",
    "#                     x_dense = np.linspace(np.min(secondSliceX),np.max(secondSliceX))\n",
    "#                     plt.plot(secondSliceX,secondSliceY)\n",
    "#                     plt.plot(x_dense,flexi_gaussian(x_dense,maxIdx,4., 2.1,np.max(secondSliceY),0))\n",
    "#                     plt.show()\n",
    "\n",
    "            p,_ = fit_flexi_gaussian([maxIdx,4., 2.1, np.max(secondSliceY), 0], secondSliceY, secondSliceX )\n",
    "#             if rowIdx>30:\n",
    "#                 if colIdx==1:\n",
    "#                     x_dense = np.linspace(np.min(secondSliceX),np.max(secondSliceX))\n",
    "#                     plt.plot(secondSliceX,secondSliceY)\n",
    "#                     plt.plot(x_dense,flexi_gaussian(x_dense,p[0],p[1],p[2],p[3],p[4]))\n",
    "#                     tit='line',rowIdx,'epoch',colIdx\n",
    "#                     plt.title(tit)\n",
    "#                     plt.show()\n",
    "\n",
    "#             print secondSliceX, secondSliceY\n",
    "#             print [maxIdx,.2, 2.8, np.max(secondSliceY), 2]\n",
    "#             print 'F',p[0], extendedLinelist[rowIdx,0]\n",
    "#             diff =np.abs(p[0]-extendedLinelist[rowIdx,0])\n",
    "#             if diff>1.5:\n",
    "#                 x_dense = np.linspace(np.min(secondSliceX),np.max(secondSliceX))\n",
    "#                 plt.plot(secondSliceX,secondSliceY)\n",
    "#                 plt.plot(x_dense,flexi_gaussian(x_dense,p[0],p[1],p[2],p[3],p[4]))\n",
    "#                 tit='line',rowIdx,'epoch',colIdx\n",
    "#                 plt.title(tit)\n",
    "#                 plt.show()\n",
    "\n",
    "            pxValuesEpoch[rowIdx, colIdx] = p[0]\n",
    "    \n",
    "    \n",
    "    return pxValuesEpoch\n",
    "#         lineLocations[thisFibre,i] = goodWlValue\n",
    "#             lineLocations[i] = goodWlValue\n",
    "\n",
    "#         adjLineList[i,0] = goodPxValue\n",
    "        \n",
    "#         x_dense = np.linspace(np.min(secondSliceX),np.max(secondSliceX))\n",
    "#         plt.plot(secondSliceX,secondSliceY)\n",
    "#         plt.plot(x_dense,flexi_gaussian(x_dense,p[0],p[1],p[2],p[3],p[4]))\n",
    "# # #         plt.title(goodPxValue)\n",
    "#         plt.show()\n",
    "\n",
    "# #     print adjLineList\n",
    "    \n",
    "#     a = np.polyfit(adjLineList[:,0], adjLineList[:,1], 5)\n",
    "#     x = fithOrder(a, np.arange(4095))\n",
    "#     err = fithOrder(a, adjLineList[:,0]) - adjLineList[:,1]\n",
    "\n",
    "#     wlPolys.append(a)\n",
    "#     wlErrors.append(err)\n",
    "#     wlSolutions.append(x)\n",
    "    \n",
    "# wlPolys = np.array(wlPolys)\n",
    "# wlErrors = np.array(wlErrors)\n",
    "# wlSolutions = np.array(wlSolutions)\n",
    "# #         plt.plot(x_dense,gaussian(x_dense,p[0],p[1]))\n",
    "# #         plt.plot(firstSliceX,firstSliceY/np.max(firstSliceY))\n",
    "# #         plt.title(maxIdx)\n",
    "# # #         plt.plot(masterArc[thisLineWl[0]-5:thisLineWl[0]+5])\n",
    "# #         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_WLS_from_polys(refWLS, epochPolyFit):\n",
    "    \n",
    "    newWLS = []\n",
    "    newPXs = []\n",
    "    refPx = np.arange(refWLS.shape[0])\n",
    "    for thisEpochPolyFit in epochPolyFit:\n",
    "        \n",
    "        thisNewPx = refPx + np.polynomial.polynomial.polyval(refPx, thisEpochPolyFit[::-1])\n",
    "        newPXs.append(thisNewPx)\n",
    "\n",
    "        thisNewWLS = np.interp(refPx, thisNewPx, refWLS)\n",
    "        newWLS.append(thisNewWLS)\n",
    "    return newPXs, newWLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_flux_and_wls(thisExtracted_obj, thisExtracted_arc, wls, epochIdx, fileIdx, folder):\n",
    "    objFilename = folder + '/HD1581_' + str(epochIdx) + '_' + str(fileIdx) + '.txt'\n",
    "    arcFilename = folder + '/ThXe_' + str(epochIdx) + '_' + str(fileIdx) + '.txt'\n",
    "    np.savetxt(objFilename, np.vstack((wls[epochIdx], thisExtracted_obj)).transpose())\n",
    "    print objFilename, 'saved.'\n",
    "    np.savetxt(arcFilename, np.vstack((wls[epochIdx], thisExtracted_arc)).transpose())    \n",
    "    print arcFilename, 'saved.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def robust_polyfit(x, y, order, sigmaClips, booPlot=False):\n",
    "\n",
    "    for idx,i in enumerate(sigmaClips):\n",
    "        a = x.copy()\n",
    "        b = y.copy()\n",
    "        \n",
    "        poly = np.polyfit(a, b, order)\n",
    "        res = np.polynomial.polynomial.polyval(a, poly[::-1])-b\n",
    "        stdRes = np.std(res)\n",
    "        \n",
    "        polyFilter = np.abs(res)<=stdRes*i\n",
    "        \n",
    "        x = a[polyFilter].copy()\n",
    "        y = b[polyFilter].copy()\n",
    "        print 'Clipping (std*sigma)', stdRes*i,'.', x.shape, 'points left.'\n",
    "\n",
    "        if booPlot==True:\n",
    "            plt.plot(x,y,'.')\n",
    "            if idx==0:\n",
    "                ylim = plt.ylim()\n",
    "            else:\n",
    "                plt.ylim(ylim)\n",
    "            plt.plot(x,np.polynomial.polynomial.polyval(x, poly[::-1]))\n",
    "            plt.title(str(stdRes*i))\n",
    "            plt.show()\n",
    "        \n",
    "    poly = np.polyfit(x, y, order)\n",
    "    \n",
    "    if booPlot==True:\n",
    "        plt.plot(x,y,'.')\n",
    "        plt.ylim(ylim)\n",
    "        plt.plot(x,np.polynomial.polynomial.polyval(x, poly[::-1]))\n",
    "        plt.title(str(stdRes*i))\n",
    "        plt.show()\n",
    "        \n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
