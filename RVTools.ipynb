{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from scipy import interpolate, signal, optimize, constants, stats\n",
    "from scipy.optimize import leastsq\n",
    "import pyfits as pf\n",
    "import sys\n",
    "import os\n",
    "from lmfit import minimize, Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sys.path = ['', '/disks/ceres/makemake/aphot/kalumbe/reductions/NGC2477_1arc_6.2','/usr/local/yt-hg', '/home/science/staff/kalumbe/my-astro-lib', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/lib/pymodules/python2.7', '/usr/lib/python2.7/dist-packages/ubuntu-sso-client', '/usr/lib/python2.7/dist-packages/ubuntuone-client', '/usr/lib/python2.7/dist-packages/ubuntuone-couch', '/usr/lib/python2.7/dist-packages/ubuntuone-storage-protocol', '/usr/lib/python2.7/dist-packages/wx-2.8-gtk2-unicode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_sine_RVs(baryRVs, MJDs,data, RVClip = 1e6, starIdx = -1, cam = -1, npyName = 'sineFit.npy'):\n",
    "\n",
    "    sine_fit = np.ones((baryRVs.shape[0],4,4))*np.nan\n",
    "    try: \n",
    "        sine_fit = np.load('npy/'+npyName)\n",
    "        print 'Found previous',npyName,'array. Using it for update'\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for cam in range(4):\n",
    "        for i,thisRVs in enumerate(baryRVs[:,:,cam]):\n",
    "            if ((starIdx==-1) or(starIdx==i)): \n",
    "                thisRVs[np.abs(np.nan_to_num(thisRVs))>RVClip]=np.nan\n",
    "                thisBaryRVs = thisRVs[-np.isnan(thisRVs)]\n",
    "                thisMJDs = MJDs[-np.isnan(thisRVs)]\n",
    "                \n",
    "                print 'This target:', data[i,0], '- Camera ',str(cam+1)\n",
    "                print 'Calculating RV fit for', thisBaryRVs.shape[0], 'data points.',np.sum(np.isnan(thisRVs)),'NaNs'\n",
    "                if thisMJDs.shape[0]>3:                \n",
    "                    minIdx = np.where(thisBaryRVs==np.min(thisBaryRVs))[0][0]\n",
    "                    maxIdx = np.where(thisBaryRVs==np.max(thisBaryRVs))[0][0]\n",
    "                    guess_P = np.abs(thisMJDs[minIdx] - thisMJDs[maxIdx])*2\n",
    "\n",
    "                    params = Parameters()\n",
    "                    params.add('amp', value=np.abs((np.max(thisBaryRVs)-np.min(thisBaryRVs))/2.), min=0)\n",
    "                    params.add('phase', value = 0, max = guess_P/2., min = -guess_P/2. )\n",
    "                    params.add('period', value=guess_P, min = 0 )\n",
    "\n",
    "                    print 'Guess A,ph,P',params.values()\n",
    "\n",
    "                    output = minimize(optimise_sine, params, args=(thisMJDs, thisBaryRVs))\n",
    "                    \n",
    "                    print 'std err',output.chisqr, output.redchi , np.std(output.residual)\n",
    "\n",
    "                    sine_fit[i,0,cam]=output.params.valuesdict()['amp']\n",
    "                    sine_fit[i,1,cam]=output.params.valuesdict()['phase']\n",
    "                    sine_fit[i,2,cam]=output.params.valuesdict()['period']\n",
    "                    sine_fit[i,3,cam]=np.std(output.residual)\n",
    "\n",
    "                    print 'Guess A,ph,P', sine_fit[i,:3,cam]\n",
    "\n",
    "                else: \n",
    "                    print 'Result','NOT ENOUGH DATAPOINTS'\n",
    "\n",
    "    #                 est_std, est_phase, est_P =ouput[0]\n",
    "\n",
    "                    sine_fit[i,:,cam]=[0,0,0,0]\n",
    "                print \n",
    "            \n",
    "    np.save('npy/'+npyName,sine_fit)\n",
    "    print 'Fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_MJDs_groups(MJDs, gapMins = 40):\n",
    "    \n",
    "    mins2Days = 1/24./60\n",
    "    gap2Days = mins2Days * gapMins # diff in days between exposures to be considered different exposures\n",
    "    \n",
    "    diffArray = MJDs.copy()\n",
    "    diffArray[0] = 0\n",
    "    diffArray[1:] = MJDs[1:]-MJDs[:-1]\n",
    "    \n",
    "    avgIdxGroups = diffArray.copy()\n",
    "    \n",
    "    avgIdx = 0\n",
    "    for i,diff in enumerate(diffArray):\n",
    "        if diff>gap2Days: avgIdx+=1\n",
    "        avgIdxGroups[i] = avgIdx\n",
    "        \n",
    "    np.save('npy/avgIdxGroups.npy',avgIdxGroups.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_MJDs_data():\n",
    "\n",
    "    avgIdxGroups = np.load('npy/avgIdxGroups.npy')\n",
    "    baryRVs = np.load('npy/baryRVs.npy')\n",
    "    MJDs = np.load('npy/MJDs.npy')\n",
    "    \n",
    "    ttlGroups = np.max(avgIdxGroups)+1\n",
    "    avgBaryRVs = np.zeros((baryRVs.shape[0],ttlGroups,4))\n",
    "    avgMJDs = np.zeros(ttlGroups)\n",
    "    \n",
    "    for i in range(ttlGroups):\n",
    "        print i,np.nanmean(baryRVs[:,avgIdxGroups==i,:],axis=1)\n",
    "        avgBaryRVs[:,i,:] = np.nanmean(baryRVs[:,avgIdxGroups==i,:],axis=1)\n",
    "        avgMJDs[i] = np.nanmean(MJDs[avgIdxGroups==i])\n",
    "            \n",
    "    np.save('npy/avgBaryRVs.npy',avgBaryRVs)\n",
    "    np.save('npy/avgMJDs.npy',avgMJDs)\n",
    "    print 'Fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimise_sine(x, MJDs, thisBaryRVs):\n",
    "    \n",
    "#     print 'x',x\n",
    "    \n",
    "    amp = x['amp'].value\n",
    "    ph = x['phase'].value\n",
    "    period = x['period'].value\n",
    "\n",
    "#     print 'MJDs',MJDs\n",
    "#     print 'thisBaryRVs',thisBaryRVs.shape\n",
    "#     if x[2]==0: x[2]=1e-17\n",
    "#     result = x[0]*(np.sin(np.pi*2./x[2]*(MJDs+x[1]))-np.sin(np.pi*2./x[2]*(MJDs[0]+x[1]))) - thisBaryRVs\n",
    "#     if x[2]==0: x[2]=1e-17\n",
    "    #subtracts epoch 0\n",
    "#     result = amp*(np.sin(np.pi*2./period*(MJDs+ph))- np.sin(np.pi*2./period*(MJDs[0]+ph))) - thisBaryRVs\n",
    "\n",
    "    #direct fit\n",
    "    result = amp*(np.sin(np.pi*2./period*(MJDs+ph))) - thisBaryRVs\n",
    "#     print 'result',result\n",
    "#     print result - thisBaryRVs\n",
    "    \n",
    "    return result \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_results(data, sineFit, avgSineFit, baryRVs, avgBaryRVs):\n",
    "\n",
    "    Range = np.ptp(np.nan_to_num(baryRVs),axis=1)\n",
    "    order = np.argsort(Range[:,0])[::-1]    \n",
    "    fittedRangeResults = Range[order]\n",
    "\n",
    "    ratios = sineFit[:,0,:]/sineFit[:,3,:]\n",
    "    fittedResults = ratios[order]\n",
    "    \n",
    "    \n",
    "    avgRatios = avgSineFit[:,0,:]/avgSineFit[:,3,:]\n",
    "    fittedAvgResults = avgRatios[order]\n",
    "    \n",
    "    AvgRange = np.ptp(np.nan_to_num(avgBaryRVs),axis=1)\n",
    "    fittedAvgRangeResults = AvgRange[order]\n",
    "    \n",
    "    fittedData = data[:,0][order]\n",
    "    \n",
    "    np.save('npy/fittedResults.npy',fittedResults)\n",
    "    np.save('npy/fittedRangeResults.npy',fittedRangeResults)\n",
    "    np.save('npy/fittedAvgResults.npy',fittedAvgResults)\n",
    "    np.save('npy/fittedAvgRangeResults.npy',fittedAvgRangeResults)\n",
    "    np.save('npy/fittedData.npy',fittedData)\n",
    "    print 'Fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_equal_wl(wl1, wl2):\n",
    "    result = False\n",
    "    \n",
    "    diff = np.sum(wl1-wl2)\n",
    "    \n",
    "    if diff<1e-17:\n",
    "        result = True\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pivot2idx(pivot):\n",
    "    pivot = np.array(pivot)\n",
    "    \n",
    "    rev_num = [np.nan] + ((np.tile(np.arange(10,0,-1),40)+np.repeat(np.arange(0,40)*10,10))-1).tolist()\n",
    "    rev_num = np.array(rev_num)\n",
    "    \n",
    "    return rev_num[pivot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def idx2pivot(idx):\n",
    "\n",
    "    rev_num = [np.nan] + ((np.tile(np.arange(10,0,-1),40)+np.repeat(np.arange(0,40)*10,10))-1).tolist()\n",
    "    \n",
    "    if len(np.where(rev_num==idx))>0:\n",
    "        result = np.where(rev_num==idx)[0][0]\n",
    "    else:\n",
    "        result = np.nan\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resample_sp(wavelength, flux, minWL, maxWL, xStep):\n",
    "    '''\n",
    "    Rebins the flux into xSteps in log_e space\n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    wavelength : 1-D array\n",
    "            Wavelength values \n",
    "            \n",
    "    flux : 1-D array\n",
    "        Flux values \n",
    "        \n",
    "    xStep : float\n",
    "        Increase step between pixels in log_e(wl)\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    new_wavelength: \n",
    "        log_e(wl) in xStep steps\n",
    "    \n",
    "    new_flux: \n",
    "        rebinned flux\n",
    "\n",
    "    '''\n",
    "    \n",
    "    lnWavelength = np.log(wavelength)\n",
    "    fFlux = interpolate.splrep(lnWavelength, flux) \n",
    "    new_wavelength = np.arange(np.log(minWL), np.log(maxWL),xStep)\n",
    "    new_flux = interpolate.splev(new_wavelength, fFlux, der=0)\n",
    "    \n",
    "#     plt.plot(np.log(wavelength),flux)\n",
    "#     plt.plot(new_wavelength,new_flux)\n",
    "#     plt.show()\n",
    "    \n",
    "    return new_wavelength, new_flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cubic(x,a,b,c,d):\n",
    "    '''\n",
    "    Cubic function\n",
    "    '''\n",
    "    return a*x**3+b*x**2+c*x+d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find the common range of wl for all cameras\n",
    "def find_max_wl_range(thisCam):\n",
    "    '''\n",
    "    Checks the range of valid wavelength for all exposures in given camera.\n",
    "    '''\n",
    "    if len(thisCam.wavelengths)>0:\n",
    "        minWL = np.max(np.min(thisCam.wavelengths, axis=1))\n",
    "        maxWl = np.min(np.max(thisCam.wavelengths, axis=1))\n",
    "\n",
    "    else:\n",
    "        minWL, maxWl = 0,0\n",
    "        \n",
    "    return minWL, maxWl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_arc(wavelength, flux, minWL=0, maxWL=0, xStep = 5*10**-6):\n",
    "    '''\n",
    "    Clean a 1D spectrum. \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    wavelength : int or None, optional\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : int or None, optional\n",
    "        Array of fluxes \n",
    "        \n",
    "    minWL : int, optional\n",
    "        Minimum walength value to return \n",
    "        \n",
    "    maxWL : int, optional\n",
    "        Maximum wavelength value to return \n",
    "        \n",
    "    xStep : float, optional\n",
    "        Coeficient to resample. Final array will be flux.shape[0]*xDef long. \n",
    "        \n",
    "    medianRange : int, optional\n",
    "        Number of pixels to median over. 0 will skip this step. Optional.\n",
    "\n",
    "    flatten : boolean, optional\n",
    "        Divides flux by a fitted 3rd ord polynomial if True. Optional.\n",
    "        \n",
    "    Returns\n",
    "    ----\n",
    "    wavelength : numpy, floats\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : numpy, floats\n",
    "        Array of fluxes \n",
    "        \n",
    "\n",
    "    '''\n",
    "    \n",
    "    #fix initial nans on edges\n",
    "    nanMap = np.isnan(flux)\n",
    "    leftEdgeIdx=0\n",
    "    rightEdgeIdx=len(flux)\n",
    "    \n",
    "#     nanMapIdx = np.where(nanMap==True) <<<<<make the next lines faster by using this\n",
    "    if np.sum(nanMap)>0:\n",
    "        print 'Found NaNs in flux array'\n",
    "    \n",
    "    for i,booI in enumerate(nanMap):\n",
    "        if booI==False:\n",
    "            leftEdgeIdx = i\n",
    "            break\n",
    "            \n",
    "    for j,rbooI in enumerate(nanMap[::-1]):\n",
    "        if rbooI==False:\n",
    "            rightEdgeIdx = len(nanMap)-j\n",
    "            break        \n",
    "\n",
    "    fluxMedian = stats.nanmedian(flux)\n",
    "    if leftEdgeIdx>0:\n",
    "        flux[:leftEdgeIdx] = np.linspace(0, flux[leftEdgeIdx+1],leftEdgeIdx)\n",
    "    if rightEdgeIdx<len(flux):\n",
    "        flux[rightEdgeIdx:] = np.linspace(flux[rightEdgeIdx-1], 0, len(flux)-rightEdgeIdx)\n",
    "\n",
    "        \n",
    "    if ((wavelength[-np.isnan(flux)].shape[0]>0) &  (flux[-np.isnan(flux)].shape[0]>0)):\n",
    "        #resample\n",
    "        wavelength,flux = resample_sp(wavelength, flux, minWL, maxWL, xStep)\n",
    "        \n",
    "    else: #if not enough data return NaNs\n",
    "        wavelength = np.ones(4096)*np.nan\n",
    "        flux = np.ones(4096)*np.nan\n",
    "        \n",
    "    return wavelength, flux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_flux(wavelength, flux, minWL=0, maxWL=0, xStep = 10**-5, medianRange = 0, flatten = True):\n",
    "    '''\n",
    "    Clean a 1D spectrum. \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    wavelength : int or None, optional\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : int or None, optional\n",
    "        Array of fluxes \n",
    "        \n",
    "    minWL : int, optional\n",
    "        Minimum walength value to return \n",
    "        \n",
    "    maxWL : int, optional\n",
    "        Maximum wavelength value to return \n",
    "        \n",
    "    xStep : float, optional\n",
    "        Coeficient to resample. Final array will be flux.shape[0]*xDef long. \n",
    "        \n",
    "    medianRange : int, optional\n",
    "        Number of pixels to median over. 0 will skip this step. Optional.\n",
    "\n",
    "    flatten : boolean, optional\n",
    "        Divides flux by a fitted 3rd ord polynomial if True. Optional.\n",
    "        \n",
    "    Returns\n",
    "    ----\n",
    "    wavelength : numpy, floats\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : numpy, floats\n",
    "        Array of fluxes \n",
    "        \n",
    "\n",
    "    '''\n",
    "    \n",
    "    #fix initial nans on edges\n",
    "    nanMap = np.isnan(flux)\n",
    "    leftEdgeIdx=0\n",
    "    rightEdgeIdx=len(flux)\n",
    "    \n",
    "#     nanMapIdx = np.where(nanMap==True) <<<<<make the next lines faster by using this\n",
    "    if np.sum(nanMap)>0:\n",
    "        print 'Found NaNs in flux array'\n",
    "        \n",
    "    for i,booI in enumerate(nanMap):\n",
    "        if booI==False:\n",
    "            leftEdgeIdx = i\n",
    "            break\n",
    "            \n",
    "    for j,rbooI in enumerate(nanMap[::-1]):\n",
    "        if rbooI==False:\n",
    "            rightEdgeIdx = len(nanMap)-j\n",
    "            break        \n",
    "\n",
    "    fluxMedian = stats.nanmedian(flux)\n",
    "    if leftEdgeIdx>0:\n",
    "        flux[:leftEdgeIdx] = np.linspace(fluxMedian, flux[leftEdgeIdx+1],leftEdgeIdx)\n",
    "    if rightEdgeIdx<len(flux):\n",
    "        flux[rightEdgeIdx:] = np.linspace(flux[rightEdgeIdx-1], fluxMedian, len(flux)-rightEdgeIdx)\n",
    "\n",
    "        \n",
    "        \n",
    "    #median outliers\n",
    "    if medianRange>0:\n",
    "        fluxMed = signal.medfilt(flux,medianRange)\n",
    "        fluxDiff = abs(flux-fluxMed)\n",
    "#         fluxDiff = flux-fluxMed\n",
    "        fluxDiffStd = np.std(fluxDiff)\n",
    "        mask = fluxDiff> 3 * fluxDiffStd\n",
    "        flux[mask] = fluxMed[mask]\n",
    "\n",
    "\n",
    "    if ((wavelength[-np.isnan(flux)].shape[0]>0) &  (flux[-np.isnan(flux)].shape[0]>0)):\n",
    "        \n",
    "        if flatten==True:#flatten curve by fitting a 3rd order poly\n",
    "            fFlux = optimize.curve_fit(cubic, wavelength[-np.isnan(flux)], flux[-np.isnan(flux)], p0 = [1,1,1,1])\n",
    "            fittedCurve = cubic(wavelength, fFlux[0][0], fFlux[0][1], fFlux[0][2], fFlux[0][3])\n",
    "            flux = flux/fittedCurve-1\n",
    "        else:\n",
    "            flux = flux/fluxMedian-1\n",
    "            \n",
    "        #apply tukey\n",
    "        flux = flux * signal.tukey(len(flux), 0.2)\n",
    "\n",
    "        #resample\n",
    "        wavelength,flux = resample_sp(wavelength, flux, minWL, maxWL, xStep)\n",
    "        \n",
    "    else: #if not enough data return NaNs\n",
    "        wavelength = np.ones(4096)*np.nan\n",
    "        flux = np.ones(4096)*np.nan\n",
    "        \n",
    "    return wavelength, flux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create cross correlation curves wrt epoch 0\n",
    "def RVs_CC_t0_arc(thisStar, CCReferenceSet = 0, corrHWidth=10):\n",
    "    '''\n",
    "    Cross-correlates all epochs wrt t0. Writes the results to thisStar.cameras[].RVs\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    thisStar : obj\n",
    "        Object holding the star that holds the fluxes to be cross-correlated\n",
    "        \n",
    "    starIdx : int\n",
    "        Index of the star in to be linked in the comments. Not very useful. \n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    Nottin.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "#     validDates = np.all([np.nansum(thisCam.red_fluxes,1).astype(bool) for thisCam in thisStar.exposures.cameras],0)\n",
    "    print ''\n",
    "    for cam,thisCam in enumerate(thisStar.exposures.cameras[:1]):\n",
    "        RVs = []\n",
    "        sigmas = [] \n",
    "        Qs = []\n",
    "        SNRs = []\n",
    "\n",
    "        validDates = np.nansum(thisCam.red_fluxes,1).astype(bool)\n",
    "        \n",
    "        print 'Camera',cam\n",
    "        \n",
    "        minWL, maxWL = find_max_wl_range(thisCam)\n",
    "        \n",
    "        #Filters exposures to a minimum MJD\n",
    "#         if minMJD>0:\n",
    "#             print 'Reducing MJD to >=',minMJD\n",
    "#             validDates = thisStar.exposures.MJDs>=minMJD\n",
    "            \n",
    "            \n",
    "#         if len(np.arange(len(validDates))[validDates])>0:\n",
    "#             CCReferenceSet = np.arange(len(validDates))[validDates][0]\n",
    "#         else:\n",
    "#             CCReferenceSet = 0\n",
    "            \n",
    "#         print 'Refernce set =',CCReferenceSet\n",
    "        \n",
    "        lambda1, flux1 = clean_arc(thisCam.wavelengths[CCReferenceSet], thisCam.red_fluxes[CCReferenceSet], minWL, maxWL)\n",
    "        \n",
    "        plts = 0    \n",
    "        for epoch, MJD in enumerate(thisStar.exposures.MJDs):\n",
    "            print epoch,\n",
    "            lambda2, flux2 = clean_arc(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch], minWL, maxWL)\n",
    "\n",
    "            try:\n",
    "                \n",
    "                #Duncan's approach to CC. \n",
    "                CCCurve = np.correlate(flux1, flux2, mode='full')\n",
    "\n",
    "                y = CCCurve[int(CCCurve.shape[0]/2.)-corrHWidth:int(CCCurve.shape[0]/2.)+1+corrHWidth].copy()\n",
    "                y /=np.max(y)\n",
    "                x = np.arange(-corrHWidth,corrHWidth+1)\n",
    "                p,_ = fit_flexi_gaussian([1,3.,2.,1.,0],y,x )\n",
    "                shift = p[0]\n",
    "                \n",
    "#                 thisQ, thisdRV = QdRV(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch])\n",
    "\n",
    "                px = 1000\n",
    "                RV = (np.exp(lambda1[px+1]-lambda1[px]) -1) * constants.c * shift\n",
    "                print 'RV',RV                \n",
    "\n",
    "            except Exception,e: \n",
    "                print 'CC Error'\n",
    "                print str(e)\n",
    "                R = 0\n",
    "                thisQ = 0\n",
    "                thisdRV = 0\n",
    "                RV = 0\n",
    "\n",
    "            SNR = np.sqrt(stats.nanmedian(thisCam.red_fluxes[epoch]))\n",
    "\n",
    "\n",
    "            SNRs.append(SNR)\n",
    "    #         Qs.append(thisQ)\n",
    "    #         sigmas.append(thisdRV)\n",
    "            RVs.append(RV)\n",
    "\n",
    "\n",
    "\n",
    "#     thisCam.sigmas = np.array(sigmas)\n",
    "#     thisCam.Qs = np.array(Qs)\n",
    "    thisCam.RVs = np.array(RVs)\n",
    "    thisCam.SNRs = np.array(SNRs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig, ):\n",
    "    x = np.array(x)\n",
    "    return np.exp(-np.power(x - mu, 2.) / 2 / np.power(sig, 2.))\n",
    "\n",
    "\n",
    "def flexi_gaussian(x, mu, sig, power, a, d ):\n",
    "    x = np.array(x)\n",
    "    return a* np.exp(-np.power(np.abs((x - mu) * np.sqrt(2*np.log(2))/sig),power))+d\n",
    "\n",
    "def fit_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def fit_flexi_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_flexi_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def diff_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "\n",
    "    diff = gaussian(x_range, p[0],p[1]) - flux\n",
    "    return diff\n",
    "\n",
    "def diff_flexi_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "    weights = np.abs(np.gradient(flux)) * (flux+np.max(flux)*.1)\n",
    "    diff = (flexi_gaussian(x_range, p[0], p[1], p[2], p[3], p[4]) - flux)# *weights\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create cross correlation curves wrt epoch 0\n",
    "def RVs_CC_t0(thisStar, starIdx, minMJD=0 ,  xDef = 1, CCReferenceSet = 0, printDetails=False, corrHWidth=10, medianRange = 0, useRangeFilter = False):\n",
    "    '''\n",
    "    Cross-correlates all epochs wrt t0. Writes the results to thisStar.cameras[].RVs\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    thisStar : obj\n",
    "        Object holding the star that holds the fluxes to be cross-correlated\n",
    "        \n",
    "    starIdx : int\n",
    "        Index of the star in to be linked in the comments. Not very useful. \n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    Nottin.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "#     validDates = np.all([np.nansum(thisCam.red_fluxes,1).astype(bool) for thisCam in thisStar.exposures.cameras],0)\n",
    "    print ''\n",
    "    for cam,thisCam in enumerate(thisStar.exposures.cameras[:1]):\n",
    "        RVs = []\n",
    "        sigmas = [] \n",
    "        Qs = []\n",
    "        SNRs = []\n",
    "\n",
    "        validDates = np.nansum(thisCam.red_fluxes,1).astype(bool)\n",
    "        \n",
    "        print 'Camera',cam\n",
    "        \n",
    "        minWL, maxWL = find_max_wl_range(thisCam)\n",
    "        \n",
    "        #Filters exposures to a minimum MJD\n",
    "#         if minMJD>0:\n",
    "#             print 'Reducing MJD to >=',minMJD\n",
    "#             validDates = thisStar.exposures.MJDs>=minMJD\n",
    "            \n",
    "            \n",
    "#         if len(np.arange(len(validDates))[validDates])>0:\n",
    "#             CCReferenceSet = np.arange(len(validDates))[validDates][0]\n",
    "#         else:\n",
    "#             CCReferenceSet = 0\n",
    "            \n",
    "#         print 'Refernce set =',CCReferenceSet\n",
    "        \n",
    "        lambda1, flux1 = clean_flux(thisCam.wavelengths[CCReferenceSet], thisCam.red_fluxes[CCReferenceSet], minWL, maxWL, medianRange=medianRange)\n",
    "        \n",
    "        plts = 0    \n",
    "        for epoch, MJD in enumerate(thisStar.exposures.MJDs):\n",
    "            print epoch,\n",
    "            lambda2, flux2 = clean_flux(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch], minWL, maxWL, medianRange=medianRange)\n",
    "\n",
    "            try:\n",
    "                \n",
    "                #Duncan's approach to CC. \n",
    "                CCCurve = np.correlate(flux1, flux2, mode='full')\n",
    "\n",
    "                y = CCCurve[int(CCCurve.shape[0]/2.)+1-5:int(CCCurve.shape[0]/2.)+1+4].copy()\n",
    "                y /=np.max(y)\n",
    "                x = np.arange(-4,5)\n",
    "                p,_ = fit_gaussian([1,3.],y,x )\n",
    "                shift = p[0]\n",
    "                \n",
    "#                 thisQ, thisdRV = QdRV(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch])\n",
    "\n",
    "                px = 1000\n",
    "                RV = (np.exp(lambda1[px+1]-lambda1[px]) -1) * constants.c * shift\n",
    "                print 'RV',RV                \n",
    "\n",
    "            except Exception,e: \n",
    "                print 'CC Error'\n",
    "                print str(e)\n",
    "                R = 0\n",
    "                thisQ = 0\n",
    "                thisdRV = 0\n",
    "                RV = 0\n",
    "\n",
    "            SNR = np.sqrt(stats.nanmedian(thisCam.red_fluxes[epoch]))\n",
    "\n",
    "\n",
    "            SNRs.append(SNR)\n",
    "    #         Qs.append(thisQ)\n",
    "    #         sigmas.append(thisdRV)\n",
    "            RVs.append(RV)\n",
    "\n",
    "\n",
    "\n",
    "#     thisCam.sigmas = np.array(sigmas)\n",
    "#     thisCam.Qs = np.array(Qs)\n",
    "    thisCam.RVs = np.array(RVs)\n",
    "    thisCam.SNRs = np.array(SNRs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def comment(star, epoch, cam, comment):\n",
    "    comments = []\n",
    "    try:\n",
    "        os.mkdir('npy')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        comments = np.load('npy/comments.npy')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if comments==[]:\n",
    "        comments = np.zeros((1,),dtype=('i4,i4,i4,a100'))\n",
    "        comments[:] = [(star, epoch, cam, comment)]\n",
    "    else:\n",
    "        x = np.zeros((1,),dtype=('i4,i4,i4,a100'))\n",
    "        x[:] = [(star, epoch, cam, comment)]\n",
    "        comments = np.append(comments,x)\n",
    "    \n",
    "    np.save('npy/comments.npy',comments)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create cross correlation curves wrt epoch 0\n",
    "def single_RVs_CC_t0(thisStar, cam = 0, t = 0, corrHWidth =10, xDef = 1):\n",
    "\n",
    "        print 'Camera',cam, '- t0 wrt t',t\n",
    "        \n",
    "        thisCam = thisStar.exposures.cameras[cam]\n",
    "            \n",
    "        lambda1, flux1 = clean_flux(thisCam.wavelengths[0], thisCam.red_fluxes[0], thisCam, medianRange=5, xDef=xDef )\n",
    "        \n",
    "        lambda2, flux2 = clean_flux(thisCam.wavelengths[t], thisCam.red_fluxes[t], thisCam, medianRange=5, xDef=xDef)\n",
    "        CCCurve = []\n",
    "        CCCurve = signal.fftconvolve(flux1[-np.isnan(flux1)], flux2[-np.isnan(flux2)][::-1], mode='same')\n",
    "        corrMax = np.where(CCCurve==max(CCCurve))[0][0]\n",
    "        p_guess = [corrMax,corrHWidth]\n",
    "        x_mask = np.arange(corrMax-corrHWidth, corrMax+corrHWidth+1)\n",
    "        if max(x_mask)<len(CCCurve):\n",
    "            p = fit_gaussian(p_guess, CCCurve[x_mask], np.arange(len(CCCurve))[x_mask])[0]\n",
    "            if np.modf(CCCurve.shape[0]/2.0)[0]>1e-5:\n",
    "                pixelShift = (p[0]-(CCCurve.shape[0]-1)/2.) #odd number of elements\n",
    "            else:\n",
    "                pixelShift = (p[0]-(CCCurve.shape[0])/2.) #even number of elements\n",
    "\n",
    "\n",
    "            mid_px = thisCam.wavelengths.shape[1]/2\n",
    "            dWl = (thisCam.wavelengths[t,mid_px+1]-thisCam.wavelengths[t,mid_px]) / thisCam.wavelengths[t,mid_px]/xDef\n",
    "            RV = dWl * pixelShift * constants.c \n",
    "            print 'RV',RV\n",
    "        else:\n",
    "            p=RV=0\n",
    "            \n",
    "#         print 'HERE:'\n",
    "\n",
    "        return lambda1,flux1, lambda2,flux2, CCCurve, p, x_mask, RV \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bouchy functions\n",
    "def QdRV(Lambda, A0):\n",
    "\t\n",
    "\tW1 = W(Lambda, A0)\n",
    "\tQ_out = 0\n",
    "\tdRV = 0\n",
    "\tif np.sum(W1)>0:\n",
    "\t\tQ_out = Q(W1, A0)\n",
    "\t\tdRV = constants.c/np.sqrt(np.sum(W1))\n",
    "\t\n",
    "\treturn Q_out, dRV\n",
    "\n",
    "def Q(W, A0):\n",
    "\t'''\n",
    "    Calculates the Q factor of a spectrum from W(weight) and A0(flux) form Bouchy 2001.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    W : np.array\n",
    "        n x 1 np.array weight \n",
    "        \n",
    "    AO : np.array\n",
    "        n x 1 np.array with flux counts\n",
    "    \n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    Q : float\n",
    "        Quality factor. \n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    '''\n",
    "\tQ = 0\n",
    "\tif np.sum(A0[-np.isnan(A0)])>0:\n",
    "\t\tQ = np.sqrt(np.sum(W)/np.sum(A0[-np.isnan(A0)]))\n",
    "\t\n",
    "\treturn Q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def W(Lambda, A0):\n",
    "\t'''\n",
    "    Calculates the weight function form Bouchy 2001.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Lambda : np.array\n",
    "        n x 1 np.array with wavelength bins\n",
    "        \n",
    "    AO : np.array\n",
    "        n x 1 np.array with counts\n",
    "    \n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    W : np.array\n",
    "        n x 1 np.array weights as a function of pixel.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Lambda and A0 should be equal length.\n",
    "    Uses:\n",
    "    W(i) = Lambda(i)**2 (dA0(i)/dLambda(i))**2 / A0(i)\n",
    "    Assumes noise free detector. (No sigma_D**2 term in the denominator).\n",
    "    dA0(i)/dLambda(i) simplified as discrete DeltaY/DeltaX.\n",
    "    '''\n",
    "\n",
    "\tdA0dL = np.zeros(len(A0)-1)\n",
    "\t\n",
    "\tfor i in range(len(A0)-1): #compute partial derivative\n",
    "\t\tdA0dL[i] = (A0[i+1] - A0[i])/(Lambda[i+1] - Lambda[i])\n",
    "\n",
    "\t#compute W (removing last term from Lambda and A0 as dA0dL has n-1 terms.\n",
    "\tW = Lambda[:-1]**2 * dA0dL**2 / A0[:-1]\n",
    "\t\n",
    "\t#clean nans\n",
    "\tW[np.isnan(W)] = 0\n",
    "\t\n",
    "\treturn W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit gaussian in CCCurves\n",
    "def gaussian(x, mu, sig, ):\n",
    "    return np.exp(-np.power(x - mu, 2.) / 2 / np.power(sig, 2.))\n",
    "\n",
    "def fit_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_gausian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def diff_gausian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "    diff = gaussian(x_range, p[0],p[1]) - flux/np.max(flux)\n",
    "    return diff\n",
    "\n",
    "def get_wavelength(wavelengths, pixel):\n",
    "    intPx = int(pixel)\n",
    "    fracPx = pixel - int(pixel)\n",
    "\n",
    "    return (wavelengths[intPx+1] - wavelengths[intPx])*fracPx + wavelengths[intPx]\n",
    "\n",
    "def extract_HERMES_wavelength(fileName):\n",
    "\n",
    "    a = pf.open(fileName)\n",
    "\n",
    "    CRVAL1 = a[0].header['CRVAL1'] # / Co-ordinate value of axis 1                    \n",
    "    CDELT1 = a[0].header['CDELT1'] #  / Co-ordinate increment along axis 1             \n",
    "    CRPIX1 = a[0].header['CRPIX1'] #  / Reference pixel along axis 1                   \n",
    "\n",
    "    #Creates an array of offset wavelength from the referece px/wavelength\n",
    "    Lambda = CRVAL1 - (CRPIX1 - (np.arange(int(CRPIX1)*2)))* CDELT1\n",
    "\n",
    "    return Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_iraf_wavelength(header, app):\n",
    "    WS = 'WS_'+str(app)\n",
    "    WD = 'WD_'+str(app)\n",
    "\n",
    "    first_px = float(header[WS])\n",
    "    disp = float(header[WD])\n",
    "    length = header['NAXIS1']\n",
    "    wl = np.arange(length)*disp\n",
    "    wl += first_px\n",
    "    \n",
    "    return wl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_pyhermes_wavelength(fileName):\n",
    "\n",
    "    thisFile = pf.open(fileName)\n",
    "\n",
    "    CRVAL1 = thisFile[0].header['CRVAL1'] # / Co-ordinate value of axis 1                    \n",
    "    CDELT1 = thisFile[0].header['CDELT1'] #  / Co-ordinate increment along axis 1             \n",
    "    CRPIX1 = thisFile[0].header['CRPIX1'] #  / Reference pixel along axis 1                   \n",
    "    NAXIS1 = thisFile[0].header['NAXIS1'] #  / length of the array     \n",
    "\n",
    "    #Creates an array of offset wavelength from the referece px/wavelength\n",
    "    Lambda = (np.arange(int(NAXIS1)))* CDELT1 + CRVAL1\n",
    "    \n",
    "    return Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pivot_to_y(ref_file):\n",
    "     \n",
    "    a = pf.getdata(ref_file)\n",
    "    \n",
    "    return a[:,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def calibrator_weights(deltay, sigma):\n",
    "    \"\"\"For calibrator stars with CCD y values deltay from the target star\n",
    "    and radial velocity errors sigma, create an optimal set of weights.\n",
    "\n",
    "    We want to minimise the variance of the weighted sum of calibrator\n",
    "    radial velocities where we have the following constraints:\n",
    "\n",
    "    1) \\Sigma w_i = 1  (i.e. the average value of the calibrators measure CCD shifts)\n",
    "    2) \\Sigma w_i dy_i = 0 (i.e. allow the wavelength solution to rotate about the target)\n",
    "\n",
    "    See http://en.wikipedia.org/wiki/Quadratic_programming\n",
    "    \"\"\"\n",
    "    N = len(sigma)\n",
    "    #Start of with a matrix of zeros then fill it with the \"Q\" and \"E\" matrices\n",
    "    M = np.zeros((N+2,N+2))\n",
    "    M[(range(N),range(N))] = sigma\n",
    "#     idx = np.where(deltay==0)[0][0]\n",
    "#     M[idx,idx] = 1e17\n",
    "    M[N,0:N] = deltay\n",
    "    M[0:N,N] = deltay\n",
    "    M[N+1,0:N] = np.ones(N)\n",
    "    M[0:N,N+1] = np.ones(N)\n",
    "    b = np.zeros(N+2)\n",
    "    b[N+1] = 1.0\n",
    "    #Solve the problem M * x = b\n",
    "    x = np.linalg.solve(M,b)\n",
    "    #The first N elements of x contain the weights.\n",
    "    return x[0:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calibrator_weights2(deltay,SNR):\n",
    "\n",
    "    c = 1/np.abs(deltay)/SNR\n",
    "    c[deltay==0]=0\n",
    "    c /=np.sum(c)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calibrator_weights3(deltay,SNR):\n",
    "#nope\n",
    "    c = (SNR+np.abs(deltay))/np.abs(deltay)\n",
    "    c[deltay==0]=0\n",
    "    c /=np.sum(c)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_allW(data = [], SNRs = [], starSet=[], RVCorrMethod = 'PM', refEpoch = 0):\n",
    "\n",
    "    if ((data!=[]) and (SNRs!=[])):\n",
    "        if ((starSet!=[]) and (len(starSet.shape)==1) and (starSet[0]>0)):\n",
    "            data = data[starSet]\n",
    "            SNRs = SNRs[starSet]\n",
    "\n",
    "        #load function that translates pivot# to y-pixel  p2y(pivot)=y-pixel of pivot\n",
    "        p2y = pivot_to_y('/Users/Carlos/Documents/HERMES/reductions/6.2/rhoTuc_6.2/0_20aug/1/20aug10042tlm.fits') \n",
    "\n",
    "        #gets the y position of for the data array\n",
    "        datay = p2y[data[:,2].astype(float).astype(int)]\n",
    "        order = np.argsort(datay)\n",
    "        \n",
    "        #Creates empty array for relative weights\n",
    "        #allW[Weights, camera, staridx of the star to be corrected]\n",
    "        allW = np.zeros((data.shape[0],4,data.shape[0]))\n",
    "\n",
    "        for thisStarIdx in range(data.shape[0]):\n",
    "\n",
    "            #converts datay into deltay\n",
    "            deltay = datay-datay[thisStarIdx]\n",
    "\n",
    "            for cam in range(4):\n",
    "\n",
    "                thisSigma = 1./SNRs[:,refEpoch,cam].copy()\n",
    "                thisSigma[np.isnan(thisSigma)]=1e+17  #sets NaNs into SNR=1e-17\n",
    "                \n",
    "                if np.sum(thisSigma)>0:\n",
    "                    if RVCorrMethod == 'PM':\n",
    "                        W = calibrator_weights(deltay,thisSigma)\n",
    "                    elif RVCorrMethod == 'DM':\n",
    "                        W = calibrator_weights2(deltay,thisSigma)\n",
    "                        \n",
    "#                         print data[thisStarIdx,0],RVCorrMethod\n",
    "                        if data[thisStarIdx,0]=='Giant01':\n",
    "                            for a,b,c in zip(thisSigma[order],W[order], thisSigma[order]):\n",
    "                                print 1./a,b,c\n",
    "                        print ''\n",
    "\n",
    "                else:\n",
    "                    W = np.zeros(deltay.shape[0]) #hack to fix an all zeros SNRs for failed reductions\n",
    "                \n",
    "                allW[:,cam,thisStarIdx] = W\n",
    "                    \n",
    "    else:\n",
    "        print 'Create allW: Input arrays missing'\n",
    "        allW =[]\n",
    "\n",
    "    return allW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_RVCorr_PM(RVs, allW, RVClip = 1e17,starSet=[]):\n",
    "    RVCorr = np.zeros(RVs.shape)\n",
    "    print 'Clipping to',RVClip\n",
    "    RVs[np.abs(RVs)>RVClip]=0\n",
    "    \n",
    "    for thisStarIdx in range(RVs.shape[0]):\n",
    "        for epoch in range(RVs.shape[1]):\n",
    "            thisRVCorr = (allW[:,:,thisStarIdx]+1)*RVs[:,epoch,:]\n",
    "            RVCorr[:,epoch,:] = thisRVCorr + RVs[:,epoch,:] \n",
    "\n",
    "    return RVCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_RVCorr_DM(RVs, allW, RVClip = 1e17,starSet=[]):\n",
    "    RVCorr = np.zeros(RVs.shape)\n",
    "    print 'Clipping to',RVClip\n",
    "    RVs[np.abs(RVs)>RVClip]=0\n",
    "    \n",
    "    for thisStarIdx in range(RVs.shape[0]):\n",
    "        for epoch in range(RVs.shape[1]):\n",
    "            for cam in range(RVs.shape[2]):\n",
    "                thisRVCorr = np.nansum(allW[:,cam,thisStarIdx]*RVs[:,epoch,cam])\n",
    "                RVCorr[thisStarIdx,epoch,cam] = thisRVCorr\n",
    "\n",
    "    return RVCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quad(x,a,b,c):\n",
    "    curve  = a*x**2+b*x+c\n",
    "    return curve\n",
    "\n",
    "def fit_quad(p, quadX, quadY):\n",
    "    a = optimize.leastsq(diff_quad, p, args= [quadX, quadY], epsfcn=0.1)\n",
    "    return a\n",
    "\n",
    "def diff_quad(p, args):\n",
    "    quadX = args[0]\n",
    "    quadY = args[1]\n",
    "    diff = quad(quadX, p[0],p[1], p[2]) - quadY\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tukey(alpha, N):\n",
    "    '''\n",
    "    Deprecated, use scipy.signal.tukey\n",
    "    Creates a tukey function\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    alpha : float\n",
    "        Fraction of the pixels to fade in/out.\n",
    "        i.e. alpha=0.1 will use 10% of the pixels to go from 0 to 1. \n",
    "        \n",
    "    N : int\n",
    "        Totla number of pixels in the array.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "\n",
    "    N-length array of floats from 0 to 1. \n",
    "    '''\n",
    "\n",
    "    \n",
    "    tukey = np.zeros(N)\n",
    "    for i in range(int(alpha*(N-1)/2)):\n",
    "        tukey[i] = 0.5*(1+np.cos(np.pi*(2*i/alpha/(N-1)-1)))\n",
    "    for i in range(int(alpha*(N-1)/2),int((N-1)*(1-alpha/2))):\n",
    "        tukey[i] = 1\n",
    "    for i in range(int((N-1)*(1-alpha/2)),int((N-1))):\n",
    "        tukey[i] = 0.5*(1+np.cos(np.pi*(2*i/alpha/(N-1)-2/alpha+1)))\n",
    "    \n",
    "    return tukey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_continuum(disp, flux, knot_spacing=200, sigma_clip=(1.0, 0.2), \\\n",
    "      max_iterations=3, order=3, exclude=None, include=None, \\\n",
    "      additional_points=None, function='spline', scale=1.0, **kwargs):\n",
    "    \"\"\"Fits the continuum for a given `Spectrum1D` spectrum.\n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    knot_spacing : float or None, optional\n",
    "        The knot spacing for the continuum spline function in Angstroms. Optional.\n",
    "        If not provided then the knot spacing will be determined automatically.\n",
    "    \n",
    "    sigma_clip : a tuple of two floats, optional\n",
    "        This is the lower and upper sigma clipping level respectively. Optional.\n",
    "        \n",
    "    max_iterations : int, optional\n",
    "        Maximum number of spline-fitting operations.\n",
    "        \n",
    "    order : int, optional\n",
    "        The order of the spline function to fit.\n",
    "        \n",
    "    exclude : list of tuple-types containing floats, optional\n",
    "        A list of wavelength regions to always exclude when determining the\n",
    "        continuum. Example:\n",
    "        \n",
    "        >> exclude = [\n",
    "        >>    (3890.0, 4110.0),\n",
    "        >>    (4310.0, 4340.0)\n",
    "        >>  ]\n",
    "        \n",
    "        In the example above the regions between 3890 A and 4110 A, as well as\n",
    "        4310 A to 4340 A will always be excluded when determining the continuum\n",
    "        regions.\n",
    "\n",
    "    function: only 'spline' or 'poly'\n",
    "\n",
    "    scale : float\n",
    "        A scaling factor to apply to the normalised flux levels.\n",
    "        \n",
    "    include : list of tuple-types containing floats, optional\n",
    "        A list of wavelength regions to always include when determining the\n",
    "        continuum.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    (c) Dr. Casey\n",
    "    \"\"\"\n",
    "    \n",
    "    exclusions = []\n",
    "    continuum_indices = range(len(flux))\n",
    "\n",
    "    # Snip left and right\n",
    "    finite_positive_flux = np.isfinite(flux) * flux > 0\n",
    "\n",
    "    #print \"finite flux\", np.any(finite_positive_flux), finite_positive_flux\n",
    "    #print \"where flux\", np.where(finite_positive_flux)\n",
    "    #print \"flux is...\", flux\n",
    "    left_index = np.where(finite_positive_flux)[0][0]\n",
    "    right_index = np.where(finite_positive_flux)[0][-1]\n",
    "\n",
    "    # See if there are any regions we need to exclude\n",
    "    if exclude is not None and len(exclude) > 0:\n",
    "        exclude_indices = []\n",
    "        \n",
    "        if isinstance(exclude[0], float) and len(exclude) == 2:\n",
    "            # Only two floats given, so we only have one region to exclude\n",
    "            exclude_indices.extend(range(*np.searchsorted(disp, exclude)))\n",
    "            \n",
    "        else:\n",
    "            # Multiple regions provided\n",
    "            for exclude_region in exclude:\n",
    "                exclude_indices.extend(range(*np.searchsorted(disp, exclude_region)))\n",
    "    \n",
    "        continuum_indices = np.sort(list(set(continuum_indices).difference(np.sort(exclude_indices))))\n",
    "        \n",
    "    # See if there are any regions we should always include\n",
    "    if include is not None and len(include) > 0:\n",
    "        include_indices = []\n",
    "        \n",
    "        if isinstance(include[0], float) and len(include) == 2:\n",
    "            # Only two floats given, so we can only have one region to include\n",
    "            include_indices.extend(range(*np.searchsorted(disp, include)))\n",
    "            \n",
    "        else:\n",
    "            # Multiple regions provided\n",
    "            for include_region in include:\n",
    "                include_indices.extend(range(*np.searchsorted(disp, include_region)))\n",
    "    \n",
    "\n",
    "    # We should exclude non-finite numbers from the fit\n",
    "    non_finite_indices = np.where(~np.isfinite(flux))[0]\n",
    "    continuum_indices = np.sort(list(set(continuum_indices).difference(non_finite_indices)))\n",
    "\n",
    "    # We should also exclude zero or negative flux points from the fit\n",
    "    zero_flux_indices = np.where(0 >= flux)[0]\n",
    "    continuum_indices = np.sort(list(set(continuum_indices).difference(zero_flux_indices)))\n",
    "\n",
    "    original_continuum_indices = continuum_indices.copy()\n",
    "\n",
    "    if knot_spacing is None or knot_spacing == 0:\n",
    "        knots = []\n",
    "\n",
    "    else:\n",
    "        knot_spacing = abs(knot_spacing)\n",
    "        \n",
    "        end_spacing = ((disp[-1] - disp[0]) % knot_spacing) /2.\n",
    "    \n",
    "        if knot_spacing/2. > end_spacing: end_spacing += knot_spacing/2.\n",
    "            \n",
    "        knots = np.arange(disp[0] + end_spacing, disp[-1] - end_spacing + knot_spacing, knot_spacing)\n",
    "        if len(knots) > 0 and knots[-1] > disp[continuum_indices][-1]:\n",
    "            knots = knots[:knots.searchsorted(disp[continuum_indices][-1])]\n",
    "            \n",
    "        if len(knots) > 0 and knots[0] < disp[continuum_indices][0]:\n",
    "            knots = knots[knots.searchsorted(disp[continuum_indices][0]):]\n",
    "\n",
    "    for iteration in xrange(max_iterations):\n",
    "        \n",
    "        splrep_disp = disp[continuum_indices]\n",
    "        splrep_flux = flux[continuum_indices]\n",
    "\n",
    "        splrep_weights = np.ones(len(splrep_disp))\n",
    "\n",
    "        # We need to add in additional points at the last minute here\n",
    "        if additional_points is not None and len(additional_points) > 0:\n",
    "\n",
    "            for point, flux, weight in additional_points:\n",
    "\n",
    "                # Get the index of the fit\n",
    "                insert_index = int(np.searchsorted(splrep_disp, point))\n",
    "                \n",
    "                # Insert the values\n",
    "                splrep_disp = np.insert(splrep_disp, insert_index, point)\n",
    "                splrep_flux = np.insert(splrep_flux, insert_index, flux)\n",
    "                splrep_weights = np.insert(splrep_weights, insert_index, weight)\n",
    "\n",
    "        if function == 'spline':\n",
    "            order = 5 if order > 5 else order\n",
    "            tck = interpolate.splrep(splrep_disp, splrep_flux,\n",
    "                k=order, task=-1, t=knots, w=splrep_weights)\n",
    "\n",
    "            continuum = interpolate.splev(disp, tck)\n",
    "\n",
    "        elif function in (\"poly\", \"polynomial\"):\n",
    "        \n",
    "            p = poly1d(polyfit(splrep_disp, splrep_flux, order))\n",
    "            continuum = p(disp)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown function type: only spline or poly available (%s given)\" % (function, ))\n",
    "        \n",
    "        difference = continuum - flux\n",
    "        sigma_difference = difference / np.std(difference[np.isfinite(flux)])\n",
    "\n",
    "        # Clipping\n",
    "        upper_exclude = np.where(sigma_difference > sigma_clip[1])[0]\n",
    "        lower_exclude = np.where(sigma_difference < -sigma_clip[0])[0]\n",
    "        \n",
    "        exclude_indices = list(upper_exclude)\n",
    "        exclude_indices.extend(lower_exclude)\n",
    "        exclude_indices = np.array(exclude_indices)\n",
    "        \n",
    "        if len(exclude_indices) is 0: break\n",
    "        \n",
    "        exclusions.extend(exclude_indices)\n",
    "        \n",
    "        # Before excluding anything, we must check to see if there are regions\n",
    "        # which we should never exclude\n",
    "        if include is not None:\n",
    "            exclude_indices = set(exclude_indices).difference(include_indices)\n",
    "        \n",
    "        # Remove regions that have been excluded\n",
    "        continuum_indices = np.sort(list(set(continuum_indices).difference(exclude_indices)))\n",
    "    \n",
    "    # Snip the edges based on exclude regions\n",
    "    if exclude is not None and len(exclude) > 0:\n",
    "\n",
    "        # If there are exclusion regions that extend past the left_index/right_index,\n",
    "        # then we will need to adjust left_index/right_index accordingly\n",
    "\n",
    "        left_index = np.max([left_index, np.min(original_continuum_indices)])\n",
    "        right_index = np.min([right_index, np.max(original_continuum_indices)])\n",
    "        \n",
    "\n",
    "    # Apply flux scaling\n",
    "    continuum *= scale\n",
    "    return disp, flux/continuum\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
