{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import importlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataset = 'HD1581'\n",
    "dataset = 'HD285507'\n",
    "# dataset = 'rhoTuc'\n",
    "\n",
    "cam = 0\n",
    "\n",
    "os.chdir(\"/Users/Carlos/Documents/HERMES/reductions/new_start_6.5/\"+dataset+\"/herpy_out/\"+str(cam))\n",
    "\n",
    "if dataset=='HD1581':\n",
    "    \n",
    "    Th1 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "    Th2 = np.loadtxt(\"ThXe_1_1.txt\")\n",
    "    Th3 = np.loadtxt(\"ThXe_1_2.txt\")\n",
    "    Th4 = np.loadtxt(\"ThXe_1_3.txt\")\n",
    "    Th5 = np.loadtxt(\"ThXe_2_1.txt\")\n",
    "    Th6 = np.loadtxt(\"ThXe_2_2.txt\")\n",
    "    Th7 = np.loadtxt(\"ThXe_2_3.txt\")\n",
    "    Th8 = np.loadtxt(\"ThXe_3_1.txt\")\n",
    "    Th9 = np.loadtxt(\"ThXe_3_2.txt\")\n",
    "    Th10 = np.loadtxt(\"ThXe_3_3.txt\")\n",
    "    Th11 = np.loadtxt(\"ThXe_3_4.txt\")\n",
    "    Th12 = np.loadtxt(\"ThXe_3_5.txt\")\n",
    "    Th13 = np.loadtxt(\"ThXe_4_1.txt\")\n",
    "    Th14 = np.loadtxt(\"ThXe_4_2.txt\")\n",
    "    Th15 = np.loadtxt(\"ThXe_4_3.txt\")\n",
    "\n",
    "    ThCube = np.array([Th1, Th2, Th3, Th4, Th5, Th6, Th7, Th8, Th9, Th10, Th11, Th12, Th13, Th14, Th15])\n",
    "\n",
    "    baryVels = np.load(\"/Users/Carlos/Documents/HERMES/reductions/6.5/HD1581/npy/baryVels.npy\")\n",
    "\n",
    "    Days = np.load(\"/Users/Carlos/Documents/HERMES/reductions/6.5/HD1581/npy/JDs.npy\")\n",
    "\n",
    "elif dataset=='HD285507':\n",
    " \n",
    "    Th1 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "    Th2 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "    Th3 = np.loadtxt(\"ThXe_0_3.txt\")\n",
    "    Th4 = np.loadtxt(\"ThXe_1_1.txt\")\n",
    "    Th5 = np.loadtxt(\"ThXe_1_2.txt\")\n",
    "    Th6 = np.loadtxt(\"ThXe_1_3.txt\")\n",
    "    Th7 = np.loadtxt(\"ThXe_2_1.txt\")\n",
    "    Th8 = np.loadtxt(\"ThXe_2_2.txt\")\n",
    "    Th9 = np.loadtxt(\"ThXe_2_3.txt\")\n",
    "    Th10 = np.loadtxt(\"ThXe_3_1.txt\")\n",
    "    Th11 = np.loadtxt(\"ThXe_3_2.txt\")\n",
    "    Th12 = np.loadtxt(\"ThXe_3_3.txt\")\n",
    "    Th13 = np.loadtxt(\"ThXe_4_1.txt\")\n",
    "    Th14 = np.loadtxt(\"ThXe_4_2.txt\")\n",
    "    Th15 = np.loadtxt(\"ThXe_4_3.txt\")\n",
    "    \n",
    "    ThCube = np.array([Th1, Th2, Th3, Th4, Th5, Th6, Th7, Th8, Th9, Th10, Th11, Th12, Th13, Th14, Th15])\n",
    "\n",
    "    baryVels = np.load(\"/Users/Carlos/Documents/HERMES/reductions/6.5/HD285507/npy/baryVels.npy\")\n",
    "\n",
    "    Days = np.load(\"/Users/Carlos/Documents/HERMES/reductions/6.5/HD285507/npy/MJDs.npy\")\n",
    "\n",
    "elif dataset=='rhoTuc':\n",
    "\n",
    "    Th1 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "    Th2 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "    Th3 = np.loadtxt(\"ThXe_0_3.txt\")\n",
    "    Th4 = np.loadtxt(\"ThXe_0_4.txt\")\n",
    "    Th5 = np.loadtxt(\"ThXe_0_5.txt\")\n",
    "    Th6 = np.loadtxt(\"ThXe_0_6.txt\")\n",
    "    Th7 = np.loadtxt(\"ThXe_0_7.txt\")\n",
    "    Th8 = np.loadtxt(\"ThXe_0_8.txt\")\n",
    "    Th9 = np.loadtxt(\"ThXe_1_1.txt\")\n",
    "    Th10 = np.loadtxt(\"ThXe_1_2.txt\")\n",
    "    Th11 = np.loadtxt(\"ThXe_1_3.txt\")\n",
    "    Th12 = np.loadtxt(\"ThXe_2_1.txt\")\n",
    "    Th13 = np.loadtxt(\"ThXe_3_1.txt\")\n",
    "    Th14 = np.loadtxt(\"ThXe_3_2.txt\")\n",
    "    Th15 = np.loadtxt(\"ThXe_3_3.txt\")\n",
    "    Th16 = np.loadtxt(\"ThXe_4_1.txt\")\n",
    "    Th17 = np.loadtxt(\"ThXe_4_2.txt\")\n",
    "    Th18 = np.loadtxt(\"ThXe_5_1.txt\")\n",
    "    Th19 = np.loadtxt(\"ThXe_5_2.txt\")\n",
    "    Th20 = np.loadtxt(\"ThXe_5_3.txt\")\n",
    "    Th21 = np.loadtxt(\"ThXe_6_1.txt\")\n",
    "    Th22 = np.loadtxt(\"ThXe_6_2.txt\")\n",
    "    Th23 = np.loadtxt(\"ThXe_6_3.txt\")\n",
    "    Th24 = np.loadtxt(\"ThXe_7_1.txt\")\n",
    "    \n",
    "    Days = np.load(\"/Users/Carlos/Documents/HERMES/reductions/6.5/rhoTuc/npy/MJDs.npy\")\n",
    "\n",
    "    baryVels = np.load(\"/Users/Carlos/Documents/HERMES/reductions/6.5/rhoTuc/npy/baryVels.npy\")\n",
    "    \n",
    "    ThCube = np.array([Th1, Th2, Th3, Th4, Th5, Th6, Th7, Th8, Th9, Th10, Th11, Th12, Th13, Th14, Th15,\n",
    "                       Th16, Th17, Th18, Th19, Th20, Th21, Th22, Th23, Th24])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(np.exp(logAxis),Th3)\n",
    "# plt.plot(Th8)\n",
    "# plt.plot(Th9)\n",
    "# plt.plot(Th10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The the maximum comon wl range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#added the +0.000001 because it flops on the interpolation otherwise ( the 12th decimal place!!!)roundup...\n",
    "wlRange = np.array([np.max(ThCube[:,0,0])+0.00001, np.min(ThCube[:,-1,0])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Log axis of the common range (logged) \n",
    "#step size (Duncan's suggestion) is about 1500m/s (i.e. x2 upscaled)\n",
    "logAxis = np.arange(np.log(wlRange)[0], np.log(wlRange)[1], 5*10**(-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This holds the linearized interpolated flux for the 15 epoch\n",
    "#all share the same wl bins, that's why we don't need that dimension in the array (loosing the 3rd dimension)\n",
    "linLogThCube = np.zeros((ThCube.shape[0], logAxis.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We re-sample the flux based on the linearised log axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n"
     ]
    }
   ],
   "source": [
    "#commented to protect\n",
    "# for i in range(ThCube.shape[0]):\n",
    "#     f2 = interp1d(ThCube[i,:,0], ThCube[i,:,1], kind='cubic')\n",
    "#     linLogThCube[i,:] = f2(np.exp(logAxis))\n",
    "#     print i\n",
    "\n",
    "for i in range(ThCube.shape[0]):\n",
    "#     f2 = interp1d(ThCube[i,:,0], ThCube[i,:,1], kind='cubic')\n",
    "    linLogThCube[i,:] =  np.interp(np.exp(logAxis), ThCube[i,:,0], ThCube[i,:,1])\n",
    "    print i,\n",
    "    \n",
    "# this was used to check the out of range in the inerpolation\n",
    "#     print np.exp(logAxis)[0], np.exp(logAxis)[-1]\n",
    "#     print ThCube[i,:,0][0], ThCube[i,:,0][-1]\n",
    "#     print np.exp(logAxis)[0]-ThCube[i,:,0][0], np.exp(logAxis)[-1]-ThCube[i,:,0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"ThXe_HD1581\", linLogThCube)\n",
    "# linLogThCube = np.load(\"ThXe_HD1581.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print linLogThCube.shape\n",
    "# i = 0\n",
    "# newFlux = np.interp(np.exp(logAxis), ThCube[i,:,0], ThCube[i,:,1]) #     f2 = interp1d(ThCube[i,:,0], ThCube[i,:,1], kind='cubic')\n",
    "# plt.plot(newFlux)\n",
    "#     linLogThCube[i,:] = f2(np.exp(logAxis))\n",
    "\n",
    "# for i, flux in enumerate(linLogThCube):\n",
    "#     if ((i>6) and (i<12)):\n",
    "# #     if i==0:    \n",
    "#         plt.plot(flux)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(medFilt)\n",
    "# plt.plot(polyEval)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes linLogThCube and:\n",
    "#   - mean normalises\n",
    "#   - removes unwanted regions of spectra TODO\n",
    "#   - cleans cosmic rays\n",
    "#   - barycenter corrects TODO\n",
    "#   - flattens TODO\n",
    "#   - tappers TODO\n",
    "\n",
    "def clean_linLogThCube(linLogThCube, baryVels=[]):\n",
    "    from scipy.signal import medfilt\n",
    "    import pylab as plt\n",
    "    #4859\n",
    "    removeWl = [[4859,4863]]\n",
    "    \n",
    "\n",
    "    mean = np.mean(linLogThCube, axis=0)\n",
    "    mean /= np.mean(mean)\n",
    "    \n",
    "    cleanLinLogThCube = np.ones(linLogThCube.shape) *np.nan\n",
    "    for i in range(linLogThCube.shape[0]): #range (the amount of epochs)\n",
    "    # i=0\n",
    "        \n",
    "        thisSpec = remove_parts_by_wl(linLogThCube[i,:], logAxis, removeWl)\n",
    "\n",
    "        removeIdx  = find_comic_rays_idx(thisSpec,11)\n",
    "        if len(removeIdx)>0:\n",
    "            print 'Found cosmic rays',removeIdx\n",
    "            thisSpec = remove_parts_by_idx(thisSpec, removeIdx)\n",
    "\n",
    "        if i!=1000:\n",
    "            plt.plot(thisSpec)\n",
    "            plt.show()\n",
    "    \n",
    "        #baryShift\n",
    "#         pxShift = RV2px(1500, valStep)\n",
    "#         thisSpec = shift_spectrum(thisSpec, pxShift)\n",
    "\n",
    "        linLogThCube_n = (thisSpec/np.mean(thisSpec))\n",
    "\n",
    "        linLogThCube_m = linLogThCube_n - mean\n",
    "        medFilt = medfilt(linLogThCube_m,201)\n",
    "        coefs = np.polyfit(range(medFilt.shape[0]),medFilt, 5)\n",
    "        polyEval = np.polynomial.polynomial.polyval(range(medFilt.shape[0]),coefs[::-1])\n",
    "\n",
    "        linLogThCube_m_s =linLogThCube_n - polyEval\n",
    "        cleanLinLogThCube[i,:] = linLogThCube_m_s\n",
    "#         plt.plot(np.exp(logAxis), linLogThCube_m_s)\n",
    "#     plt.show()\n",
    "    return cleanLinLogThCube\n",
    "\n",
    "def RV2px(RV, valStep):\n",
    "    #RV in m/s\n",
    "    \n",
    "    px = RV/valStep\n",
    "       \n",
    "    return px\n",
    "\n",
    "\n",
    "def remove_parts_by_idx(inputSpec, removeIdx):\n",
    "    \n",
    "    inputSpecOut = inputSpec.copy()\n",
    "    \n",
    "    for i in removeIdx:\n",
    "        fromIdx = i[0]\n",
    "        toIdx = i[1]\n",
    "        fromVal = inputSpec[fromIdx]\n",
    "        toVal = inputSpec[toIdx]\n",
    "        \n",
    "        #make new section\n",
    "        inputSpecOut[np.arange(fromIdx,toIdx)] = np.interp(np.arange(fromIdx,toIdx), [fromIdx, toIdx], [fromVal, toVal])\n",
    "\n",
    "    return inputSpecOut\n",
    "        \n",
    "def remove_parts_by_wl(inputSpec, logAxis, removeWl):\n",
    "\n",
    "    removeIdx = []\n",
    "    for i in removeWl:\n",
    "        fromWl = i[0]\n",
    "        toWl = i[1]\n",
    "\n",
    "        fromDiff = np.abs(np.exp(logAxis)-fromWl)\n",
    "        toDiff = np.abs(np.exp(logAxis)-toWl)\n",
    "        fromIdx = np.where(np.min(fromDiff)==fromDiff)[0][0]\n",
    "        toIdx = np.where(np.min(toDiff)==toDiff)[0][0] \n",
    "        removeIdx.append([fromIdx, toIdx])\n",
    "    \n",
    "    inputSpecOut = remove_parts_by_idx(inputSpec, removeIdx)\n",
    "    \n",
    "    return inputSpecOut\n",
    "        \n",
    "        \n",
    "def find_comic_rays_idx(inputSpec, sigma):\n",
    "\n",
    "    removeIdx = []\n",
    "\n",
    "    fFlux = optimize.curve_fit(cubic, range(inputSpec.shape[0]), inputSpec, p0 = [1,1,1,1])\n",
    "    fittedCurve = cubic(np.arange(inputSpec.shape[0]), fFlux[0][0], fFlux[0][1], fFlux[0][2], fFlux[0][3])\n",
    "\n",
    "    inputSpecOut = inputSpec.copy()/fittedCurve -1\n",
    "    std = np.std(inputSpecOut-np.mean(inputSpecOut, axis=0))\n",
    "    sigmas = inputSpecOut/std\n",
    "    a = np.where(sigmas>sigma)\n",
    "    \n",
    "    prevPx = 0\n",
    "    fistPx = 0\n",
    "    lastPx = 0\n",
    "    for i in a:\n",
    "        if np.abs(prevPx-i)>1:\n",
    "            if prevPx>0:\n",
    "                removeIdx.append([fistPx-1, lastPx+1])\n",
    "            firstPx = i\n",
    "        lastPx = i\n",
    "        prevPx = i\n",
    "        \n",
    "    if len(a[0])>0:\n",
    "        removeIdx.append([fistPx-1, lastPx+1])\n",
    "\n",
    "    return removeIdx\n",
    "    \n",
    "def shift_spectrum(inputSpec, shift):\n",
    "    \n",
    "    initialX = np.arange(inputSpec.shape[0])\n",
    "    finalX = initialX + shift\n",
    "    print \"about to interp\"\n",
    "    \n",
    "#     f2 = interp1d(finalX, inputSpec, kind='cubic', bounds_error=False, fill_value=np.nan)\n",
    "    np.interp(initialX, finalX, inputSpec)\n",
    "    print \"Ax`fter interp, about to produce output\"\n",
    "    xMin, xMax =  np.min(initialX), np.max(initialX)\n",
    "    xFMin, xFMax =  np.min(finalX), np.max(finalX)\n",
    "    print xMin, xMax\n",
    "    print xFMin, xFMax\n",
    "#     inputSpecOut = f2(initialX)\n",
    "    print \"After produce output\"\n",
    "    \n",
    "#     return inputSpecOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 861,  862, 6674, 6675]),)\n",
      "Found cosmic rays [[860, 6676]]\n",
      "(array([ 861,  862, 6674, 6675]),)\n",
      "Found cosmic rays [[860, 6676]]\n",
      "(array([7273, 7274]),)\n",
      "Found cosmic rays [[7272, 7275]]\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n",
      "(array([4203, 4204, 4205, 4206, 7247, 7248, 7249, 7250, 7251, 7252, 7253]),)\n",
      "Found cosmic rays [[4202, 7254]]\n",
      "(array([1221, 7605]),)\n",
      "Found cosmic rays [[1220, 7606]]\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n",
      "(array([5150, 5151]),)\n",
      "Found cosmic rays [[5149, 5152]]\n",
      "(array([], dtype=int64),)\n",
      "(array([6246]),)\n",
      "Found cosmic rays [[6245, 6247]]\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n",
      "(array([1434, 2143]),)\n",
      "Found cosmic rays [[1433, 2144]]\n"
     ]
    }
   ],
   "source": [
    "cleanLinLogThCube = clean_linLogThCube(linLogThCube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "legs = np.arange(-(linLogThCube.shape[1]-1), linLogThCube.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import constants\n",
    "\n",
    "#the value of a pixel in m/s\n",
    "valStep = (np.exp(logAxis)[9]-np.exp(logAxis)[8])/np.exp(logAxis)[8]*constants.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is an axis of the 2*size of each spectrum in linLogThCube in km/s\n",
    "valAxis = valStep * legs /1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mask to slice the CCResult for gaussian fitting\n",
    "centPeak=0\n",
    "W = ((valAxis > (centPeak-25)) &  (valAxis < (centPeak+25)))\n",
    "# W = ((valAxis > -85) &  (valAxis < 85))\n",
    "# W = ((valAxis > -10) &  (valAxis < 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cubic(x,a,b,c,d):\n",
    "    '''\n",
    "    Cubic function\n",
    "    '''\n",
    "    return a*x**3+b*x**2+c*x+d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0048266598594\n",
      "0.189817172102\n",
      "0.161451049746\n",
      "0.190529451859\n",
      "0.181860921586\n",
      "0.209232903099\n",
      "0.206679631282\n",
      "-0.164214859826\n",
      "-0.168927980246\n",
      "-0.167004102467\n",
      "-0.190671280275\n",
      "-0.168487375794\n",
      "-0.217223417513\n",
      "-0.227293358639\n",
      "-0.235885996226\n"
     ]
    }
   ],
   "source": [
    "import pylab as plt\n",
    "from scipy import signal\n",
    "\n",
    "flux1 = cleanLinLogThCube[0,:] # the reference flux\n",
    "RVs = np.zeros((linLogThCube.shape[0]))\n",
    "\n",
    "for i in range(linLogThCube.shape[0]): #range (the amount of epochs)\n",
    "    flux2 = cleanLinLogThCube[i,:]\n",
    "\n",
    "#     plt.plot(flux1)\n",
    "#     plt.plot(flux2)\n",
    "#     plt.show()\n",
    "\n",
    "#     fFlux = optimize.curve_fit(cubic, range(flux1.shape[0]), flux1, p0 = [1,1,1,1])\n",
    "#     fittedCurve = cubic(np.arange(flux1.shape[0]), fFlux[0][0], fFlux[0][1], fFlux[0][2], fFlux[0][3])\n",
    "    cFlux1 = flux1 - np.mean(flux1)#/fittedCurve-1\n",
    "    cFlux1 = cFlux1 * signal.tukey(len(cFlux1), 0.2)\n",
    "\n",
    "#     fFlux = optimize.curve_fit(cubic, range(flux2.shape[0]), flux2, p0 = [1,1,1,1])\n",
    "#     fittedCurve = cubic(np.arange(flux2.shape[0]), fFlux[0][0], fFlux[0][1], fFlux[0][2], fFlux[0][3])\n",
    "    cFlux2 = flux2 - np.mean(flux2)# /fittedCurve-1\n",
    "    cFlux2 = cFlux2 * signal.tukey(len(cFlux2), 0.2)\n",
    "#     if i==1:\n",
    "#         plt.plot(cFlux1)\n",
    "#         plt.plot(cFlux2)\n",
    "#         plt.show()\n",
    "    weights = np.hstack((np.arange(1,flux1.shape[0]+1),np.arange(flux1.shape[0],1,-1))) \n",
    "    ccResult = np.correlate(cFlux1, cFlux2, \"full\")/weights\n",
    "#     if i==1:\n",
    "#         plt.plot(ccResult)\n",
    "#         plt.plot(weights)\n",
    "#         plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    centPeak = valAxis[np.where(ccResult==np.max(ccResult))[0]]\n",
    "    W = ((valAxis > (centPeak-25)) &  (valAxis < (centPeak+25)))\n",
    "\n",
    "    x = valAxis[W]\n",
    "    y = ccResult[W]\n",
    "    y /= np.max(y)\n",
    "#     plt.plot(valAxis,ccResult)\n",
    "#     plt.show()\n",
    "\n",
    "    plt.plot(x,y)\n",
    "    plt.plot(x,flexi_gaussian(x, centPeak, 10., 2., 1., 0))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    p,_ = fit_flexi_gaussian([float(centPeak), 10., 2. ,1., 0.], y, x )\n",
    "    \n",
    "    plt.plot(x,y)\n",
    "    plt.plot(x,flexi_gaussian(x, p[0], p[1], p[2], p[3], p[4]))\n",
    "    plt.show()\n",
    "    RVs[i]=p[0]\n",
    "    print p[0]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cameraNames = ['Blue', 'Green', 'Red', 'IR']\n",
    "colors = ['b.','g.','r.','c.']\n",
    "title = dataset + ' - ' +  cameraNames[cam] + ' Camera'\n",
    "\n",
    "plt.plot(Days,RVs*1000-baryVels, colors[cam])\n",
    "# plt.plot( Days,a[np.array([0,1,4,7,12])])\n",
    "\n",
    "plt.xlabel(\"MJD\")\n",
    "plt.ylabel(\"RV [m/s]\")\n",
    "\n",
    "\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def gaussian(x, mu, sig, ):\n",
    "    x = np.array(x)\n",
    "    return np.exp(-np.power(x - mu, 2.) / 2 / np.power(sig, 2.))\n",
    "\n",
    "\n",
    "def flexi_gaussian(x, mu, sig, power, a, d ):\n",
    "    x = np.array(x)\n",
    "    return a* np.exp(-np.power(np.abs((x - mu) * np.sqrt(2*np.log(2))/sig),power))+d\n",
    "\n",
    "def fit_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def fit_flexi_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_flexi_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def diff_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "\n",
    "    diff = gaussian(x_range, p[0],p[1]) - flux\n",
    "    return diff\n",
    "\n",
    "def diff_flexi_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "    weights = np.abs(np.gradient(flux)) * (flux+np.max(flux)*.1)\n",
    "    diff = (flexi_gaussian(x_range, p[0], p[1], p[2], p[3], p[4]) - flux)# *weights\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linLogThCube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as plt \n",
    "for i in range(linLogThCube.shape[0])[12:15]:\n",
    "#     plt.plot(logAxis,linLogThCube[i,:]/np.percentile(linLogThCube[i,:], 90))\n",
    "    plt.plot(logAxis,linLogThCube[i,:], label=str(i))\n",
    "plt.ylim(0, 2e5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pylab as plt \n",
    "for i in range(linLogThCube.shape[0])[11:15]:\n",
    "#     plt.plot(logAxis,linLogThCube[i,:]/np.percentile(linLogThCube[i,:], 90))\n",
    "    plt.plot(linLogThCube[i,:])\n",
    "plt.ylim(0, 2e5)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.load(\"/Users/Carlos/Documents/HERMES/reductions/6.5/HD285507/npy/baryVels.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ccs from star with +-25\n",
    "\n",
    "6.14367202446e-09\n",
    "-0.167474516269\n",
    "-0.185552242756\n",
    "-0.155002606345\n",
    "-0.104232244195\n",
    "-0.082658264156\n",
    "-0.0747539297579\n",
    "-0.747097050087\n",
    "-0.751346051391\n",
    "-0.744659958864\n",
    "-0.780037056979\n",
    "-0.752506902652\n",
    "-1.33462563626\n",
    "-1.33961076013\n",
    "-1.35122423503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -8.6101706948e-10\n",
    "    -0.0623372536655\n",
    "    -0.0623372438661\n",
    "    -0.0623372741398\n",
    "    -0.011374196462\n",
    "    -0.0113741614478\n",
    "    -0.0113741019891\n",
    "    -0.187732113388\n",
    "    -0.187732103719\n",
    "    -0.187732110375\n",
    "    -0.187732104556\n",
    "    -0.187732113388\n",
    "    -0.910444964683\n",
    "    -0.91044496166\n",
    "    -0.910444965535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to see the fitted gaussian\n",
    "plt.plot(x, y)\n",
    "plt.plot(x,flexi_gaussian(x, p[0], p[1], p[2], p[3], p[4]) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vh, vb = toolbox.baryvel(59289811.5) \n",
    "ra = (0+20/60+04/3600)*15\n",
    "dec = -64+52/60+30/3600\n",
    "-(vb[0]*np.cos(dec)*np.cos(ra) + vb[1]*np.cos(dec)*np.sin(ra) + vb[2]*np.sin(dec))*1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Days[0]+2400000+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toolbox.baryvel(59289811.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_flux(wavelength, flux, minWL=0, maxWL=0, xStep = 10**-5, medianRange = 0, flatten = True):\n",
    "    '''\n",
    "    Clean a 1D spectrum. \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    wavelength : int or None, optional\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : int or None, optional\n",
    "        Array of fluxes \n",
    "        \n",
    "    minWL : int, optional\n",
    "        Minimum walength value to return \n",
    "        \n",
    "    maxWL : int, optional\n",
    "        Maximum wavelength value to return \n",
    "        \n",
    "    xStep : float, optional\n",
    "        Coeficient to resample. Final array will be flux.shape[0]*xDef long. \n",
    "        \n",
    "    medianRange : int, optional\n",
    "        Number of pixels to median over. 0 will skip this step. Optional.\n",
    "\n",
    "    flatten : boolean, optional\n",
    "        Divides flux by a fitted 3rd ord polynomial if True. Optional.\n",
    "        \n",
    "    Returns\n",
    "    ----\n",
    "    wavelength : numpy, floats\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : numpy, floats\n",
    "        Array of fluxes \n",
    "        \n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    #median outliers\n",
    "    if medianRange>0:\n",
    "        fluxMed = signal.medfilt(flux,medianRange)\n",
    "        fluxDiff = abs(flux-fluxMed)\n",
    "#         fluxDiff = flux-fluxMed\n",
    "        fluxDiffStd = np.std(fluxDiff)\n",
    "        mask = fluxDiff> 3 * fluxDiffStd\n",
    "        flux[mask] = fluxMed[mask]\n",
    "\n",
    "\n",
    "#     if ((wavelength[-np.isnan(flux)].shape[0]>0) &  (flux[-np.isnan(flux)].shape[0]>0)):\n",
    "        \n",
    "    if flatten==True:#flatten curve by fitting a 3rd order poly\n",
    "        fFlux = optimize.curve_fit(cubic, range(flux.shape[0]), flux, p0 = [1,1,1,1])\n",
    "        print fFlux\n",
    "#         fittedCurve = cubic(range(flux.shape[0]), fFlux[0][0], fFlux[0][1], fFlux[0][2], fFlux[0][3])\n",
    "#         flux = flux/fittedCurve-1\n",
    "    else:\n",
    "        flux = flux/fluxMedian-1\n",
    "\n",
    "    #apply tukey\n",
    "    flux = flux * signal.tukey(len(flux), 0.2)\n",
    "\n",
    "    #resample\n",
    "#     wavelength,flux = resample_sp(wavelength, flux, minWL, maxWL, xStep)\n",
    "\n",
    "#     else: #if not enough data return NaNs\n",
    "#         wavelength = np.ones(4096)*np.nan\n",
    "#         flux = np.ones(4096)*np.nan\n",
    "        \n",
    "    return flux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the thxe arrays.\n",
    "#pack them into a cube [exp, px, [wl,flux]] [15,4095,2]\n",
    "#load the days (mayeb for use in interpolating the rv)\n",
    "\n",
    "# Th1 = np.loadtxt(\"ThXe_0.txt\")\n",
    "# Th2 = np.loadtxt(\"ThXe_1.txt\")\n",
    "# Th3 = np.loadtxt(\"ThXe_2.txt\")\n",
    "# Th4 = np.loadtxt(\"ThXe_3.txt\")\n",
    "# Th5 = np.loadtxt(\"ThXe_4.txt\")\n",
    "\n",
    "\n",
    "#HD285507\n",
    "# Th1 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "# Th2 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "# Th3 = np.loadtxt(\"ThXe_0_3.txt\")\n",
    "# Th4 = np.loadtxt(\"ThXe_1_1.txt\")\n",
    "# Th5 = np.loadtxt(\"ThXe_1_2.txt\")\n",
    "# Th6 = np.loadtxt(\"ThXe_1_3.txt\")\n",
    "# Th7 = np.loadtxt(\"ThXe_2_1.txt\")\n",
    "# Th8 = np.loadtxt(\"ThXe_2_2.txt\")\n",
    "# Th9 = np.loadtxt(\"ThXe_2_3.txt\")\n",
    "# Th10 = np.loadtxt(\"ThXe_3_1.txt\")\n",
    "# Th11 = np.loadtxt(\"ThXe_3_2.txt\")\n",
    "# Th12 = np.loadtxt(\"ThXe_3_3.txt\")\n",
    "# Th13 = np.loadtxt(\"ThXe_4_1.txt\")\n",
    "# Th14 = np.loadtxt(\"ThXe_4_2.txt\")\n",
    "# Th15 = np.loadtxt(\"ThXe_4_3.txt\")\n",
    "\n",
    "#rhoTuc\n",
    "# Th1 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "# Th2 = np.loadtxt(\"ThXe_0_1.txt\")\n",
    "# Th3 = np.loadtxt(\"ThXe_0_3.txt\")\n",
    "# Th4 = np.loadtxt(\"ThXe_0_4.txt\")\n",
    "# Th5 = np.loadtxt(\"ThXe_0_5.txt\")\n",
    "# Th6 = np.loadtxt(\"ThXe_0_6.txt\")\n",
    "# Th7 = np.loadtxt(\"ThXe_0_7.txt\")\n",
    "# Th8 = np.loadtxt(\"ThXe_0_8.txt\")\n",
    "# Th9 = np.loadtxt(\"ThXe_1_1.txt\")\n",
    "# Th10 = np.loadtxt(\"ThXe_1_2.txt\")\n",
    "# Th11 = np.loadtxt(\"ThXe_1_3.txt\")\n",
    "# Th12 = np.loadtxt(\"ThXe_2_1.txt\")\n",
    "# Th13 = np.loadtxt(\"ThXe_3_1.txt\")\n",
    "# Th14 = np.loadtxt(\"ThXe_3_2.txt\")\n",
    "# Th15 = np.loadtxt(\"ThXe_3_3.txt\")\n",
    "# Th16 = np.loadtxt(\"ThXe_4_1.txt\")\n",
    "# Th17 = np.loadtxt(\"ThXe_4_2.txt\")\n",
    "# Th18 = np.loadtxt(\"ThXe_5_1.txt\")\n",
    "# Th19 = np.loadtxt(\"ThXe_5_2.txt\")\n",
    "# Th20 = np.loadtxt(\"ThXe_5_3.txt\")\n",
    "# Th21 = np.loadtxt(\"ThXe_6_1.txt\")\n",
    "# Th22 = np.loadtxt(\"ThXe_6_2.txt\")\n",
    "# Th23 = np.loadtxt(\"ThXe_6_3.txt\")\n",
    "# Th24 = np.loadtxt(\"ThXe_7_1.txt\")\n",
    "\n",
    "\n",
    "\n",
    "# Th1 = np.loadtxt(\"ThXe_0_53.56889811.txt\")\n",
    "# Th2 = np.loadtxt(\"ThXe_1_41.56890804.txt\")\n",
    "# Th3 = np.loadtxt(\"ThXe_1_42.56890807.txt\")\n",
    "# Th4 = np.loadtxt(\"ThXe_1_43.56890809.txt\")\n",
    "# Th5 = np.loadtxt(\"ThXe_2_36.56891707.txt\")\n",
    "# Th6 = np.loadtxt(\"ThXe_2_37.56891709.txt\")\n",
    "# Th7 = np.loadtxt(\"ThXe_2_38.56891711.txt\")\n",
    "# Th8 = np.loadtxt(\"ThXe_3_58.56893765.txt\")\n",
    "# Th9 = np.loadtxt(\"ThXe_3_59.56893767.txt\")\n",
    "# Th10 = np.loadtxt(\"ThXe_3_60.56893768.txt\")\n",
    "# Th11 = np.loadtxt(\"ThXe_3_61.56893769.txt\")\n",
    "# Th12 = np.loadtxt(\"ThXe_3_62.56893771.txt\")\n",
    "# Th13 = np.loadtxt(\"ThXe_4_44.56894743.txt\")\n",
    "# Th14 = np.loadtxt(\"ThXe_4_45.56894745.txt\")\n",
    "# Th15 = np.loadtxt(\"ThXe_4_46.56894746.txt\")\n",
    "\n",
    "# Th1 = np.loadtxt(\"HD1581_0.txt\")\n",
    "# Th2 = np.loadtxt(\"HD1581_1.txt\")\n",
    "# Th3 = np.loadtxt(\"HD1581_2.txt\")\n",
    "# Th4 = np.loadtxt(\"HD1581_3.txt\")\n",
    "# Th5 = np.loadtxt(\"HD1581_4.txt\")\n",
    "\n",
    "# Th1 = np.loadtxt(\"HD1581_0_53.56889811.txt\")\n",
    "# Th2 = np.loadtxt(\"HD1581_1_41.56890804.txt\")\n",
    "# Th3 = np.loadtxt(\"HD1581_1_42.56890807.txt\")\n",
    "# Th4 = np.loadtxt(\"HD1581_1_43.56890809.txt\")\n",
    "# Th5 = np.loadtxt(\"HD1581_2_36.56891707.txt\")\n",
    "# Th6 = np.loadtxt(\"HD1581_2_37.56891709.txt\")\n",
    "# Th7 = np.loadtxt(\"HD1581_2_38.56891711.txt\")\n",
    "# Th8 = np.loadtxt(\"HD1581_3_58.56893765.txt\")\n",
    "# Th9 = np.loadtxt(\"HD1581_3_59.56893767.txt\")\n",
    "# Th10 = np.loadtxt(\"HD1581_3_60.56893768.txt\")\n",
    "# Th11 = np.loadtxt(\"HD1581_3_61.56893769.txt\")\n",
    "# Th12 = np.loadtxt(\"HD1581_3_62.56893771.txt\")\n",
    "# Th13 = np.loadtxt(\"HD1581_4_44.56894743.txt\")\n",
    "# Th14 = np.loadtxt(\"HD1581_4_45.56894745.txt\")\n",
    "# Th15 = np.loadtxt(\"HD1581_4_46.56894746.txt\")\n",
    "\n",
    "# version of 5 objs\n",
    "# Days = np.array([56889811,56890804,\n",
    "#                  56891711,56893771,56894743])\n",
    "# ThCube = np.array([Th1, Th2, Th3, Th4, Th5])\n",
    "\n",
    "\n",
    "# 15 objs\n",
    "Days = np.array([56889811,56890804,56890807,56890809,56891707,56891709,\n",
    "                 56891711,56893765,56893767,56893768,56893769,56893771,56894743,\n",
    "                 56894745,56894746])\n",
    "\n",
    "# ThCube = np.array([Th1, Th2, Th3, Th4, Th5, Th6, Th7, Th8, Th9, Th10, Th11, Th12, Th13, Th14, Th15])\n",
    "\n",
    "\n",
    "# 24 objs\n",
    "# Days = np.array([56889811,56890804,56890807,56890807,56890807,56890807,56890807,56890807,\n",
    "#                  56890809,56891707,56891709,\n",
    "#                  56891711,\n",
    "#                  56893765,56893767,56893768,\n",
    "#                  56893769,56893771,56893771,56893771,56893771,\n",
    "#                  56894743,56894745,56894746,56894746])\n",
    "\n",
    "# ThCube = np.array([Th1, Th2, Th3, Th4, Th5, Th6, Th7, Th8, Th9, Th10, Th11, Th12, Th13, Th14, Th15,\n",
    "#                    Th16, Th17, Th18, Th19, Th20, Th21, Th22, Th23, Th24])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
