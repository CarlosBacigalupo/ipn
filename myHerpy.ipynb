{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyfits as pf\n",
    "import pylab as plt\n",
    "from scipy import optimize\n",
    "from scipy.signal import medfilt, find_peaks_cwt\n",
    "from scipy.ndimage.filters import minimum_filter, maximum_filter, median_filter, convolve\n",
    "from scipy.ndimage.measurements import label\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd /Users/Carlos/Documents/HERMES/reductions/myherpy/HD1581/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "a[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def openFile(fileName): #TODO use gain to scale adus\n",
    "    '''\n",
    "    Open a HERMES fits file. Subtracts bias from overscan\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        fileName: input file name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        thisData : 2D array with the bias subtracted image of the first HDU.\n",
    "    \n",
    "    '''\n",
    "    thisFile = pf.open(fileName)\n",
    "\n",
    "    print thisFile[0].header['OBJECT']\n",
    "    \n",
    "    #Readout amplifier (inverse) gain (e-/ADU) \n",
    "    gain0_2000  = thisFile[0].header['RO_GAIN']\n",
    "    gain2000_4000  = thisFile[0].header['RO_GAIN1']\n",
    "\n",
    "    # Readout noise (electrons)\n",
    "    noise0_2000  = thisFile[0].header['RO_NOISE']\n",
    "    noise2000_4000  = thisFile[0].header['RO_NOIS1']\n",
    "\n",
    "    thisData = thisFile[0].data\n",
    "    \n",
    "    print 'raw array shape',thisData.shape\n",
    "    \n",
    "    bias0_2000 = np.median(thisData[3:2052,4099:-3])\n",
    "    bias2000_4000 = np.median(thisData[2059:-3,4099:-3])\n",
    "\n",
    "    thisData = thisData[:,:4095]\n",
    "\n",
    "    thisData[:2056] -= bias0_2000\n",
    "    thisData[2056:] -= bias2000_4000\n",
    "    \n",
    "    thisData[:2056] *= gain0_2000\n",
    "    thisData[2056:] *= gain2000_4000\n",
    "\n",
    "    print 'output array shape',thisData.shape\n",
    "    print\n",
    "\n",
    "    return thisData\n",
    "\n",
    "\n",
    "def fifthOrder(thisPoly, thisRange):\n",
    "    '''\n",
    "    Evaluates a 5th order polybomial at the specified range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        thisPoly: Array. 6 x polynomila coefficients\n",
    "\n",
    "        thisRange: Array. Range of values for the independent variable\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        result : polynomial evaluated over the range\n",
    "    \n",
    "    '''\n",
    "\n",
    "    result = thisPoly[0]*thisRange**5\n",
    "    result += thisPoly[1]*thisRange**4\n",
    "    result += thisPoly[2]*thisRange**3\n",
    "    result += thisPoly[3]*thisRange**2\n",
    "    result += thisPoly[4]*thisRange**1\n",
    "    result += thisPoly[5]*thisRange**0\n",
    "    \n",
    "    return result\n",
    "\n",
    "def find_vertical_shift(flat, arc):\n",
    "    '''\n",
    "    Calculates the vertical shift between the flat and the arc. \n",
    "    Needs to SUBTRACT the result of the gaussian fit to the traces \n",
    "    to make the 1st curve be like the second (i.e the traces be like the arc)\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flat: 2-D Array. Flat image\n",
    "\n",
    "    arc: 2-D Array. Arc Imag\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    shift : vertical pixel shift calculated\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    CCTotal = 0\n",
    "    for column in range(flat.shape[1]):\n",
    "        thisFlatCol = flat[:,column]\n",
    "        thisArcCol = arc[:,column]\n",
    "        CCCurve = np.correlate(thisFlatCol, thisArcCol, mode='full')\n",
    "        CCTotal += CCCurve\n",
    "\n",
    "    y = CCTotal[int(CCTotal.shape[0]/2.)+1-5:int(CCTotal.shape[0]/2.)+1+4]\n",
    "    y /=np.max(y)\n",
    "    x = np.arange(-4,5)\n",
    "    x_dense = np.linspace(-4,4)\n",
    "    p,_ = fit_gaussian([1,3.],y,x )\n",
    "    shift = p[0]\n",
    "    \n",
    "    return shift\n",
    "\n",
    "\n",
    "def sum_extract(fibre, tramlines, image, numPx):\n",
    "    '''\n",
    "    Extracts the flux from a given fibre from an image using the tramline map. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fibre: Fibre number to be extracted\n",
    "\n",
    "    tramlines: 2-D Array. Fibre centroids\n",
    "\n",
    "    image: 2-D Array. Image of the flux to be extracted\n",
    "\n",
    "    numPx: Number of pixels to extract on each side of the centroid\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    flux : Extracted flux\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    flux = np.ones(tramlines.shape[1])*np.nan\n",
    "#     flux1 = np.ones(tramlines.shape[1])*np.nan\n",
    "#     flux2 = np.ones(tramlines.shape[1])*np.nan\n",
    "    \n",
    "    for i,thisCentroid in enumerate(tramlines[fibre]):\n",
    "#         print thisCentroid\n",
    "        try:\n",
    "            fullPx = image[ int(thisCentroid)-numPx : int(thisCentroid)+numPx+1 , i]\n",
    "            flux[i] = np.sum(fullPx) - fullPx[0]*(thisCentroid%1) - fullPx[-1]*(1-thisCentroid%1)\n",
    "#         flux1[i] = fullPx[0]*(thisCentroid%1)\n",
    "#         flux2[i] = fullPx[-1]*(1-thisCentroid%1)\n",
    "        except:\n",
    "            print fibre, 'falied'\n",
    "            print thisCentroid, 'centroid found in index',i\n",
    "            break\n",
    "#             print fibre\n",
    "    return flux\n",
    "\n",
    "\n",
    "def nosum_extract_img(fibre, tramlines, image, numPx):\n",
    "    '''\n",
    "    Extracts the flux from a given fibre from an image using the tramline map. NO SUM \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fibre: Fibre number to be extracted\n",
    "\n",
    "    tramlines: 2-D Array. Fibre centroids\n",
    "\n",
    "    image: 2-D Array. Image of the flux to be extracted\n",
    "\n",
    "    numPx: Number of pixels to extract on each side of the centroid\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    flux : Extracted flux\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    flux = np.ones((numPx*2+1,tramlines.shape[1]))*np.nan\n",
    "#     flux1 = np.ones(tramlines.shape[1])*np.nan\n",
    "#     flux2 = np.ones(tramlines.shape[1])*np.nan\n",
    "    \n",
    "    for i,thisCentroid in enumerate(tramlines[fibre]):\n",
    "#         print thisCentroid\n",
    "#         for j, range(numPx*2+1);\n",
    "        try:\n",
    "            fullPx = image[ int(thisCentroid)-numPx : int(thisCentroid)+numPx+1 , i]\n",
    "            flux[:,i] = fullPx\n",
    "            flux[0,i] -= fullPx[0]*(thisCentroid%1)\n",
    "    #         print thisCentroid%1\n",
    "            flux[-1,i] -= fullPx[-1]*(1-thisCentroid%1)\n",
    "#             flux[i] = np.sum(fullPx) - fullPx[0]*(thisCentroid%1) - fullPx[-1]*(1-thisCentroid%1)\n",
    "#         flux1[i] = fullPx[0]*(thisCentroid%1)\n",
    "#         flux2[i] = fullPx[-1]*(1-thisCentroid%1)\n",
    "        except:\n",
    "            print fibre, 'falied'\n",
    "            print thisCentroid, 'centroid found in index',i\n",
    "#             break\n",
    "# #             print fibre\n",
    "    return flux\n",
    "\n",
    "def gaussian(x, mu, sig, ):\n",
    "    x = np.array(x)\n",
    "    return np.exp(-np.power(x - mu, 2.) / 2 / np.power(sig, 2.))\n",
    "\n",
    "\n",
    "def flexi_gaussian(x, mu, sig, power, a, d ):\n",
    "    x = np.array(x)\n",
    "    return a* np.exp(-np.power(np.abs((x - mu) * np.sqrt(2*np.log(2))/sig),power))+d\n",
    "\n",
    "def fit_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def fit_flexi_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_flexi_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def diff_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "\n",
    "    diff = gaussian(x_range, p[0],p[1]) - flux\n",
    "    return diff\n",
    "\n",
    "def diff_flexi_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "    weights = np.abs(np.gradient(flux)) * (flux+np.max(flux)*.1)\n",
    "    diff = (flexi_gaussian(x_range, p[0], p[1], p[2], p[3], p[4]) - flux)# *weights\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisFile = pf.open('0_20aug/1/20aug10034.fits')\n",
    "thisFile[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flatFileName = '0_20aug/1/20aug10034.fits'\n",
    "arcFileName = '0_20aug/1/20aug10052.fits'\n",
    "objFileName = '0_20aug/1/20aug10053.fits'\n",
    "\n",
    "# flatFileName = '1_21aug/1/21aug10047.fits'\n",
    "# arcFileName = '1_21aug/1/21aug10046.fits'\n",
    "# objFileName = '1_21aug/1/21aug10041.fits'\n",
    "# objFileName = '1_21aug/1/21aug10042.fits'\n",
    "# objFileName = '1_21aug/1/21aug10043.fits'\n",
    "\n",
    "# flatFileName = '2_22aug/1/22aug10032.fits'\n",
    "# arcFileName = '2_22aug/1/22aug10031.fits'\n",
    "# objFileName = '2_22aug/1/22aug10036.fits'\n",
    "# objFileName = '2_22aug/1/22aug10037.fits'\n",
    "# objFileName = '2_22aug/1/22aug10038.fits'\n",
    "\n",
    "# flatFileName = '3_24aug/1/24aug10053.fits'\n",
    "# arcFileName = '3_24aug/1/24aug10054.fits'\n",
    "# objFileName = '3_24aug/1/24aug10058.fits'\n",
    "# objFileName = '3_24aug/1/24aug10059.fits'\n",
    "# objFileName = '3_24aug/1/24aug10060.fits'\n",
    "# objFileName = '3_24aug/1/24aug10061.fits'\n",
    "# objFileName = '3_24aug/1/24aug10062.fits'\n",
    "\n",
    "# flatFileName = '4_25aug/1/25aug10039.fits'\n",
    "# arcFileName = '4_25aug/1/25aug10043.fits'\n",
    "# objFileName = '4_25aug/1/25aug10044.fits'\n",
    "# objFileName = '4_25aug/1/25aug10045.fits'\n",
    "# objFileName = '4_25aug/1/25aug10046.fits'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat = openFile(flatFileName)\n",
    "arc =  openFile(arcFileName)\n",
    "obj =  openFile(objFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stuff to check the open files\n",
    "# import pylab as plt\n",
    "# plt.imshow(obj)\n",
    "# plt.plot(np.sum(obj, axis=1))\n",
    "# # plt.plot(np.sum(obj[2000:2100, :200], axis=1))\n",
    "# # plt.plot(np.sum(obj[2000:2100, 3000:3200], axis=1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial flat handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_mf = medfilt(flat, [3,9])\n",
    "flat_1d = np.sum(flat_mf,axis =0) \n",
    "flat_per = np.percentile(flat_1d, 90)\n",
    "flat_1d_norm = flat_1d/flat_per\n",
    "\n",
    "flat_flat = flat_mf / flat_1d_norm[None,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#THis is an example of what the singleMin line does\n",
    "# singleCol = flat_flat[:,10]\n",
    "# a = minimum_filter(singleCol,15)\n",
    "# b = convolve(a, [.2,.2,.2,.2,.2])\n",
    "# plt.plot(singleCol)\n",
    "# plt.plot(a)\n",
    "# plt.plot(b)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example of singleMax\n",
    "# singleMin = singleCol - convolve(minimum_filter(singleCol,15),[.2,.2,.2,.2,.2])\n",
    "# singleMax = convolve(maximum_filter(singleMin,15),[.2,.2,.2,.2,.2])\n",
    "# plt.plot(singleMin)    \n",
    "# plt.plot(singleMax)\n",
    "# plt.plot(fixer)\n",
    "# singleColFlat = singleMin/singleMax\n",
    "# plt.plot(singleColFlat)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#turn to binary\n",
    "for i in range(flat_flat.shape[1]):\n",
    "    \n",
    "    singleCol = flat_flat[:,i] #isolates a single column\n",
    "    \n",
    "    #removes a somoothen (convolved) array of the minima in a 15px range from singleCol\n",
    "    singleMin = singleCol - convolve(minimum_filter(singleCol,15),[.2,.2,.2,.2,.2])\n",
    "    \n",
    "    #smoothen (convolved) maxima in a 15px range\n",
    "    singleMax = convolve(maximum_filter(singleMin,15),[.2,.2,.2,.2,.2])\n",
    "    \n",
    "    #removes the gaps between maxima (where lower than 1/2 of the smoothered (fixer) version)\n",
    "    fixer = convolve(singleMax, np.ones(200)/200)\n",
    "    singleMax2 = singleMax.copy()\n",
    "    singleMax[singleMax<fixer*.5] = fixer[singleMax<fixer*.5]*.5\n",
    "    \n",
    "    #ratio btween max and min\n",
    "    singleColFlat = singleMin/singleMax\n",
    "\n",
    "    #Set cut-off value (0.3)\n",
    "    singleColFlat[singleColFlat>.3] = 1\n",
    "    singleColFlat[singleColFlat<.3] = 0\n",
    "    \n",
    "    #write back to flat\n",
    "    flat_flat[:,i] = singleColFlat\n",
    "\n",
    "    \n",
    "#flat_flat becames a single-bit mape of the tram regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find goups of 1s and 0s in flat_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#looks for groups (label features) in flat_flat using a 3by3 stamp. \n",
    "#out_array is the list of features, one int per group, same shape than flat_flat\n",
    "# n is the number of groups (labels) \n",
    "out_array, n = label(flat_flat, np.ones((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the centroids array. (nFibres, 4095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create centroid array\n",
    "fibre_centroids = np.ones((n,out_array.shape[1]))*np.nan\n",
    "for col in range(out_array.shape[1]):\n",
    "    testCol = out_array[:,col]\n",
    "    for fibre in range(n):\n",
    "        fibre_centroids[fibre,col] = np.average(np.where(testCol==fibre+1)[0])\n",
    "#         print np.average(np.where(testCol==fibre+1)[0])\n",
    "#         print fibre_centroids\n",
    "#         if np.sum(np.isnan(fibre_centroids[fibre,col]))>0:\n",
    "#             print 'Found nan',np.where(testCol==fibre+1)[0], fibre+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fibrePolys.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 5th deg polynomials to map out the centroids. (nFibres, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fibrePolys = np.ones((fibre_centroids.shape[0],6))*np.nan\n",
    "for y,fibre in enumerate(fibre_centroids):\n",
    "    fibrePolys[y,:] = np.polyfit(range(fibre.shape[0]),fibre,5)\n",
    "#     if np.sum(np.isnan(fibrePolys[y,:]))>0:\n",
    "#         print 'Found nan in fibre',y\n",
    "#         print 'Fibre values',fibre\n",
    "#         print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create tramlines from 5th deg polynomials (nFibres, 4095)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create tramlines\n",
    "tramlines = np.ones(fibre_centroids.shape)*np.nan\n",
    "thisRange = np.arange(fibre_centroids.shape[1])\n",
    "for i,thisPoly in enumerate(fibrePolys):\n",
    "    tramlines[i] = fifthOrder(thisPoly,thisRange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(out_array, cmap=\"gray\")\n",
    "# a = out_array\n",
    "# a[out_array==1]=100\n",
    "# plt.imshow(a)\n",
    "# for i in range(tramlines.shape[0]):\n",
    "plt.plot(tramlines[170,:])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arc Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Vertical Shift between flat and arc (shift flat to be like arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shift = find_vertical_shift(flat, arc) #result to be subtracted to the tramlines (1st array in the CC...)\n",
    "tramlines_shifted = tramlines - shift\n",
    " \n",
    "shift = find_vertical_shift(flat, obj) #result to be subtracted to the tramlines (1st array in the CC...)\n",
    "tramlines_shifted_obj = tramlines - shift\n",
    " \n",
    "#why this is important for the arc but not for the obj?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(flat_sub_n, cmap=\"gray\")\n",
    "# plt.plot(np.sum(arc_sub, axis=0))\n",
    "# for i in range(tramlines.shape[0]):\n",
    "i=171\n",
    "# plt.plot(tramlines[i,:], c='r')\n",
    "# plt.plot(tramlines_shifted[i,:], c='b')\n",
    "# plt.plot(tramlines_shifted_obj[i,:], c='g')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_sub = flat[np.min(np.floor(tramlines[171,:]))-3:np.max(np.floor(tramlines[171,:]))+5, :]\n",
    "arc_sub = arc[np.min(np.floor(tramlines[171,:]))-3:np.max(np.floor(tramlines[171,:]))+5, :]\n",
    "obj_sub = obj[np.min(np.floor(tramlines[171,:]))-3:np.max(np.floor(tramlines[171,:]))+5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(flat_sub.transpose())\n",
    "plt.plot(flat_sub[0,:])\n",
    "xp = np.linspace(0, flat_sub.shape[1], 4000)\n",
    "plt.plot(a(xp))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = interpolate.UnivariateSpline(range(flat_sub.shape[1]),flat_sub[0,:], s=1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a(range(flat_sub.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_sub_n = flat_sub/np.sum(flat_sub, axis=0)\n",
    "flat_sub_n,flat_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum Extract arc fluxes using shifted tram lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(9, tramlines_shifted.shape[1],tramlines_shifted.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO justify sum vs optimal extraction (Horne 1986, Robertson 92? )\n",
    "# extracted_arc = np.ones(tramlines_shifted.shape)*np.nan\n",
    "nPix = 4\n",
    "extracted_flat_img = np.ones((nPix*2+1, tramlines_shifted.shape[1],tramlines_shifted.shape[0]))*np.nan\n",
    "extracted_arc_img = np.ones((nPix*2+1, tramlines_shifted.shape[1],tramlines_shifted.shape[0]))*np.nan\n",
    "extracted_obj_img = np.ones((nPix*2+1, tramlines_shifted.shape[1],tramlines_shifted.shape[0]))*np.nan\n",
    "\n",
    "for fibre in range(tramlines_shifted.shape[0]):\n",
    "#     extracted_arc[fibre] = sum_extract(fibre,tramlines_shifted, arc, 4)\n",
    "    extracted_flat_img[:,:,fibre] = nosum_extract_img(fibre,tramlines_shifted, flat, nPix)\n",
    "    extracted_arc_img[:,:,fibre] = nosum_extract_img(fibre,tramlines_shifted, arc, nPix)\n",
    "    extracted_obj_img[:,:,fibre] = nosum_extract_img(fibre,tramlines_shifted, obj, nPix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Normalise the flat column by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracted_flat_img_flat = extracted_flat_img / np.sum(extracted_flat_img, axis=0)\n",
    "extracted_arc_img_norm = extracted_arc_img / extracted_flat_img_flat\n",
    "extracted_obj_img_norm = extracted_obj_img / extracted_flat_img_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(extracted_flat_img_flat[:,:,171].transpose())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(a[:,:100])\n",
    "plt.clim(-10,30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = nosum_extract_img(171,tramlines_shifted, arc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum extract object fluxes using shifted tramlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracted_obj = np.ones(tramlines_shifted.shape)*np.nan\n",
    "for fibre in range(tramlines_shifted.shape[0]):\n",
    "    extracted_obj[fibre] = sum_extract(fibre,tramlines_shifted, obj, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wlSolutions = []\n",
    "wlErrors = []\n",
    "wlPolys = []\n",
    "\n",
    "for thisFibre in range(extracted_arc.shape[0])[:5]:\n",
    "    print \n",
    "    print 'Fibre',thisFibre\n",
    "\n",
    "    halfCCRange = 15\n",
    "\n",
    "    masterArc = extracted_arc[thisFibre].copy()\n",
    "\n",
    "    lineTemplate = np.zeros(extracted_arc.shape[1])\n",
    "    lineList = np.loadtxt('linelist_blue_v2.txt')\n",
    "    lineTemplate[lineList[:,0].astype(int)]=1\n",
    "\n",
    "    CCCurve = np.correlate(masterArc, lineTemplate, mode='full')\n",
    "\n",
    "    y = CCCurve[int(CCCurve.shape[0]/2.)+1-halfCCRange:int(CCCurve.shape[0]/2.)+1+halfCCRange+1]\n",
    "    x = np.arange(-halfCCRange,halfCCRange+1)\n",
    "\n",
    "    maxIdx = np.where(y==np.max(y))[0][0]\n",
    "    thisShift = x[maxIdx]\n",
    "\n",
    "    print 'Shift', thisShift\n",
    "\n",
    "    #these 2 lines adjust the px value assigned in lineList based on the shift found above\n",
    "    adjLineList = lineList.copy()\n",
    "    adjLineList[:,0] += thisShift\n",
    "\n",
    "    for i, thisLineWl in enumerate(adjLineList):\n",
    "        print 'Searching for wl',thisLineWl[1],'in px',thisLineWl[0],\n",
    "        \n",
    "        #first run looks for max in master arc +-5 px from nominal corrected px position in adjLineList\n",
    "        firstSliceX = np.arange(thisLineWl[0]-5,thisLineWl[0]+6).astype(int)\n",
    "        firstSliceY = masterArc[firstSliceX]\n",
    "        maxIdx =  firstSliceX[np.where(firstSliceY==np.max(firstSliceY))[0][0]]\n",
    "        \n",
    "        #second run slices +-5 px from max\n",
    "        secondSliceX = np.arange(maxIdx-5,maxIdx+6).astype(int)\n",
    "        secondSliceY = masterArc[secondSliceX]      \n",
    "        \n",
    "        #gaussian fit on the slice found\n",
    "#         p,_ = fit_gaussian([maxIdx,1.], secondSliceY, secondSliceX )\n",
    "        p,_ = fit_flexi_gaussian([maxIdx,1., 2., np.max(secondSliceY), 0], secondSliceY, secondSliceX )\n",
    "        print 'Found',p\n",
    "        goodPxValue = p[0]\n",
    "        \n",
    "        #replace pixel value for gaussian fit result\n",
    "        adjLineList[i,0] = goodPxValue\n",
    "        \n",
    "#         x_dense = np.linspace(np.min(secondSliceX),np.max(secondSliceX))\n",
    "#         plt.plot(secondSliceX,secondSliceY)\n",
    "#         plt.plot(x_dense,flexi_gaussian(x_dense,p[0],p[1],p[2],p[3],p[4]))\n",
    "#         plt.title(goodPxValue)\n",
    "#         plt.show()\n",
    "\n",
    "    print adjLineList\n",
    "    \n",
    "    a = np.polyfit(adjLineList[:,0], adjLineList[:,1], 5)\n",
    "    x = fifthOrder(a, np.arange(4095))\n",
    "    err = fifthOrder(a, adjLineList[:,0]) - adjLineList[:,1]\n",
    "\n",
    "    wlPolys.append(a)\n",
    "    wlErrors.append(err)\n",
    "    wlSolutions.append(x)\n",
    "    \n",
    "wlPolys = np.array(wlPolys)\n",
    "wlErrors = np.array(wlErrors)\n",
    "wlSolutions = np.array(wlSolutions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.savetxt('HD1581_1_42.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_1_42.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_1_43.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_1_43.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_2_37.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_2_37.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_2_38.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_2_38.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_3_59.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_3_59.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_3_60.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_3_60.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_3_61.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_3_61.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_3_62.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_3_62.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_4.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_4.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "# np.savetxt('HD1581_4_45.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "# np.savetxt('ThXe_4_45.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n",
    "\n",
    "np.savetxt('HD1581_4_46.txt',np.vstack((wlSolutions[170], extracted_obj[170])).transpose())\n",
    "np.savetxt('ThXe_4_46.txt',np.vstack((wlSolutions[170], extracted_arc[170])).transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
