{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import myHerpyTools as MHT \n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "import glob\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reduction flags\n",
    "# ver = '6.5'\n",
    "booLog = False\n",
    "useBias = False\n",
    "copyFiles = False\n",
    "doReduce = True\n",
    "overwrite = False\n",
    "# idxFile = 'no_flat_no_bias.idx'\n",
    "startFrom = 0 #number of data set to begin with. 0 for beginning. Good for starting half way through if it cancelled\n",
    "baseFolder='/Users/Carlos/Documents/HERMES/reductions/new_start_6.5'\n",
    "\n",
    "# -1 for all\n",
    "reduceSet = -1\n",
    "reduceCam = np.array([0,1,3]) #don't have wl for 2(red)\n",
    "targetFolder =''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'HD1581'\n",
    "if 1==1: #len(sys.argv)>1:\n",
    "# if len(sys.argv)>1:\n",
    "#     dataset = sys.argv[1]\n",
    "    try:\n",
    "        thisDataset = importlib.import_module('data_sets.'+dataset)\n",
    "    except:\n",
    "        print 'Could not load dataset:',dataset         \n",
    "        sys.exit()\n",
    "    \n",
    "#     if len(sys.argv)>2:\n",
    "#         reduceSet = int(sys.argv[2])\n",
    "#         if len(sys.argv)>3:\n",
    "#             reduceCam = np.array([int(sys.argv[3])])\n",
    "            \n",
    "    #compose file prefixes from date_list\n",
    "    months = np.array(['', 'jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'])\n",
    "    d = np.array([s[4:] for s in thisDataset.date_list])\n",
    "    m = months[np.array([s[2:4] for s in thisDataset.date_list]).astype(int)]\n",
    "    filename_prfx = np.core.defchararray.add(d, m)\n",
    "    dataFolders = np.array([str(i)+'_'+s for i,s in enumerate(filename_prfx)])\n",
    "    \n",
    "    if reduceSet==-1: \n",
    "        reduceSet = dataFolders\n",
    "    else:\n",
    "        reduceSet = dataFolders[reduceSet]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0-0 169\n",
    "# 0-1 169\n",
    "# 0-2 169\n",
    "# 0-3 169\n",
    "# 0-3 169\n",
    "\n",
    "# 1-0 169\n",
    "# 1-1 169\n",
    "# 1-2 169\n",
    "# 1-3 169\n",
    "# 1-4 169\n",
    "\n",
    "# 2-0 215\n",
    "# 2-1 168\n",
    "# 2-2 168\n",
    "# 2-3 267\n",
    "# 2-4 169\n",
    "\n",
    "# 3-0 169\n",
    "# 3-1 169\n",
    "# 3-2 169\n",
    "# 3-3 188\n",
    "# 3-4 187\n",
    "\n",
    "goodFibres = np.ones((4,5)).astype(int)*169\n",
    "goodFibres[2,0] = 215\n",
    "goodFibres[2,1] = 168\n",
    "goodFibres[2,2] = 168\n",
    "goodFibres[2,3] = 267\n",
    "goodFibres[2,4] = 169\n",
    "\n",
    "goodFibres[3,0] = 169\n",
    "goodFibres[3,1] = 169\n",
    "goodFibres[3,2] = 169\n",
    "goodFibres[3,3] = 188\n",
    "goodFibres[3,4] = 187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Carlos/Documents/HERMES/reductions/new_start_6.5/HD1581/herpy_out/0\n",
      "Fibre 169 epoch 0\n",
      "Shift between template and this fibre arc 0\n",
      "Fibre 169 epoch 1\n",
      "Shift between template and this fibre arc 0\n",
      "Fibre 169 epoch 2\n",
      "Shift between template and this fibre arc 0\n",
      "Fibre 169 epoch 3\n",
      "Shift between template and this fibre arc 0\n",
      "Fibre 169 epoch 4\n",
      "Shift between template and this fibre arc 0\n",
      "169\n",
      "/Users/Carlos/Documents/HERMES/reductions/new_start_6.5/HD1581/herpy_out/0/0_arc_s1_20aug10052_cam1.npy read\n",
      "/Users/Carlos/Documents/HERMES/reductions/new_start_6.5/HD1581/herpy_out/0/0_obj1_s1_20aug10053_cam1.npy read\n",
      "wls shape (4096,)\n",
      "arc shape (390, 4096)\n",
      "obj shape (390, 4096)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fileIdx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c667490ca43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"obj shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m#         print np.vstack((wls[thisSetIdx], extracted_arc[thisFibreIdx]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mMHT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_flux_and_wls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_arc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthisFibreIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthisFibreIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthisSetIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileIdx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fileIdx' is not defined"
     ]
    }
   ],
   "source": [
    "reload(MHT)\n",
    "\n",
    "for thisCam in reduceCam:\n",
    "    \n",
    "    targetFolder = baseFolder + '/' + dataset + '/' + 'herpy_out' + '/' + str(thisCam)    \n",
    "    print targetFolder\n",
    "    \n",
    "#     #get the initial poly (wls wrt px) to find extended linelist\n",
    "#     initialWlsFileName = baseFolder + '/initial_wls_' + str(thisCam) + '.txt'\n",
    "#     initialPoly = MHT.make_poly_from_wls(initialWlsFileName)\n",
    "    \n",
    "    #this needs to be the fibre# loop....TODO\n",
    "    thisFibreIdx = goodFibres[thisCam,0]\n",
    "    finalLineListFileName = targetFolder + '/final_linelist_' + str(thisCam) + '_fib' +str(thisFibreIdx) + '.txt'\n",
    "    finalLineList = np.loadtxt(finalLineListFileName)\n",
    "\n",
    "\n",
    "    pxValuesEpoch = MHT.px_change_across_epochs(finalLineList, glob.glob1(targetFolder,\"*arc*\"), goodFibres[thisCam], targetFolder)\n",
    "\n",
    "    \n",
    "    \n",
    "    order = 3\n",
    "    epochPolyFit = []\n",
    "    epochDiffToFit = []\n",
    "    #the offsets of 1 epoch per loop\n",
    "    for i in range(pxValuesEpoch.shape[1]):\n",
    "\n",
    "        polyFilter = [(pxValuesEpoch[:,i]-pxValuesEpoch[:,0])<100]\n",
    "#         print pxValuesEpoch[:,i]\n",
    "        thisEpochPolyFit = np.polyfit(pxValuesEpoch[:,0],(pxValuesEpoch[:,i]-pxValuesEpoch[:,0]), order)\n",
    "#         thisEpochDiffToFit = np.polynomial.polynomial.polyval(pxValuesEpoch[:,0], thisEpochPolyFit[::-1])-(pxValuesEpoch[:,i]-pxValuesEpoch[:,0])#     plt.plot(pxValuesEpoch[:,0],pxValuesEpoch[:,i]-pxValuesEpoch[:,0], '.')\n",
    "        \n",
    "#         plt.plot(pxValuesEpoch[:,0],np.polynomial.polynomial.polyval(pxValuesEpoch[:,0], thisEpochPolyFit[::-1]))\n",
    "#         plt.plot(pxValuesEpoch[:,0],thisEpochDiffToFit, '.')\n",
    "#         plt.show()\n",
    "        \n",
    "#         print thisEpochPolyFit\n",
    "        epochPolyFit.append(thisEpochPolyFit)\n",
    "#         epochDiffToFit.append(thisEpochDiffToFit)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    initialWlsFileName = baseFolder + '/initial_wls_' + str(thisCam) + '.txt'\n",
    "    refWls = np.loadtxt(initialWlsFileName)\n",
    "\n",
    "#         print epochPolyFit\n",
    "    _,wls = MHT.make_WLS_from_polys(refWls, epochPolyFit)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#     print \"WLS\",wls\n",
    "    \n",
    "    #load extracted obj and arc and write with the new wls\n",
    "    for thisSetIdx, thisSet in enumerate([s + '/' + str(thisCam+1) for s in reduceSet]):\n",
    "\n",
    "        thisFibreIdx = goodFibres[thisCam, thisSetIdx]\n",
    "        print thisFibreIdx\n",
    "#         print thisSet \n",
    "        fileList = [filename_prfx[thisSetIdx] + str(thisCam+1) + str(name).zfill(4)+ '.fits' for name in thisDataset.ix_array[thisSetIdx]]\n",
    "\n",
    "        arcFileName=fileList[1] \n",
    "        pre = str(thisSetIdx) + '_' + 'arc_s1'\n",
    "        post = 'cam' + str(thisCam+1)\n",
    "        extracted_arc = MHT.read_NPY(arcFileName, pre, post, targetFolder)\n",
    "\n",
    "        for fileIdx, thisFileName in enumerate(fileList[2:]):\n",
    "            objFileName=thisFileName\n",
    "            pre = str(thisSetIdx) + '_obj' + str(fileIdx+1) + '_s1'\n",
    "            post = 'cam' + str(thisCam+1)\n",
    "            extracted_obj = MHT.read_NPY(objFileName, pre, post, targetFolder)\n",
    "\n",
    "            if thisCam==10:\n",
    "                for j in range(thisFibreIdx-10, thisFibreIdx+10):\n",
    "                    plt.plot(extracted_obj[j], label=str(j))\n",
    "                    plt.legend(loc=0)\n",
    "                title = 'Cam:', thisCam,'fib',thisFibreIdx, 'file', objFileName\n",
    "                plt.title(title)\n",
    "                plt.show()\n",
    "            print \"wls shape\", wls[thisSetIdx].shape\n",
    "            print \"arc shape\", extracted_arc.shape\n",
    "            print \"obj shape\", extracted_obj.shape\n",
    "    #         print np.vstack((wls[thisSetIdx], extracted_arc[thisFibreIdx]))\n",
    "            MHT.write_flux_and_wls(extracted_arc[thisFibreIdx], extracted_obj[thisFibreIdx], wls, thisSetIdx, fileIdx+1, targetFolder)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#     # get the flux from a single arc\n",
    "#     objectArc = extracted_arc[thisFibre].copy() \n",
    "    \n",
    "#     # Template to build model from.\n",
    "# #     lineListfFileName = '../linelist_blue_v3.txt'\n",
    "        \n",
    "#     #Create the model, etc\n",
    "#     thisPoly, thisSolution, thisErr = MHT.make_poly_model_err(objectArc, finalLineListFileName)\n",
    "\n",
    "#     for thisSetIdx, thisSet in enumerate([s + '/' + str(thisCam+1) for s in reduceSet]):\n",
    "        \n",
    "#         print thisSet \n",
    "#         fileList = [filename_prfx[thisSetIdx] + str(thisCam+1) + str(name).zfill(4)+ '.fits' for name in thisDataset.ix_array[thisSetIdx]]\n",
    "#         arcFileName=fileList[1] \n",
    "        \n",
    "#         if thisSetIdx==0:\n",
    "#             #open arc from epoch 0\n",
    "#             pre = str(thisSetIdx) + '_' + 'arc_s1'\n",
    "#             post = 'cam' + str(thisCam+1)\n",
    "\n",
    "#             extracted_arc = MHT.read_NPY(arcFileName, pre, post, targetFolder)\n",
    "\n",
    "#             #extend line list to all peaks\n",
    "#             #creates the new linelist. Wrong, but equally wrong\n",
    "#             extendedLinelist = MHT.extend_lineList(extracted_arc[thisFibreIdx],initialPoly)\n",
    "            \n",
    "            \n",
    "#             pxValuesEpoch = MHT.px_change_across_epochs(extendedLinelist, glob.glob1(targetFolder,\"*arc*\"), thisFibreIdx, targetFolder)\n",
    "            \n",
    "#             #Calculate differences to fit in order to filter\n",
    "#             order = 3\n",
    "#             epochPolyFit = []\n",
    "#             epochDiffToFit = []\n",
    "#             #the offsets of 1 epoch per loop\n",
    "#             for i in range(pxValuesEpoch.shape[1]):\n",
    "#                 polyFilter = [(pxValuesEpoch[:,i]-pxValuesEpoch[:,0])<10]\n",
    "#                 thisEpochPolyFit = np.polyfit(pxValuesEpoch[:,0][polyFilter],(pxValuesEpoch[:,i]-pxValuesEpoch[:,0])[polyFilter], order)\n",
    "#                 thisEpochDiffToFit = np.polynomial.polynomial.polyval(pxValuesEpoch[:,0], thisEpochPolyFit[::-1])-(pxValuesEpoch[:,i]-pxValuesEpoch[:,0])\n",
    "#                 epochPolyFit.append(thisEpochPolyFit)\n",
    "#                 epochDiffToFit.append(thisEpochDiffToFit)\n",
    "\n",
    "#             fibreFilter = np.sum(np.abs(epochDiffToFit)>0.4, axis=0)\n",
    "# #             print lineList_v2[-fibreFilter.astype(bool)].shape\n",
    "\n",
    "#             finalLineListFileName = targetFolder + '/final_linelist_' + str(thisCam) + '_fib' +str(thisFibreIdx) + '.txt'\n",
    "#             np.savetxt(finalLineListFileName, extendedLinelist[-fibreFilter.astype(bool)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
