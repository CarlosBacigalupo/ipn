{
 "metadata": {
  "name": "",
  "signature": "sha256:d19a6833ebca64e414a4f4ddcd027ab8e5fe7e9d3aad7fa7d6ddedeebbf1a47b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pickle\n",
      "import pylab as plt\n",
      "from scipy import interpolate, signal, optimize, constants, stats\n",
      "import pyfits as pf\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sys.path = ['', '/disks/ceres/makemake/aphot/kalumbe/reductions/NGC2477_1arc_6.2','/usr/local/yt-hg', '/home/science/staff/kalumbe/my-astro-lib', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/lib/pymodules/python2.7', '/usr/lib/python2.7/dist-packages/ubuntu-sso-client', '/usr/lib/python2.7/dist-packages/ubuntuone-client', '/usr/lib/python2.7/dist-packages/ubuntuone-couch', '/usr/lib/python2.7/dist-packages/ubuntuone-storage-protocol', '/usr/lib/python2.7/dist-packages/wx-2.8-gtk2-unicode']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_flux(wavelength, flux, thisCam, xDef = 1, medianRange = 0):\n",
      "    '''Clean a 1D spectrum. \n",
      "    \n",
      "    Parameters\n",
      "    ----\n",
      "    xDef : int or None, optional\n",
      "        Coeficient to resample. Final array will be flux.shape[0]*xDef long. \n",
      "        \n",
      "    medianRange : int, optional\n",
      "        Number of pixels to median over. 0 will skip this step. Optional.\n",
      "\n",
      "    '''\n",
      "        \n",
      "    #median outliers\n",
      "    if medianRange>0:\n",
      "        fluxMed = signal.medfilt(flux,medianRange)\n",
      "        w = np.where(abs((flux-fluxMed)/np.maximum(fluxMed,50)) > 0.4)\n",
      "        for ix in w[0]:\n",
      "            flux[ix] = fluxMed[ix]\n",
      "\n",
      "    if ((wavelength[-np.isnan(flux)].shape[0]>0) &  (flux[-np.isnan(flux)].shape[0]>0)):\n",
      "        \n",
      "        #flatten curve by fitting a 3rd order poly\n",
      "        fFlux = optimize.curve_fit(cubic, wavelength[-np.isnan(flux)], flux[-np.isnan(flux)], p0 = [1,1,1,1])\n",
      "        fittedCurve = cubic(wavelength, fFlux[0][0], fFlux[0][1], fFlux[0][2], fFlux[0][3])\n",
      "        flux = flux/fittedCurve-1\n",
      "        \n",
      "        #apply tukey\n",
      "        flux = flux * tukey(0.1, len(flux))\n",
      "\n",
      "        #resample\n",
      "        if (xDef>1):\n",
      "            fFlux = interpolate.interp1d(wavelength, flux) \n",
      "            wavelength = np.linspace(min(wavelength), max(wavelength),len(wavelength)*xDef)\n",
      "            flux = fFlux(wavelength)\n",
      "\n",
      "    else: #if not enough data return NaNs\n",
      "        if (xDef>1):\n",
      "            wavelength = np.linspace(min(wavelength), max(wavelength),len(wavelength)*xDef)\n",
      "            flux = np.ones(wavelength.shape[0])*np.nan\n",
      "        \n",
      "    return wavelength, flux\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cubic(x,a,b,c,d):\n",
      "    '''\n",
      "    Cubic function\n",
      "    '''\n",
      "    return a*x**3+b*x**2+c*x+d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tukey(alpha, N):\n",
      "    '''Creates a tukey function\n",
      "    \n",
      "    \n",
      "    Parameters\n",
      "    ----\n",
      "    alpha : float\n",
      "        Fraction of the pixels to fade in/out.\n",
      "        i.e. alpha=0.1 will use 10% of the pixels to go from 0 to 1. \n",
      "        \n",
      "    N : int\n",
      "        Totla number of pixels in the array.\n",
      "        \n",
      "        \n",
      "    Returns\n",
      "    ------\n",
      "\n",
      "    N-length array of floats from 0 to 1. \n",
      "    '''\n",
      "\n",
      "    \n",
      "    tukey = np.zeros(N)\n",
      "    for i in range(int(alpha*(N-1)/2)):\n",
      "        tukey[i] = 0.5*(1+np.cos(np.pi*(2*i/alpha/(N-1)-1)))\n",
      "    for i in range(int(alpha*(N-1)/2),int((N-1)*(1-alpha/2))):\n",
      "        tukey[i] = 1\n",
      "    for i in range(int((N-1)*(1-alpha/2)),int((N-1))):\n",
      "        tukey[i] = 0.5*(1+np.cos(np.pi*(2*i/alpha/(N-1)-2/alpha+1)))\n",
      "    \n",
      "    return tukey\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Find the common range of wl for all cameras\n",
      "def find_max_wl_range(thisStar):\n",
      "    for thisCam in thisStar.exposures.cameras:\n",
      "        if np.nansum(thisCam.wavelengths - thisCam.wavelengths[0,:])==0:\n",
      "            print 'WL aligned'\n",
      "        else:\n",
      "            print 'WL NOT aligned'\n",
      "\n",
      "        mask = np.isnan(thisCam.red_fluxes)\n",
      "        collapsed_mask = np.sum(mask, axis=0)==0\n",
      "        single_wl =  thisCam.wavelengths[0][collapsed_mask]\n",
      "        thisCam.wavelengths = np.reshape(np.tile(single_wl, thisCam.wavelengths.shape[0]), \n",
      "                         ((thisCam.wavelengths.shape[0], single_wl.shape[0])))\n",
      "        full_mask =  np.reshape(np.tile(collapsed_mask, thisCam.wavelengths.shape[0]), thisCam.red_fluxes.shape)\n",
      "        thisCam.red_fluxes =  np.reshape(thisCam.red_fluxes[full_mask], (thisCam.red_fluxes.shape[0], np.sum(collapsed_mask)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create cross correlation curves wrt epoch 0\n",
      "def RVs_CC_t0(thisStar, starIdx,  xDef = 1, CCReferenceSet = 0, printDetails=False, corrHWidth=10, medianRange = 0):\n",
      "\n",
      "#     validDates = np.all([np.nansum(thisCam.red_fluxes,1).astype(bool) for thisCam in thisStar.exposures.cameras],0)\n",
      "    print ''\n",
      "    for cam,thisCam in enumerate(thisStar.exposures.cameras):\n",
      "        RVs = []\n",
      "        sigmas = [] \n",
      "        Qs = []\n",
      "        SNRs = []\n",
      "\n",
      "        validDates = np.nansum(thisCam.red_fluxes,1).astype(bool)\n",
      "        \n",
      "        print 'Camera',cam\n",
      "        \n",
      "        if len(np.arange(len(validDates))[validDates])>0:\n",
      "            CCReferenceSet = np.arange(len(validDates))[validDates][0]\n",
      "        else:\n",
      "            CCReferenceSet = 0\n",
      "            \n",
      "            \n",
      "        lambda1, flux1 = clean_flux(thisCam.wavelengths[CCReferenceSet], thisCam.red_fluxes[CCReferenceSet], thisCam, medianRange=medianRange)\n",
      "        \n",
      "        plts = 0    \n",
      "        for epoch, JD in enumerate(thisStar.exposures.JDs):\n",
      "            print epoch,\n",
      "            lambda2, flux2 = clean_flux(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch], thisCam, medianRange=medianRange)\n",
      "\n",
      "            if validDates[epoch]==True:\n",
      "#                 CCCurve = signal.fftconvolve(flux1, flux2[::-1], mode='same')\n",
      "#                 if epoch <5:\n",
      "#                     plt.plot(flux1)\n",
      "#                     plt.plot(flux2)\n",
      "#                     plt.plot(CCCurve)\n",
      "#                     plt.show()\n",
      "                try:\n",
      "#                     print 'max_idx, len(CCCurve) =',np.where(CCCurve==max(CCCurve)), CCCurve.shape\n",
      "                    CCCurve = []\n",
      "                    CCCurve = signal.fftconvolve(flux1[-np.isnan(flux1)], flux2[-np.isnan(flux2)][::-1], mode='same')\n",
      "                    corrMax = np.where(CCCurve==max(CCCurve))[0][0]\n",
      "                    p_guess = [corrMax,corrHWidth]\n",
      "                    x_mask = np.arange(corrMax-corrHWidth, corrMax+corrHWidth+1)\n",
      "                    if max(x_mask)<len(CCCurve):\n",
      "        #                 try:\n",
      "        #                 print '4 params',p_guess, x_mask, np.sum(x_mask), CCCurve.shape\n",
      "                        p = fit_gaussian(p_guess, CCCurve[x_mask], np.arange(len(CCCurve))[x_mask])[0]\n",
      "                        if np.modf(CCCurve.shape[0]/2.0)[0]>1e-5:\n",
      "                            pixelShift = (p[0]-(CCCurve.shape[0]-1)/2.) #odd number of elements\n",
      "                        else:\n",
      "                            pixelShift = (p[0]-(CCCurve.shape[0])/2.) #even number of elements\n",
      "        #                 except:\n",
      "        #                     pixelShift = 0\n",
      "\n",
      "                        thisQ, thisdRV = QdRV(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch])\n",
      "\n",
      "                        mid_px = thisCam.wavelengths.shape[1]/2\n",
      "                        dWl = (thisCam.wavelengths[epoch,mid_px+1]-thisCam.wavelengths[epoch,mid_px]) / thisCam.wavelengths[epoch,mid_px]\n",
      "                        RV = dWl * pixelShift * constants.c \n",
      "                        print 'RV',RV\n",
      "\n",
      "                    else:\n",
      "                        R = 0\n",
      "                        thisQ = 0\n",
      "                        thisdRV = 0\n",
      "                        RV = 0\n",
      "                        print 'Invalid data point'\n",
      "\n",
      "                except Exception,e: \n",
      "                    print 'CC Error'\n",
      "                    print str(e)\n",
      "                    R = 0\n",
      "                    thisQ = 0\n",
      "                    thisdRV = 0\n",
      "                    RV = 0\n",
      "#                     if plts<5:\n",
      "#                         plts+=1\n",
      "#                         plt.plot(flux1)\n",
      "#                         plt.plot(flux2)\n",
      "#                         plt.plot(CCCurve)\n",
      "#                         plt.show()\n",
      "\n",
      "\n",
      "            else:\n",
      "#                 if i==CCReferenceSet:\n",
      "#                     print 'The CC reference set is not present. Can\\'t continue. Launch again with different reference set.'\n",
      "#                     sys.exit()\n",
      "                thisQ = 0\n",
      "                thisdRV = 0\n",
      "                RV = 0\n",
      "                print 'Invalid data point'\n",
      "\n",
      "            SNR = np.sqrt(stats.nanmedian(thisCam.red_fluxes[epoch]))\n",
      "            \n",
      "            if np.isnan(SNR)==True: \n",
      "                msg = 'NaN in SNR calculation sqrt(median(flux)).'\n",
      "                msg += str(np.sum(np.isnan(thisCam.red_fluxes[epoch])))\n",
      "                msg += '/'+str(thisCam.red_fluxes[epoch].shape[0])+' NaNs in flux.'\n",
      "                msg += ' Median_flux='+str(stats.nanmedian(thisCam.red_fluxes[epoch]))\n",
      "                print msg\n",
      "                comment(starIdx,epoch,cam,msg )\n",
      "                print 'SNR NaN',\n",
      "            print SNR\n",
      "\n",
      "            SNRs.append(SNR)\n",
      "            Qs.append(thisQ)\n",
      "            sigmas.append(thisdRV)\n",
      "            RVs.append(RV)\n",
      "\n",
      "\n",
      "                \n",
      "        thisCam.sigmas = np.array(sigmas)\n",
      "        thisCam.Qs = np.array(Qs)\n",
      "        thisCam.RVs = np.array(RVs)\n",
      "        thisCam.SNRs = np.array(SNRs)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def comment(star, epoch, cam, comment):\n",
      "    comments = []\n",
      "    try:\n",
      "        comments = np.load('npy/comments.npy')\n",
      "    except:\n",
      "        pass\n",
      "    \n",
      "    if comments==[]:\n",
      "        comments = np.zeros((1,),dtype=('i4,i4,i4,a100'))\n",
      "        comments[:] = [(star, epoch, cam, comment)]\n",
      "    else:\n",
      "        x = np.zeros((1,),dtype=('i4,i4,i4,a100'))\n",
      "        x[:] = [(star, epoch, cam, comment)]\n",
      "        comments = np.append(comments,x)\n",
      "    \n",
      "    np.save('npy/comments.npy',comments)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create cross correlation curves wrt epoch 0\n",
      "def single_RVs_CC_t0(thisStar, cam = 0, t = 0, corrHWidth =10, xDef = 1):\n",
      "\n",
      "        print 'Camera',cam, '- t0 wrt t',t\n",
      "        \n",
      "        thisCam = thisStar.exposures.cameras[cam]\n",
      "            \n",
      "        lambda1, flux1 = clean_flux(thisCam.wavelengths[0], thisCam.red_fluxes[0], thisCam, medianRange=5, xDef=xDef )\n",
      "        \n",
      "        lambda2, flux2 = clean_flux(thisCam.wavelengths[t], thisCam.red_fluxes[t], thisCam, medianRange=5, xDef=xDef)\n",
      "        CCCurve = []\n",
      "        CCCurve = signal.fftconvolve(flux1[-np.isnan(flux1)], flux2[-np.isnan(flux2)][::-1], mode='same')\n",
      "        corrMax = np.where(CCCurve==max(CCCurve))[0][0]\n",
      "        p_guess = [corrMax,corrHWidth]\n",
      "        x_mask = np.arange(corrMax-corrHWidth, corrMax+corrHWidth+1)\n",
      "        if max(x_mask)<len(CCCurve):\n",
      "            p = fit_gaussian(p_guess, CCCurve[x_mask], np.arange(len(CCCurve))[x_mask])[0]\n",
      "            if np.modf(CCCurve.shape[0]/2.0)[0]>1e-5:\n",
      "                pixelShift = (p[0]-(CCCurve.shape[0]-1)/2.) #odd number of elements\n",
      "            else:\n",
      "                pixelShift = (p[0]-(CCCurve.shape[0])/2.) #even number of elements\n",
      "\n",
      "\n",
      "            mid_px = thisCam.wavelengths.shape[1]/2\n",
      "            dWl = (thisCam.wavelengths[t,mid_px+1]-thisCam.wavelengths[t,mid_px]) / thisCam.wavelengths[t,mid_px]/xDef\n",
      "            RV = dWl * pixelShift * constants.c \n",
      "            print 'RV',RV\n",
      "        else:\n",
      "            p=RV=0\n",
      "            \n",
      "#         print 'HERE:'\n",
      "\n",
      "        return lambda1,flux1, lambda2,flux2, CCCurve, p, x_mask, RV \n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Bouchy functions\n",
      "def QdRV(Lambda, A0):\n",
      "\t\n",
      "\tW1 = W(Lambda, A0)\n",
      "\tQ_out = 0\n",
      "\tdRV = 0\n",
      "\tif np.sum(W1)>0:\n",
      "\t\tQ_out = Q(W1, A0)\n",
      "\t\tdRV = constants.c/np.sqrt(np.sum(W1))\n",
      "\t\n",
      "\treturn Q_out, dRV\n",
      "\n",
      "def Q(W, A0):\n",
      "\t'''\n",
      "    Calculates the Q factor of a spectrum from W(weight) and A0(flux) form Bouchy 2001.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    W : np.array\n",
      "        n x 1 np.array weight \n",
      "        \n",
      "    AO : np.array\n",
      "        n x 1 np.array with flux counts\n",
      "    \n",
      "            \n",
      "    Returns\n",
      "    -------\n",
      "    Q : float\n",
      "        Quality factor. \n",
      "        \n",
      "    Notes\n",
      "    -----\n",
      "\n",
      "    '''\n",
      "\tQ = 0\n",
      "\tif np.sum(A0[-np.isnan(A0)])>0:\n",
      "\t\tQ = np.sqrt(np.sum(W)/np.sum(A0[-np.isnan(A0)]))\n",
      "\t\n",
      "\treturn Q\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def W(Lambda, A0):\n",
      "\t'''\n",
      "    Calculates the weight function form Bouchy 2001.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    Lambda : np.array\n",
      "        n x 1 np.array with wavelength bins\n",
      "        \n",
      "    AO : np.array\n",
      "        n x 1 np.array with counts\n",
      "    \n",
      "            \n",
      "    Returns\n",
      "    -------\n",
      "    W : np.array\n",
      "        n x 1 np.array weights as a function of pixel.\n",
      "        \n",
      "    Notes\n",
      "    -----\n",
      "    Lambda and A0 should be equal length.\n",
      "    Uses:\n",
      "    W(i) = Lambda(i)**2 (dA0(i)/dLambda(i))**2 / A0(i)\n",
      "    Assumes noise free detector. (No sigma_D**2 term in the denominator).\n",
      "    dA0(i)/dLambda(i) simplified as discrete DeltaY/DeltaX.\n",
      "    '''\n",
      "\n",
      "\tdA0dL = np.zeros(len(A0)-1)\n",
      "\t\n",
      "\tfor i in range(len(A0)-1): #compute partial derivative\n",
      "\t\tdA0dL[i] = (A0[i+1] - A0[i])/(Lambda[i+1] - Lambda[i])\n",
      "\n",
      "\t#compute W (removing last term from Lambda and A0 as dA0dL has n-1 terms.\n",
      "\tW = Lambda[:-1]**2 * dA0dL**2 / A0[:-1]\n",
      "\t\n",
      "\t#clean nans\n",
      "\tW[np.isnan(W)] = 0\n",
      "\t\n",
      "\treturn W\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Fit gaussian in CCCurves\n",
      "def gaussian(x, mu, sig, ):\n",
      "    return np.exp(-np.power(x - mu, 2.) / 2 / np.power(sig, 2.))\n",
      "\n",
      "def fit_gaussian(p, flux, x_range):\n",
      "    a = optimize.leastsq(diff_gausian, p, args= [flux, x_range])\n",
      "    return a\n",
      "\n",
      "def diff_gausian(p, args):\n",
      "    \n",
      "    flux = args[0]\n",
      "    x_range = args[1]\n",
      "    diff = gaussian(x_range, p[0],p[1]) - flux/np.max(flux)\n",
      "    return diff\n",
      "\n",
      "def get_wavelength(wavelengths, pixel):\n",
      "    intPx = int(pixel)\n",
      "    fracPx = pixel - int(pixel)\n",
      "\n",
      "    return (wavelengths[intPx+1] - wavelengths[intPx])*fracPx + wavelengths[intPx]\n",
      "\n",
      "def extract_HERMES_wavelength(fileName):\n",
      "\n",
      "\ta = pf.open(fileName)\n",
      "\n",
      "\tCRVAL1 = a[0].header['CRVAL1'] # / Co-ordinate value of axis 1                    \n",
      "\tCDELT1 = a[0].header['CDELT1'] #  / Co-ordinate increment along axis 1             \n",
      "\tCRPIX1 = a[0].header['CRPIX1'] #  / Reference pixel along axis 1                   \n",
      "\t\n",
      "\t#Creates an array of offset wavelength from the referece px/wavelength\n",
      "\tLambda = CRVAL1 - (CRPIX1 - (np.arange(int(CRPIX1)*2)) -1)* CDELT1\n",
      "\n",
      "\treturn Lambda\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pivot_to_y(ref_file):\n",
      "     \n",
      "    a = pf.getdata(ref_file)\n",
      "    \n",
      "    return a[:,200]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def calibrator_weights(deltay, sigma):\n",
      "    \"\"\"For calibrator stars with CCD y values deltay from the target star\n",
      "    and radial velocity errors sigma, create an optimal set of weights.\n",
      "\n",
      "    We want to minimise the variance of the weighted sum of calibrator\n",
      "    radial velocities where we have the following constraints:\n",
      "\n",
      "    1) \\Sigma w_i = 1  (i.e. the average value of the calibrators measure CCD shifts)\n",
      "    2) \\Sigma w_i dy_i = 0 (i.e. allow the wavelength solution to rotate about the target)\n",
      "\n",
      "    See http://en.wikipedia.org/wiki/Quadratic_programming\n",
      "    \"\"\"\n",
      "    N = len(sigma)\n",
      "    #Start of with a matrix of zeros then fill it with the \"Q\" and \"E\" matrices\n",
      "    M = np.zeros((N+2,N+2))\n",
      "    M[(range(N),range(N))] = sigma\n",
      "#     idx = np.where(deltay==0)[0][0]\n",
      "#     M[idx,idx] = 1e17\n",
      "    M[N,0:N] = deltay\n",
      "    M[0:N,N] = deltay\n",
      "    M[N+1,0:N] = np.ones(N)\n",
      "    M[0:N,N+1] = np.ones(N)\n",
      "    b = np.zeros(N+2)\n",
      "    b[N+1] = 1.0\n",
      "    #Solve the problem M * x = b\n",
      "    x = np.linalg.solve(M,b)\n",
      "    #The first N elements of x contain the weights.\n",
      "    return x[0:N]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calibrator_weights2(deltay,SNR):\n",
      "\n",
      "    c = 1/np.abs(deltay)/SNR\n",
      "    c[deltay==0]=0\n",
      "    c /=np.sum(c)\n",
      "    return c\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calibrator_weights3(deltay,SNR):\n",
      "#nope\n",
      "    c = (SNR+np.abs(deltay))/np.abs(deltay)\n",
      "    c[deltay==0]=0\n",
      "    c /=np.sum(c)\n",
      "    return c\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_allW(data = [], SNRs = [], starSet=[], RVCorrMethod = 'PM', refEpoch = 0):\n",
      "\n",
      "    if ((data!=[]) and (SNRs!=[])):\n",
      "        if ((starSet!=[]) and (len(starSet.shape)==1) and (starSet[0]>0)):\n",
      "            data = data[starSet]\n",
      "            SNRs = SNRs[starSet]\n",
      "\n",
      "        #load function that translates pivot# to y-pixel  p2y(pivot)=y-pixel of pivot\n",
      "        p2y = pivot_to_y('/Users/Carlos/Documents/HERMES/reductions/6.2/rhoTuc_6.2/0_20aug/1/20aug10042tlm.fits') \n",
      "\n",
      "        #gets the y position of for the data array\n",
      "        datay = p2y[data[:,2].astype(float).astype(int)]\n",
      "        order = np.argsort(datay)\n",
      "        \n",
      "        #Creates empty array for relative weights\n",
      "        #allW[Weights, camera, staridx of the star to be corrected]\n",
      "        allW = np.zeros((data.shape[0],4,data.shape[0]))\n",
      "\n",
      "        for thisStarIdx in range(data.shape[0]):\n",
      "\n",
      "            #converts datay into deltay\n",
      "            deltay = datay-datay[thisStarIdx]\n",
      "\n",
      "            for cam in range(4):\n",
      "\n",
      "                thisSigma = 1./SNRs[:,refEpoch,cam].copy()\n",
      "                thisSigma[np.isnan(thisSigma)]=1e+17  #sets NaNs into SNR=1e-17\n",
      "                \n",
      "                if np.sum(thisSigma)>0:\n",
      "                    if RVCorrMethod == 'PM':\n",
      "                        W = calibrator_weights(deltay,thisSigma)\n",
      "                    elif RVCorrMethod == 'DM':\n",
      "                        W = calibrator_weights2(deltay,thisSigma)\n",
      "                        \n",
      "#                         print data[thisStarIdx,0],RVCorrMethod\n",
      "                        if data[thisStarIdx,0]=='Giant01':\n",
      "                            for a,b,c in zip(thisSigma[order],W[order], thisSigma[order]):\n",
      "                                print 1./a,b,c\n",
      "                        print ''\n",
      "\n",
      "                else:\n",
      "                    W = np.zeros(deltay.shape[0]) #hack to fix an all zeros SNRs for failed reductions\n",
      "                \n",
      "                allW[:,cam,thisStarIdx] = W\n",
      "                    \n",
      "    else:\n",
      "        print 'Create allW: Input arrays missing'\n",
      "        allW =[]\n",
      "\n",
      "    return allW"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_RVCorr_PM(RVs, allW, RVClip = 1e17,starSet=[]):\n",
      "    RVCorr = np.zeros(RVs.shape)\n",
      "    print 'Clipping to',RVClip\n",
      "    RVs[np.abs(RVs)>RVClip]=0\n",
      "    \n",
      "    for thisStarIdx in range(RVs.shape[0]):\n",
      "        for epoch in range(RVs.shape[1]):\n",
      "            thisRVCorr = (allW[:,:,thisStarIdx]+1)*RVs[:,epoch,:]\n",
      "            RVCorr[:,epoch,:] = thisRVCorr + RVs[:,epoch,:] \n",
      "\n",
      "    return RVCorr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_RVCorr_DM(RVs, allW, RVClip = 1e17,starSet=[]):\n",
      "    RVCorr = np.zeros(RVs.shape)\n",
      "    print 'Clipping to',RVClip\n",
      "    RVs[np.abs(RVs)>RVClip]=0\n",
      "    \n",
      "    for thisStarIdx in range(RVs.shape[0]):\n",
      "        for epoch in range(RVs.shape[1]):\n",
      "            for cam in range(RVs.shape[2]):\n",
      "                thisRVCorr = np.nansum(allW[:,cam,thisStarIdx]*RVs[:,epoch,cam])\n",
      "                RVCorr[thisStarIdx,epoch,cam] = thisRVCorr\n",
      "\n",
      "    return RVCorr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def quad(x,a,b,c):\n",
      "    curve  = a*x**2+b*x+c\n",
      "    return curve\n",
      "\n",
      "def fit_quad(p, quadX, quadY):\n",
      "    a = optimize.leastsq(diff_quad, p, args= [quadX, quadY], epsfcn=0.1)\n",
      "    return a\n",
      "\n",
      "def diff_quad(p, args):\n",
      "    quadX = args[0]\n",
      "    quadY = args[1]\n",
      "    diff = quad(quadX, p[0],p[1], p[2]) - quadY\n",
      "    return diff\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fit_continuum(disp, flux, knot_spacing=200, sigma_clip=(1.0, 0.2), \\\n",
      "      max_iterations=3, order=3, exclude=None, include=None, \\\n",
      "      additional_points=None, function='spline', scale=1.0, **kwargs):\n",
      "    \"\"\"Fits the continuum for a given `Spectrum1D` spectrum.\n",
      "    \n",
      "    Parameters\n",
      "    ----\n",
      "    knot_spacing : float or None, optional\n",
      "        The knot spacing for the continuum spline function in Angstroms. Optional.\n",
      "        If not provided then the knot spacing will be determined automatically.\n",
      "    \n",
      "    sigma_clip : a tuple of two floats, optional\n",
      "        This is the lower and upper sigma clipping level respectively. Optional.\n",
      "        \n",
      "    max_iterations : int, optional\n",
      "        Maximum number of spline-fitting operations.\n",
      "        \n",
      "    order : int, optional\n",
      "        The order of the spline function to fit.\n",
      "        \n",
      "    exclude : list of tuple-types containing floats, optional\n",
      "        A list of wavelength regions to always exclude when determining the\n",
      "        continuum. Example:\n",
      "        \n",
      "        >> exclude = [\n",
      "        >>    (3890.0, 4110.0),\n",
      "        >>    (4310.0, 4340.0)\n",
      "        >>  ]\n",
      "        \n",
      "        In the example above the regions between 3890 A and 4110 A, as well as\n",
      "        4310 A to 4340 A will always be excluded when determining the continuum\n",
      "        regions.\n",
      "\n",
      "    function: only 'spline' or 'poly'\n",
      "\n",
      "    scale : float\n",
      "        A scaling factor to apply to the normalised flux levels.\n",
      "        \n",
      "    include : list of tuple-types containing floats, optional\n",
      "        A list of wavelength regions to always include when determining the\n",
      "        continuum.\n",
      "        \n",
      "    Notes\n",
      "    -----\n",
      "    (c) Dr. Casey\n",
      "    \"\"\"\n",
      "    \n",
      "    exclusions = []\n",
      "    continuum_indices = range(len(flux))\n",
      "\n",
      "    # Snip left and right\n",
      "    finite_positive_flux = np.isfinite(flux) * flux > 0\n",
      "\n",
      "    #print \"finite flux\", np.any(finite_positive_flux), finite_positive_flux\n",
      "    #print \"where flux\", np.where(finite_positive_flux)\n",
      "    #print \"flux is...\", flux\n",
      "    left_index = np.where(finite_positive_flux)[0][0]\n",
      "    right_index = np.where(finite_positive_flux)[0][-1]\n",
      "\n",
      "    # See if there are any regions we need to exclude\n",
      "    if exclude is not None and len(exclude) > 0:\n",
      "        exclude_indices = []\n",
      "        \n",
      "        if isinstance(exclude[0], float) and len(exclude) == 2:\n",
      "            # Only two floats given, so we only have one region to exclude\n",
      "            exclude_indices.extend(range(*np.searchsorted(disp, exclude)))\n",
      "            \n",
      "        else:\n",
      "            # Multiple regions provided\n",
      "            for exclude_region in exclude:\n",
      "                exclude_indices.extend(range(*np.searchsorted(disp, exclude_region)))\n",
      "    \n",
      "        continuum_indices = np.sort(list(set(continuum_indices).difference(np.sort(exclude_indices))))\n",
      "        \n",
      "    # See if there are any regions we should always include\n",
      "    if include is not None and len(include) > 0:\n",
      "        include_indices = []\n",
      "        \n",
      "        if isinstance(include[0], float) and len(include) == 2:\n",
      "            # Only two floats given, so we can only have one region to include\n",
      "            include_indices.extend(range(*np.searchsorted(disp, include)))\n",
      "            \n",
      "        else:\n",
      "            # Multiple regions provided\n",
      "            for include_region in include:\n",
      "                include_indices.extend(range(*np.searchsorted(disp, include_region)))\n",
      "    \n",
      "\n",
      "    # We should exclude non-finite numbers from the fit\n",
      "    non_finite_indices = np.where(~np.isfinite(flux))[0]\n",
      "    continuum_indices = np.sort(list(set(continuum_indices).difference(non_finite_indices)))\n",
      "\n",
      "    # We should also exclude zero or negative flux points from the fit\n",
      "    zero_flux_indices = np.where(0 >= flux)[0]\n",
      "    continuum_indices = np.sort(list(set(continuum_indices).difference(zero_flux_indices)))\n",
      "\n",
      "    original_continuum_indices = continuum_indices.copy()\n",
      "\n",
      "    if knot_spacing is None or knot_spacing == 0:\n",
      "        knots = []\n",
      "\n",
      "    else:\n",
      "        knot_spacing = abs(knot_spacing)\n",
      "        \n",
      "        end_spacing = ((disp[-1] - disp[0]) % knot_spacing) /2.\n",
      "    \n",
      "        if knot_spacing/2. > end_spacing: end_spacing += knot_spacing/2.\n",
      "            \n",
      "        knots = np.arange(disp[0] + end_spacing, disp[-1] - end_spacing + knot_spacing, knot_spacing)\n",
      "        if len(knots) > 0 and knots[-1] > disp[continuum_indices][-1]:\n",
      "            knots = knots[:knots.searchsorted(disp[continuum_indices][-1])]\n",
      "            \n",
      "        if len(knots) > 0 and knots[0] < disp[continuum_indices][0]:\n",
      "            knots = knots[knots.searchsorted(disp[continuum_indices][0]):]\n",
      "\n",
      "    for iteration in xrange(max_iterations):\n",
      "        \n",
      "        splrep_disp = disp[continuum_indices]\n",
      "        splrep_flux = flux[continuum_indices]\n",
      "\n",
      "        splrep_weights = np.ones(len(splrep_disp))\n",
      "\n",
      "        # We need to add in additional points at the last minute here\n",
      "        if additional_points is not None and len(additional_points) > 0:\n",
      "\n",
      "            for point, flux, weight in additional_points:\n",
      "\n",
      "                # Get the index of the fit\n",
      "                insert_index = int(np.searchsorted(splrep_disp, point))\n",
      "                \n",
      "                # Insert the values\n",
      "                splrep_disp = np.insert(splrep_disp, insert_index, point)\n",
      "                splrep_flux = np.insert(splrep_flux, insert_index, flux)\n",
      "                splrep_weights = np.insert(splrep_weights, insert_index, weight)\n",
      "\n",
      "        if function == 'spline':\n",
      "            order = 5 if order > 5 else order\n",
      "            tck = interpolate.splrep(splrep_disp, splrep_flux,\n",
      "                k=order, task=-1, t=knots, w=splrep_weights)\n",
      "\n",
      "            continuum = interpolate.splev(disp, tck)\n",
      "\n",
      "        elif function in (\"poly\", \"polynomial\"):\n",
      "        \n",
      "            p = poly1d(polyfit(splrep_disp, splrep_flux, order))\n",
      "            continuum = p(disp)\n",
      "\n",
      "        else:\n",
      "            raise ValueError(\"Unknown function type: only spline or poly available (%s given)\" % (function, ))\n",
      "        \n",
      "        difference = continuum - flux\n",
      "        sigma_difference = difference / np.std(difference[np.isfinite(flux)])\n",
      "\n",
      "        # Clipping\n",
      "        upper_exclude = np.where(sigma_difference > sigma_clip[1])[0]\n",
      "        lower_exclude = np.where(sigma_difference < -sigma_clip[0])[0]\n",
      "        \n",
      "        exclude_indices = list(upper_exclude)\n",
      "        exclude_indices.extend(lower_exclude)\n",
      "        exclude_indices = np.array(exclude_indices)\n",
      "        \n",
      "        if len(exclude_indices) is 0: break\n",
      "        \n",
      "        exclusions.extend(exclude_indices)\n",
      "        \n",
      "        # Before excluding anything, we must check to see if there are regions\n",
      "        # which we should never exclude\n",
      "        if include is not None:\n",
      "            exclude_indices = set(exclude_indices).difference(include_indices)\n",
      "        \n",
      "        # Remove regions that have been excluded\n",
      "        continuum_indices = np.sort(list(set(continuum_indices).difference(exclude_indices)))\n",
      "    \n",
      "    # Snip the edges based on exclude regions\n",
      "    if exclude is not None and len(exclude) > 0:\n",
      "\n",
      "        # If there are exclusion regions that extend past the left_index/right_index,\n",
      "        # then we will need to adjust left_index/right_index accordingly\n",
      "\n",
      "        left_index = np.max([left_index, np.min(original_continuum_indices)])\n",
      "        right_index = np.min([right_index, np.max(original_continuum_indices)])\n",
      "        \n",
      "\n",
      "    # Apply flux scaling\n",
      "    continuum *= scale\n",
      "    return disp, flux/continuum\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}