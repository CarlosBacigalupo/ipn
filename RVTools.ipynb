{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from scipy import interpolate, signal, optimize, constants, stats\n",
    "from scipy.optimize import leastsq\n",
    "import pyfits as pf\n",
    "import sys\n",
    "import os\n",
    "from lmfit import minimize, Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sys.path = ['', '/disks/ceres/makemake/aphot/kalumbe/reductions/NGC2477_1arc_6.2','/usr/local/yt-hg', '/home/science/staff/kalumbe/my-astro-lib', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/lib/pymodules/python2.7', '/usr/lib/python2.7/dist-packages/ubuntu-sso-client', '/usr/lib/python2.7/dist-packages/ubuntuone-client', '/usr/lib/python2.7/dist-packages/ubuntuone-couch', '/usr/lib/python2.7/dist-packages/ubuntuone-storage-protocol', '/usr/lib/python2.7/dist-packages/wx-2.8-gtk2-unicode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_sine_RVs(baryRVs, MJDs,data, RVClip = 1e6, starIdx = -1, cam = -1, npyName = 'sineFit.npy'):\n",
    "\n",
    "    sine_fit = np.ones((baryRVs.shape[0],4,4))*np.nan\n",
    "    try: \n",
    "        sine_fit = np.load('npy/'+npyName)\n",
    "        print 'Found previous',npyName,'array. Using it for update'\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for cam in range(4):\n",
    "        for i,thisRVs in enumerate(baryRVs[:,:,cam]):\n",
    "            if ((starIdx==-1) or(starIdx==i)): \n",
    "                thisRVs[np.abs(np.nan_to_num(thisRVs))>RVClip]=np.nan\n",
    "                thisBaryRVs = thisRVs[-np.isnan(thisRVs)]\n",
    "                thisMJDs = MJDs[-np.isnan(thisRVs)]\n",
    "                \n",
    "                print 'This target:', data[i,0], '- Camera ',str(cam+1)\n",
    "                print 'Calculating RV fit for', thisBaryRVs.shape[0], 'data points.',np.sum(np.isnan(thisRVs)),'NaNs'\n",
    "                if thisMJDs.shape[0]>3:                \n",
    "                    minIdx = np.where(thisBaryRVs==np.min(thisBaryRVs))[0][0]\n",
    "                    maxIdx = np.where(thisBaryRVs==np.max(thisBaryRVs))[0][0]\n",
    "                    guess_P = np.abs(thisMJDs[minIdx] - thisMJDs[maxIdx])*2\n",
    "\n",
    "                    params = Parameters()\n",
    "                    params.add('amp', value=np.abs((np.max(thisBaryRVs)-np.min(thisBaryRVs))/2.), min=0)\n",
    "                    params.add('phase', value = 0, max = guess_P/2., min = -guess_P/2. )\n",
    "                    params.add('period', value=guess_P, min = 0 )\n",
    "\n",
    "                    print 'Guess A,ph,P',params.values()\n",
    "\n",
    "                    output = minimize(optimise_sine, params, args=(thisMJDs, thisBaryRVs))\n",
    "                    \n",
    "                    print 'std err',output.chisqr, output.redchi , np.std(output.residual)\n",
    "\n",
    "                    sine_fit[i,0,cam]=output.params.valuesdict()['amp']\n",
    "                    sine_fit[i,1,cam]=output.params.valuesdict()['phase']\n",
    "                    sine_fit[i,2,cam]=output.params.valuesdict()['period']\n",
    "                    sine_fit[i,3,cam]=np.std(output.residual)\n",
    "\n",
    "                    print 'Guess A,ph,P', sine_fit[i,:3,cam]\n",
    "\n",
    "                else: \n",
    "                    print 'Result','NOT ENOUGH DATAPOINTS'\n",
    "\n",
    "    #                 est_std, est_phase, est_P =ouput[0]\n",
    "\n",
    "                    sine_fit[i,:,cam]=[0,0,0,0]\n",
    "                print \n",
    "            \n",
    "    np.save('npy/'+npyName,sine_fit)\n",
    "    print 'Fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_MJDs_groups(MJDs, gapMins = 40):\n",
    "    \n",
    "    mins2Days = 1/24./60\n",
    "    gap2Days = mins2Days * gapMins # diff in days between exposures to be considered different exposures\n",
    "    \n",
    "    diffArray = MJDs.copy()\n",
    "    diffArray[0] = 0\n",
    "    diffArray[1:] = MJDs[1:]-MJDs[:-1]\n",
    "    \n",
    "    avgIdxGroups = diffArray.copy()\n",
    "    \n",
    "    avgIdx = 0\n",
    "    for i,diff in enumerate(diffArray):\n",
    "        if diff>gap2Days: avgIdx+=1\n",
    "        avgIdxGroups[i] = avgIdx\n",
    "        \n",
    "    np.save('npy/avgIdxGroups.npy',avgIdxGroups.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_MJDs_data():\n",
    "\n",
    "    avgIdxGroups = np.load('npy/avgIdxGroups.npy')\n",
    "    baryRVs = np.load('npy/baryRVs.npy')\n",
    "    MJDs = np.load('npy/MJDs.npy')\n",
    "    \n",
    "    ttlGroups = np.max(avgIdxGroups)+1\n",
    "    avgBaryRVs = np.zeros((baryRVs.shape[0],ttlGroups,4))\n",
    "    avgMJDs = np.zeros(ttlGroups)\n",
    "    \n",
    "    for i in range(ttlGroups):\n",
    "        print i,np.nanmean(baryRVs[:,avgIdxGroups==i,:],axis=1)\n",
    "        avgBaryRVs[:,i,:] = np.nanmean(baryRVs[:,avgIdxGroups==i,:],axis=1)\n",
    "        avgMJDs[i] = np.nanmean(MJDs[avgIdxGroups==i])\n",
    "            \n",
    "    np.save('npy/avgBaryRVs.npy',avgBaryRVs)\n",
    "    np.save('npy/avgMJDs.npy',avgMJDs)\n",
    "    print 'Fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimise_sine(x, MJDs, thisBaryRVs):\n",
    "    \n",
    "#     print 'x',x\n",
    "    \n",
    "    amp = x['amp'].value\n",
    "    ph = x['phase'].value\n",
    "    period = x['period'].value\n",
    "\n",
    "#     print 'MJDs',MJDs\n",
    "#     print 'thisBaryRVs',thisBaryRVs.shape\n",
    "#     if x[2]==0: x[2]=1e-17\n",
    "#     result = x[0]*(np.sin(np.pi*2./x[2]*(MJDs+x[1]))-np.sin(np.pi*2./x[2]*(MJDs[0]+x[1]))) - thisBaryRVs\n",
    "#     if x[2]==0: x[2]=1e-17\n",
    "    #subtracts epoch 0\n",
    "#     result = amp*(np.sin(np.pi*2./period*(MJDs+ph))- np.sin(np.pi*2./period*(MJDs[0]+ph))) - thisBaryRVs\n",
    "\n",
    "    #direct fit\n",
    "    result = amp*(np.sin(np.pi*2./period*(MJDs+ph))) - thisBaryRVs\n",
    "#     print 'result',result\n",
    "#     print result - thisBaryRVs\n",
    "    \n",
    "    return result \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_results(data, sineFit, avgSineFit, baryRVs, avgBaryRVs):\n",
    "\n",
    "    Range = np.ptp(np.nan_to_num(baryRVs),axis=1)\n",
    "    order = np.argsort(Range[:,0])[::-1]    \n",
    "    fittedRangeResults = Range[order]\n",
    "\n",
    "    ratios = sineFit[:,0,:]/sineFit[:,3,:]\n",
    "    fittedResults = ratios[order]\n",
    "    \n",
    "    \n",
    "    avgRatios = avgSineFit[:,0,:]/avgSineFit[:,3,:]\n",
    "    fittedAvgResults = avgRatios[order]\n",
    "    \n",
    "    AvgRange = np.ptp(np.nan_to_num(avgBaryRVs),axis=1)\n",
    "    fittedAvgRangeResults = AvgRange[order]\n",
    "    \n",
    "    fittedData = data[:,0][order]\n",
    "    \n",
    "    np.save('npy/fittedResults.npy',fittedResults)\n",
    "    np.save('npy/fittedRangeResults.npy',fittedRangeResults)\n",
    "    np.save('npy/fittedAvgResults.npy',fittedAvgResults)\n",
    "    np.save('npy/fittedAvgRangeResults.npy',fittedAvgRangeResults)\n",
    "    np.save('npy/fittedData.npy',fittedData)\n",
    "    print 'Fine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create cross correlation curves wrt epoch 0\n",
    "def RVs_CC_t0(thisStar, starIdx, minMJD=0 ,  xDef = 1, CCReferenceSet = 0, printDetails=False, corrHWidth=4, medianRange = 0, useRangeFilter = False):\n",
    "    '''\n",
    "    Cross-correlates all epochs wrt t0. Writes the results to thisStar.cameras[].RVs\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    thisStar : obj\n",
    "        Object holding the star that holds the fluxes to be cross-correlated\n",
    "        \n",
    "    starIdx : int\n",
    "        Index of the star in to be linked in the comments. Not very useful. \n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    Nottin.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "#     validDates = np.all([np.nansum(thisCam.red_fluxes,1).astype(bool) for thisCam in thisStar.exposures.cameras],0)\n",
    "    print ''\n",
    "    for cam,thisCam in enumerate(thisStar.exposures.cameras[:]):\n",
    "        RVs = []\n",
    "        sigmas = [] \n",
    "        Qs = []\n",
    "        SNRs = []\n",
    "\n",
    "        validDates = np.nansum(thisCam.red_fluxes,1).astype(bool)\n",
    "        \n",
    "        print 'Camera',cam\n",
    "        \n",
    "        minWL, maxWL = find_max_wl_range(thisCam)\n",
    "        \n",
    "        #Filters exposures to a minimum MJD\n",
    "#         if minMJD>0:\n",
    "#             print 'Reducing MJD to >=',minMJD\n",
    "#             validDates = thisStar.exposures.MJDs>=minMJD\n",
    "            \n",
    "            \n",
    "#         if len(np.arange(len(validDates))[validDates])>0:\n",
    "#             CCReferenceSet = np.arange(len(validDates))[validDates][0]\n",
    "#         else:\n",
    "#             CCReferenceSet = 0\n",
    "            \n",
    "#         print 'Refernce set =',CCReferenceSet\n",
    "        \n",
    "        lambda1, flux1 = clean_flux(thisCam.wavelengths[CCReferenceSet], thisCam.red_fluxes[CCReferenceSet], minWL, maxWL, medianRange=medianRange)\n",
    "        \n",
    "        plts = 0    \n",
    "        for epoch, MJD in enumerate(thisStar.exposures.MJDs):\n",
    "            print epoch,\n",
    "            lambda2, flux2 = clean_flux(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch], minWL, maxWL, medianRange=medianRange)\n",
    "            \n",
    "            SNR = np.sqrt(stats.nanmedian(thisCam.red_fluxes[epoch]))\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                #Duncan's approach to CC. \n",
    "                CCCurve = np.correlate(flux1, flux2, mode='full')\n",
    "\n",
    "                y = CCCurve[int(CCCurve.shape[0]/2.)-corrHWidth:int(CCCurve.shape[0]/2.)+1+corrHWidth].copy()\n",
    "                y /=np.max(y)\n",
    "                x = np.arange(-corrHWidth,corrHWidth+1)\n",
    "                p,_ = fit_flexi_gaussian([1.,3.,2.,1.,0],y,x )\n",
    "                shift = p[0]\n",
    "                \n",
    "                plt.plot(flux1)\n",
    "                plt.plot(flux2)\n",
    "                plt.title(str(SNR))\n",
    "                plt.show()\n",
    "                \n",
    "                plt.plot(CCCurve)\n",
    "                plt.show()\n",
    "                \n",
    "                plt.plot(x,y)\n",
    "                x_dense = np.linspace(min(x),max(x))\n",
    "                plt.plot(x_dense,flexi_gaussian(x_dense,p[0],p[1],p[2],p[3],p[4]), label='gaussian')\n",
    "                plt.legend(loc=0)\n",
    "                plt.show()\n",
    "\n",
    "                \n",
    "                \n",
    "#                 thisQ, thisdRV = QdRV(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch])\n",
    "\n",
    "                px = 1000\n",
    "                RV = (np.exp(lambda1[px+1]-lambda1[px]) -1) * constants.c * shift\n",
    "                print thisStar.exposures.MJDs[epoch], 'RV',RV                \n",
    "\n",
    "            except Exception,e: \n",
    "                print 'CC Error'\n",
    "                print str(e)\n",
    "                R = 0\n",
    "                thisQ = 0\n",
    "                thisdRV = 0\n",
    "                RV = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            SNRs.append(SNR)\n",
    "    #         Qs.append(thisQ)\n",
    "    #         sigmas.append(thisdRV)\n",
    "            RVs.append(RV)\n",
    "\n",
    "\n",
    "\n",
    "#     thisCam.sigmas = np.array(sigmas)\n",
    "#     thisCam.Qs = np.array(Qs)\n",
    "    thisCam.RVs = np.array(RVs)\n",
    "    thisCam.SNRs = np.array(SNRs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create cross correlation curves wrt epoch 0\n",
    "def RVs_CC_t0_arc(thisStar, CCReferenceSet = 0, corrHWidth=10):\n",
    "    '''\n",
    "    Cross-correlates all epochs wrt t0. Writes the results to thisStar.cameras[].RVs\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    thisStar : obj\n",
    "        Object holding the star that holds the fluxes to be cross-correlated\n",
    "        \n",
    "    starIdx : int\n",
    "        Index of the star in to be linked in the comments. Not very useful. \n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    Nottin.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "#     validDates = np.all([np.nansum(thisCam.red_fluxes,1).astype(bool) for thisCam in thisStar.exposures.cameras],0)\n",
    "    print ''\n",
    "    for cam,thisCam in enumerate(thisStar.exposures.cameras[:1]):\n",
    "        RVs = []\n",
    "        sigmas = [] \n",
    "        Qs = []\n",
    "        SNRs = []\n",
    "\n",
    "        validDates = np.nansum(thisCam.red_fluxes,1).astype(bool)\n",
    "        \n",
    "        print 'Camera',cam\n",
    "        \n",
    "        minWL, maxWL = find_max_wl_range(thisCam)\n",
    "        \n",
    "        #Filters exposures to a minimum MJD\n",
    "#         if minMJD>0:\n",
    "#             print 'Reducing MJD to >=',minMJD\n",
    "#             validDates = thisStar.exposures.MJDs>=minMJD\n",
    "            \n",
    "            \n",
    "#         if len(np.arange(len(validDates))[validDates])>0:\n",
    "#             CCReferenceSet = np.arange(len(validDates))[validDates][0]\n",
    "#         else:\n",
    "#             CCReferenceSet = 0\n",
    "            \n",
    "#         print 'Refernce set =',CCReferenceSet\n",
    "        \n",
    "        lambda1, flux1 = clean_arc(thisCam.wavelengths[CCReferenceSet], thisCam.red_fluxes[CCReferenceSet], minWL, maxWL)\n",
    "        \n",
    "        plts = 0    \n",
    "        for epoch, MJD in enumerate(thisStar.exposures.MJDs):\n",
    "            print epoch,\n",
    "            lambda2, flux2 = clean_arc(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch], minWL, maxWL)\n",
    "\n",
    "            try:\n",
    "                \n",
    "                #Duncan's approach to CC. \n",
    "                CCCurve = np.correlate(flux1, flux2, mode='full')\n",
    "\n",
    "                y = CCCurve[int(CCCurve.shape[0]/2.)-corrHWidth:int(CCCurve.shape[0]/2.)+1+corrHWidth].copy()\n",
    "                y /=np.max(y)\n",
    "                x = np.arange(-corrHWidth,corrHWidth+1)\n",
    "                p,_ = fit_flexi_gaussian([1,3.,2.,1.,0],y,x )\n",
    "                shift = p[0]\n",
    "                \n",
    "#                 thisQ, thisdRV = QdRV(thisCam.wavelengths[epoch], thisCam.red_fluxes[epoch])\n",
    "\n",
    "                px = 1000\n",
    "                RV = (np.exp(lambda1[px+1]-lambda1[px]) -1) * constants.c * shift\n",
    "                print 'RV',RV                \n",
    "\n",
    "            except Exception,e: \n",
    "                print 'CC Error'\n",
    "                print str(e)\n",
    "                R = 0\n",
    "                thisQ = 0\n",
    "                thisdRV = 0\n",
    "                RV = 0\n",
    "\n",
    "            SNR = np.sqrt(stats.nanmedian(thisCam.red_fluxes[epoch]))\n",
    "\n",
    "\n",
    "            SNRs.append(SNR)\n",
    "    #         Qs.append(thisQ)\n",
    "    #         sigmas.append(thisdRV)\n",
    "            RVs.append(RV)\n",
    "\n",
    "\n",
    "\n",
    "#     thisCam.sigmas = np.array(sigmas)\n",
    "#     thisCam.Qs = np.array(Qs)\n",
    "    thisCam.RVs = np.array(RVs)\n",
    "    thisCam.SNRs = np.array(SNRs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_spec_NaNs(flux):\n",
    "    \n",
    "    #fix initial nans on edges\n",
    "    nanMap = np.isnan(flux)\n",
    "    nanGroups, nNanGroups = label(nanMap)\n",
    "#     leftEdgeIdx=0\n",
    "#     rightEdgeIdx=len(flux)\n",
    "    \n",
    "#     plt.plot(nanMap)\n",
    "#     plt.show()\n",
    "    \n",
    "#     nanMapIdx = np.where(nanMap==True) <<<<<make the next lines faster by using this\n",
    "    if np.sum(nanMap)>0:\n",
    "        print 'Found NaNs in flux array'\n",
    "        \n",
    "    for i,booI in enumerate(nanMap):\n",
    "        if booI==False:\n",
    "            leftEdgeIdx = i\n",
    "            break\n",
    "            \n",
    "    for j,rbooI in enumerate(nanMap[::-1]):\n",
    "        if rbooI==False:\n",
    "            rightEdgeIdx = len(nanMap)-j\n",
    "            break        \n",
    "\n",
    "    fluxMedian = stats.nanmedian(flux)\n",
    "    if leftEdgeIdx>0:\n",
    "        flux[:leftEdgeIdx] = np.linspace(fluxMedian, flux[leftEdgeIdx+1],leftEdgeIdx)\n",
    "    if rightEdgeIdx<len(flux):\n",
    "        flux[rightEdgeIdx:] = np.linspace(flux[rightEdgeIdx-1], fluxMedian, len(flux)-rightEdgeIdx)\n",
    "\n",
    "    nanMap = np.isnan(flux)        \n",
    "    if np.sum(nanMap)>0:\n",
    "        print 'NaNs remain in flux array'        \n",
    "\n",
    "    plt.plot(nanMap)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_flux(wavelength, flux, minWL=0, maxWL=0, xStep = 10**-5, medianRange = 0, flatten = True):\n",
    "    '''\n",
    "    Clean a 1D spectrum. \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    wavelength : int or None, optional\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : int or None, optional\n",
    "        Array of fluxes \n",
    "        \n",
    "    minWL : int, optional\n",
    "        Minimum walength value to return \n",
    "        \n",
    "    maxWL : int, optional\n",
    "        Maximum wavelength value to return \n",
    "        \n",
    "    xStep : float, optional\n",
    "        Coeficient to resample. Final array will be flux.shape[0]*xDef long. \n",
    "        \n",
    "    medianRange : int, optional\n",
    "        Number of pixels to median over. 0 will skip this step. Optional.\n",
    "\n",
    "    flatten : boolean, optional\n",
    "        Divides flux by a fitted 3rd ord polynomial if True. Optional.\n",
    "        \n",
    "    Returns\n",
    "    ----\n",
    "    wavelength : numpy, floats\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : numpy, floats\n",
    "        Array of fluxes \n",
    "        \n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    #median outliers\n",
    "    if medianRange>0:\n",
    "        fluxMed = signal.medfilt(flux,medianRange)\n",
    "        fluxDiff = abs(flux-fluxMed)\n",
    "#         fluxDiff = flux-fluxMed\n",
    "        fluxDiffStd = np.std(fluxDiff)\n",
    "        mask = fluxDiff> 3 * fluxDiffStd\n",
    "        flux[mask] = fluxMed[mask]\n",
    "\n",
    "\n",
    "    if ((wavelength[-np.isnan(flux)].shape[0]>0) &  (flux[-np.isnan(flux)].shape[0]>0)):\n",
    "        \n",
    "        if flatten==True:#flatten curve by fitting a 3rd order poly\n",
    "            fFlux = optimize.curve_fit(cubic, wavelength[-np.isnan(flux)], flux[-np.isnan(flux)], p0 = [1,1,1,1])\n",
    "            fittedCurve = cubic(wavelength, fFlux[0][0], fFlux[0][1], fFlux[0][2], fFlux[0][3])\n",
    "            flux = flux/fittedCurve-1\n",
    "        else:\n",
    "            flux = flux/fluxMedian-1\n",
    "            \n",
    "        #apply tukey\n",
    "        flux = flux * signal.tukey(len(flux), 0.2)\n",
    "\n",
    "        #resample\n",
    "        wavelength,flux = resample_sp(wavelength, flux, minWL, maxWL, xStep)\n",
    "        \n",
    "    else: #if not enough data return NaNs\n",
    "        wavelength = np.ones(4096)*np.nan\n",
    "        flux = np.ones(4096)*np.nan\n",
    "        \n",
    "    return wavelength, flux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_arc(wavelength, flux, minWL=0, maxWL=0, xStep = 5*10**-6):\n",
    "    '''\n",
    "    Clean a 1D arc spectrum. \n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    wavelength : int or None, optional\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : int or None, optional\n",
    "        Array of fluxes \n",
    "        \n",
    "    minWL : int, optional\n",
    "        Minimum walength value to return \n",
    "        \n",
    "    maxWL : int, optional\n",
    "        Maximum wavelength value to return \n",
    "        \n",
    "    xStep : float, optional\n",
    "        Coeficient to resample. Final array will be flux.shape[0]*xDef long. \n",
    "        \n",
    "    medianRange : int, optional\n",
    "        Number of pixels to median over. 0 will skip this step. Optional.\n",
    "\n",
    "    flatten : boolean, optional\n",
    "        Divides flux by a fitted 3rd ord polynomial if True. Optional.\n",
    "        \n",
    "    Returns\n",
    "    ----\n",
    "    wavelength : numpy, floats\n",
    "        Array of wavelengths \n",
    "        \n",
    "    flux : numpy, floats\n",
    "        Array of fluxes \n",
    "        \n",
    "\n",
    "    '''\n",
    "    \n",
    "    #fix initial nans on edges\n",
    "    nanMap = np.isnan(flux)\n",
    "    leftEdgeIdx=0\n",
    "    rightEdgeIdx=len(flux)\n",
    "    \n",
    "#     nanMapIdx = np.where(nanMap==True) <<<<<make the next lines faster by using this\n",
    "    if np.sum(nanMap)>0:\n",
    "        print 'Found NaNs in flux array'\n",
    "    \n",
    "    for i,booI in enumerate(nanMap):\n",
    "        if booI==False:\n",
    "            leftEdgeIdx = i\n",
    "            break\n",
    "            \n",
    "    for j,rbooI in enumerate(nanMap[::-1]):\n",
    "        if rbooI==False:\n",
    "            rightEdgeIdx = len(nanMap)-j\n",
    "            break        \n",
    "\n",
    "    fluxMedian = stats.nanmedian(flux)\n",
    "    if leftEdgeIdx>0:\n",
    "        flux[:leftEdgeIdx] = np.linspace(0, flux[leftEdgeIdx+1],leftEdgeIdx)\n",
    "    if rightEdgeIdx<len(flux):\n",
    "        flux[rightEdgeIdx:] = np.linspace(flux[rightEdgeIdx-1], 0, len(flux)-rightEdgeIdx)\n",
    "\n",
    "        \n",
    "    if ((wavelength[-np.isnan(flux)].shape[0]>0) &  (flux[-np.isnan(flux)].shape[0]>0)):\n",
    "        #resample\n",
    "        wavelength,flux = resample_sp(wavelength, flux, minWL, maxWL, xStep)\n",
    "        \n",
    "    else: #if not enough data return NaNs\n",
    "        wavelength = np.ones(4096)*np.nan\n",
    "        flux = np.ones(4096)*np.nan\n",
    "        \n",
    "    return wavelength, flux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_equal_wl(wl1, wl2):\n",
    "    result = False\n",
    "    \n",
    "    diff = np.sum(wl1-wl2)\n",
    "    \n",
    "    if diff<1e-17:\n",
    "        result = True\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resample_sp(wavelength, flux, minWL, maxWL, xStep):\n",
    "    '''\n",
    "    Rebins the flux into xSteps in log_e space\n",
    "    \n",
    "    Parameters\n",
    "    ----\n",
    "    wavelength : 1-D array\n",
    "            Wavelength values \n",
    "            \n",
    "    flux : 1-D array\n",
    "        Flux values \n",
    "        \n",
    "    xStep : float\n",
    "        Increase step between pixels in log_e(wl)\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    new_wavelength: \n",
    "        log_e(wl) in xStep steps\n",
    "    \n",
    "    new_flux: \n",
    "        rebinned flux\n",
    "\n",
    "    '''\n",
    "    \n",
    "    lnWavelength = np.log(wavelength)\n",
    "    fFlux = interpolate.splrep(lnWavelength, flux) \n",
    "    new_wavelength = np.arange(np.log(minWL), np.log(maxWL),xStep)\n",
    "    new_flux = interpolate.splev(new_wavelength, fFlux, der=0)\n",
    "    \n",
    "#     plt.plot(np.log(wavelength),flux)\n",
    "#     plt.plot(new_wavelength,new_flux)\n",
    "#     plt.show()\n",
    "    \n",
    "    return new_wavelength, new_flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cubic(x,a,b,c,d):\n",
    "    '''\n",
    "    Cubic function\n",
    "    '''\n",
    "    return a*x**3+b*x**2+c*x+d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find the common range of wl for all cameras\n",
    "def find_max_wl_range(thisCam):\n",
    "    '''\n",
    "    Checks the range of valid wavelength for all exposures in given camera.\n",
    "    '''\n",
    "    if len(thisCam.wavelengths)>0:\n",
    "        minWL = np.max(np.min(thisCam.wavelengths, axis=1))\n",
    "        maxWl = np.min(np.max(thisCam.wavelengths, axis=1))\n",
    "\n",
    "    else:\n",
    "        minWL, maxWl = 0,0\n",
    "        \n",
    "    return minWL, maxWl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig, ):\n",
    "    x = np.array(x)\n",
    "    return np.exp(-np.power(x - mu, 2.) / 2 / np.power(sig, 2.))\n",
    "\n",
    "\n",
    "def flexi_gaussian(x, mu, sig, power, a, d ):\n",
    "    x = np.array(x)\n",
    "    return a* np.exp(-np.power(np.abs((x - mu) * np.sqrt(2*np.log(2))/sig),power))+d\n",
    "\n",
    "def fit_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def fit_flexi_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_flexi_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def diff_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "\n",
    "    diff = gaussian(x_range, p[0],p[1]) - flux\n",
    "    return diff\n",
    "\n",
    "def diff_flexi_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "    weights = np.abs(np.gradient(flux)) * (flux+np.max(flux)*.1)\n",
    "    diff = (flexi_gaussian(x_range, p[0], p[1], p[2], p[3], p[4]) - flux)# *weights\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create cross correlation curves wrt epoch 0\n",
    "def single_RVs_CC_t0(thisStar, cam = 0, t = 0, corrHWidth =10, xDef = 1):\n",
    "\n",
    "        print 'Camera',cam, '- t0 wrt t',t\n",
    "        \n",
    "        thisCam = thisStar.exposures.cameras[cam]\n",
    "            \n",
    "        lambda1, flux1 = clean_flux(thisCam.wavelengths[0], thisCam.red_fluxes[0], thisCam, medianRange=5, xDef=xDef )\n",
    "        \n",
    "        lambda2, flux2 = clean_flux(thisCam.wavelengths[t], thisCam.red_fluxes[t], thisCam, medianRange=5, xDef=xDef)\n",
    "        CCCurve = []\n",
    "        CCCurve = signal.fftconvolve(flux1[-np.isnan(flux1)], flux2[-np.isnan(flux2)][::-1], mode='same')\n",
    "        corrMax = np.where(CCCurve==max(CCCurve))[0][0]\n",
    "        p_guess = [corrMax,corrHWidth]\n",
    "        x_mask = np.arange(corrMax-corrHWidth, corrMax+corrHWidth+1)\n",
    "        if max(x_mask)<len(CCCurve):\n",
    "            p = fit_gaussian(p_guess, CCCurve[x_mask], np.arange(len(CCCurve))[x_mask])[0]\n",
    "            if np.modf(CCCurve.shape[0]/2.0)[0]>1e-5:\n",
    "                pixelShift = (p[0]-(CCCurve.shape[0]-1)/2.) #odd number of elements\n",
    "            else:\n",
    "                pixelShift = (p[0]-(CCCurve.shape[0])/2.) #even number of elements\n",
    "\n",
    "\n",
    "            mid_px = thisCam.wavelengths.shape[1]/2\n",
    "            dWl = (thisCam.wavelengths[t,mid_px+1]-thisCam.wavelengths[t,mid_px]) / thisCam.wavelengths[t,mid_px]/xDef\n",
    "            RV = dWl * pixelShift * constants.c \n",
    "            print 'RV',RV\n",
    "        else:\n",
    "            p=RV=0\n",
    "            \n",
    "#         print 'HERE:'\n",
    "\n",
    "        return lambda1,flux1, lambda2,flux2, CCCurve, p, x_mask, RV \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pivot2idx(pivot):\n",
    "    pivot = np.array(pivot)\n",
    "    \n",
    "    rev_num = [np.nan] + ((np.tile(np.arange(10,0,-1),40)+np.repeat(np.arange(0,40)*10,10))-1).tolist()\n",
    "    rev_num = np.array(rev_num)\n",
    "    \n",
    "    return rev_num[pivot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bouchy functions\n",
    "def QdRV(Lambda, A0):\n",
    "\t\n",
    "\tW1 = W(Lambda, A0)\n",
    "\tQ_out = 0\n",
    "\tdRV = 0\n",
    "\tif np.sum(W1)>0:\n",
    "\t\tQ_out = Q(W1, A0)\n",
    "\t\tdRV = constants.c/np.sqrt(np.sum(W1))\n",
    "\t\n",
    "\treturn Q_out, dRV\n",
    "\n",
    "def Q(W, A0):\n",
    "\t'''\n",
    "    Calculates the Q factor of a spectrum from W(weight) and A0(flux) form Bouchy 2001.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    W : np.array\n",
    "        n x 1 np.array weight \n",
    "        \n",
    "    AO : np.array\n",
    "        n x 1 np.array with flux counts\n",
    "    \n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    Q : float\n",
    "        Quality factor. \n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    '''\n",
    "\tQ = 0\n",
    "\tif np.sum(A0[-np.isnan(A0)])>0:\n",
    "\t\tQ = np.sqrt(np.sum(W)/np.sum(A0[-np.isnan(A0)]))\n",
    "\t\n",
    "\treturn Q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def W(Lambda, A0):\n",
    "\t'''\n",
    "    Calculates the weight function form Bouchy 2001.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Lambda : np.array\n",
    "        n x 1 np.array with wavelength bins\n",
    "        \n",
    "    AO : np.array\n",
    "        n x 1 np.array with counts\n",
    "    \n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    W : np.array\n",
    "        n x 1 np.array weights as a function of pixel.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Lambda and A0 should be equal length.\n",
    "    Uses:\n",
    "    W(i) = Lambda(i)**2 (dA0(i)/dLambda(i))**2 / A0(i)\n",
    "    Assumes noise free detector. (No sigma_D**2 term in the denominator).\n",
    "    dA0(i)/dLambda(i) simplified as discrete DeltaY/DeltaX.\n",
    "    '''\n",
    "\n",
    "\tdA0dL = np.zeros(len(A0)-1)\n",
    "\t\n",
    "\tfor i in range(len(A0)-1): #compute partial derivative\n",
    "\t\tdA0dL[i] = (A0[i+1] - A0[i])/(Lambda[i+1] - Lambda[i])\n",
    "\n",
    "\t#compute W (removing last term from Lambda and A0 as dA0dL has n-1 terms.\n",
    "\tW = Lambda[:-1]**2 * dA0dL**2 / A0[:-1]\n",
    "\t\n",
    "\t#clean nans\n",
    "\tW[np.isnan(W)] = 0\n",
    "\t\n",
    "\treturn W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig, ):\n",
    "    x = np.array(x)\n",
    "    return np.exp(-np.power(x - mu, 2.) / 2 / np.power(sig, 2.))\n",
    "\n",
    "\n",
    "def flexi_gaussian(x, mu, sig, power, a, d ):\n",
    "    x = np.array(x)\n",
    "    return a* np.exp(-np.power(np.abs((x - mu) * np.sqrt(2*np.log(2))/sig),power))+d\n",
    "\n",
    "def fit_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def fit_flexi_gaussian(p, flux, x_range):\n",
    "    a = optimize.leastsq(diff_flexi_gaussian, p, args= [flux, x_range])\n",
    "    return a\n",
    "\n",
    "def diff_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "\n",
    "    diff = gaussian(x_range, p[0],p[1]) - flux\n",
    "    return diff\n",
    "\n",
    "def diff_flexi_gaussian(p, args):\n",
    "    \n",
    "    flux = args[0]\n",
    "    x_range = args[1]\n",
    "    weights = np.abs(np.gradient(flux)) * (flux+np.max(flux)*.1)\n",
    "    diff = (flexi_gaussian(x_range, p[0], p[1], p[2], p[3], p[4]) - flux)# *weights\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_wavelength(wavelengths, pixel):\n",
    "    intPx = int(pixel)\n",
    "    fracPx = pixel - int(pixel)\n",
    "\n",
    "    return (wavelengths[intPx+1] - wavelengths[intPx])*fracPx + wavelengths[intPx]\n",
    "\n",
    "\n",
    "def extract_pyhermes_wavelength(fileName):\n",
    "\n",
    "    thisFile = pf.open(fileName)\n",
    "\n",
    "    CRVAL1 = thisFile[0].header['CRVAL1'] # / Co-ordinate value of axis 1                    \n",
    "    CDELT1 = thisFile[0].header['CDELT1'] #  / Co-ordinate increment along axis 1             \n",
    "    CRPIX1 = thisFile[0].header['CRPIX1'] #  / Reference pixel along axis 1                   \n",
    "    NAXIS1 = thisFile[0].header['NAXIS1'] #  / length of the array     \n",
    "\n",
    "    #Creates an array of offset wavelength from the referece px/wavelength\n",
    "    Lambda = (np.arange(int(NAXIS1)))* CDELT1 + CRVAL1\n",
    "    \n",
    "    return Lambda\n",
    "\n",
    "\n",
    "def extract_iraf_wavelength(header, app):\n",
    "    WS = 'WS_'+str(app)\n",
    "    WD = 'WD_'+str(app)\n",
    "\n",
    "    first_px = float(header[WS])\n",
    "    disp = float(header[WD])\n",
    "    length = header['NAXIS1']\n",
    "    wl = np.arange(length)*disp\n",
    "    wl += first_px\n",
    "    \n",
    "    return wl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pivot_to_y(ref_file):\n",
    "     \n",
    "    a = pf.getdata(ref_file)\n",
    "    \n",
    "    return a[:,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def idx2pivot(idx):\n",
    "\n",
    "    rev_num = [np.nan] + ((np.tile(np.arange(10,0,-1),40)+np.repeat(np.arange(0,40)*10,10))-1).tolist()\n",
    "    \n",
    "    if len(np.where(rev_num==idx))>0:\n",
    "        result = np.where(rev_num==idx)[0][0]\n",
    "    else:\n",
    "        result = np.nan\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def calibrator_weights(deltay, sigma):\n",
    "    \"\"\"For calibrator stars with CCD y values deltay from the target star\n",
    "    and radial velocity errors sigma, create an optimal set of weights.\n",
    "\n",
    "    We want to minimise the variance of the weighted sum of calibrator\n",
    "    radial velocities where we have the following constraints:\n",
    "\n",
    "    1) \\Sigma w_i = 1  (i.e. the average value of the calibrators measure CCD shifts)\n",
    "    2) \\Sigma w_i dy_i = 0 (i.e. allow the wavelength solution to rotate about the target)\n",
    "\n",
    "    See http://en.wikipedia.org/wiki/Quadratic_programming\n",
    "    \"\"\"\n",
    "    N = len(sigma)\n",
    "    #Start of with a matrix of zeros then fill it with the \"Q\" and \"E\" matrices\n",
    "    M = np.zeros((N+2,N+2))\n",
    "    M[(range(N),range(N))] = sigma\n",
    "#     idx = np.where(deltay==0)[0][0]\n",
    "#     M[idx,idx] = 1e17\n",
    "    M[N,0:N] = deltay\n",
    "    M[0:N,N] = deltay\n",
    "    M[N+1,0:N] = np.ones(N)\n",
    "    M[0:N,N+1] = np.ones(N)\n",
    "    b = np.zeros(N+2)\n",
    "    b[N+1] = 1.0\n",
    "    #Solve the problem M * x = b\n",
    "    x = np.linalg.solve(M,b)\n",
    "    #The first N elements of x contain the weights.\n",
    "    return x[0:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calibrator_weights2(deltay,SNR):\n",
    "\n",
    "    c = 1/np.abs(deltay)/SNR\n",
    "    c[deltay==0]=0\n",
    "    c /=np.sum(c)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calibrator_weights3(deltay,SNR):\n",
    "#nope\n",
    "    c = (SNR+np.abs(deltay))/np.abs(deltay)\n",
    "    c[deltay==0]=0\n",
    "    c /=np.sum(c)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_allW(data = [], SNRs = [], starSet=[], RVCorrMethod = 'PM', refEpoch = 0):\n",
    "\n",
    "    if ((data!=[]) and (SNRs!=[])):\n",
    "        if ((starSet!=[]) and (len(starSet.shape)==1) and (starSet[0]>0)):\n",
    "            data = data[starSet]\n",
    "            SNRs = SNRs[starSet]\n",
    "\n",
    "        #load function that translates pivot# to y-pixel  p2y(pivot)=y-pixel of pivot\n",
    "        p2y = pivot_to_y('/Users/Carlos/Documents/HERMES/reductions/6.2/rhoTuc_6.2/0_20aug/1/20aug10042tlm.fits') \n",
    "\n",
    "        #gets the y position of for the data array\n",
    "        datay = p2y[data[:,2].astype(float).astype(int)]\n",
    "        order = np.argsort(datay)\n",
    "        \n",
    "        #Creates empty array for relative weights\n",
    "        #allW[Weights, camera, staridx of the star to be corrected]\n",
    "        allW = np.zeros((data.shape[0],4,data.shape[0]))\n",
    "\n",
    "        for thisStarIdx in range(data.shape[0]):\n",
    "\n",
    "            #converts datay into deltay\n",
    "            deltay = datay-datay[thisStarIdx]\n",
    "\n",
    "            for cam in range(4):\n",
    "\n",
    "                thisSigma = 1./SNRs[:,refEpoch,cam].copy()\n",
    "                thisSigma[np.isnan(thisSigma)]=1e+17  #sets NaNs into SNR=1e-17\n",
    "                \n",
    "                if np.sum(thisSigma)>0:\n",
    "                    if RVCorrMethod == 'PM':\n",
    "                        W = calibrator_weights(deltay,thisSigma)\n",
    "                    elif RVCorrMethod == 'DM':\n",
    "                        W = calibrator_weights2(deltay,thisSigma)\n",
    "                        \n",
    "#                         print data[thisStarIdx,0],RVCorrMethod\n",
    "                        if data[thisStarIdx,0]=='Giant01':\n",
    "                            for a,b,c in zip(thisSigma[order],W[order], thisSigma[order]):\n",
    "                                print 1./a,b,c\n",
    "                        print ''\n",
    "\n",
    "                else:\n",
    "                    W = np.zeros(deltay.shape[0]) #hack to fix an all zeros SNRs for failed reductions\n",
    "                \n",
    "                allW[:,cam,thisStarIdx] = W\n",
    "                    \n",
    "    else:\n",
    "        print 'Create allW: Input arrays missing'\n",
    "        allW =[]\n",
    "\n",
    "    return allW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_RVCorr_PM(RVs, allW, RVClip = 1e17,starSet=[]):\n",
    "    RVCorr = np.zeros(RVs.shape)\n",
    "    print 'Clipping to',RVClip\n",
    "    RVs[np.abs(RVs)>RVClip]=0\n",
    "    \n",
    "    for thisStarIdx in range(RVs.shape[0]):\n",
    "        for epoch in range(RVs.shape[1]):\n",
    "            thisRVCorr = (allW[:,:,thisStarIdx]+1)*RVs[:,epoch,:]\n",
    "            RVCorr[:,epoch,:] = thisRVCorr + RVs[:,epoch,:] \n",
    "\n",
    "    return RVCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_RVCorr_DM(RVs, allW, RVClip = 1e17,starSet=[]):\n",
    "    RVCorr = np.zeros(RVs.shape)\n",
    "    print 'Clipping to',RVClip\n",
    "    RVs[np.abs(RVs)>RVClip]=0\n",
    "    \n",
    "    for thisStarIdx in range(RVs.shape[0]):\n",
    "        for epoch in range(RVs.shape[1]):\n",
    "            for cam in range(RVs.shape[2]):\n",
    "                thisRVCorr = np.nansum(allW[:,cam,thisStarIdx]*RVs[:,epoch,cam])\n",
    "                RVCorr[thisStarIdx,epoch,cam] = thisRVCorr\n",
    "\n",
    "    return RVCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quad(x,a,b,c):\n",
    "    curve  = a*x**2+b*x+c\n",
    "    return curve\n",
    "\n",
    "def fit_quad(p, quadX, quadY):\n",
    "    a = optimize.leastsq(diff_quad, p, args= [quadX, quadY], epsfcn=0.1)\n",
    "    return a\n",
    "\n",
    "def diff_quad(p, args):\n",
    "    quadX = args[0]\n",
    "    quadY = args[1]\n",
    "    diff = quad(quadX, p[0],p[1], p[2]) - quadY\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def comment(star, epoch, cam, comment):\n",
    "    comments = []\n",
    "    try:\n",
    "        os.mkdir('npy')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        comments = np.load('npy/comments.npy')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if comments==[]:\n",
    "        comments = np.zeros((1,),dtype=('i4,i4,i4,a100'))\n",
    "        comments[:] = [(star, epoch, cam, comment)]\n",
    "    else:\n",
    "        x = np.zeros((1,),dtype=('i4,i4,i4,a100'))\n",
    "        x[:] = [(star, epoch, cam, comment)]\n",
    "        comments = np.append(comments,x)\n",
    "    \n",
    "    np.save('npy/comments.npy',comments)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
